<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>最小二乘法和梯度下降法</title>
      <link href="/2020/04/07/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95%E5%92%8C%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/"/>
      <url>/2020/04/07/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95%E5%92%8C%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><p>最小二乘法是用来最小化误差函数从而寻找函数得最佳参数的一种方法，学习的时候最小二乘法与梯度下降法我感觉很类似，所以来记录一下。</p><p>参考文章：<a href="https://zhuanlan.zhihu.com/p/109986821" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/109986821</a></p><h2 id="最小二乘法推导"><a href="#最小二乘法推导" class="headerlink" title="最小二乘法推导"></a>最小二乘法推导</h2><p>首先，<strong>一元线性回归</strong>的最小二乘法推导比较容易，上述知乎也有链接，这里直接给出结论：</p><script type="math/tex; mode=display">y = Wx + b \\x = {x_1,x_2,...x_m}\\</script><script type="math/tex; mode=display">\begin{cases}W = \frac{\sum_{i=1}^m(x_i-\bar{x})*(y_i-\bar{y})}{\sum_{i=1}^m(x_i-\bar{x})^2}\\b = \bar{y} - W*\bar{x}\end{cases}</script><p>对于<strong>多元线性回归</strong>，采用矩阵求解：同样直接给出结论</p><script type="math/tex; mode=display">y = X\beta</script><p><a href="https://user-images.githubusercontent.com/60562661/78578352-fbce8d00-7861-11ea-81fd-9b29e9efec21.png" data-fancybox="group" data-caption="1586188084270" class="fancybox"><img alt="1586188084270" style="zoom:80%;" title="1586188084270" data-src="https://user-images.githubusercontent.com/60562661/78578352-fbce8d00-7861-11ea-81fd-9b29e9efec21.png" class="lazyload"></a></p><p><a href="https://user-images.githubusercontent.com/60562661/78578356-fd985080-7861-11ea-84e4-d520251026bb.png" data-fancybox="group" data-caption="1586188119187" class="fancybox"><img alt="1586188119187" style="zoom:80%;" title="1586188119187" data-src="https://user-images.githubusercontent.com/60562661/78578356-fd985080-7861-11ea-84e4-d520251026bb.png" class="lazyload"></a></p><h2 id="两者区别"><a href="#两者区别" class="headerlink" title="两者区别"></a>两者区别</h2><p>由上述可以看出，</p><p><strong>最小二乘法：</strong></p><ul><li>可以直接求矩阵求逆一步到位，求出所的参数，求的全局最优解，无需迭代；</li><li>但是只适用于线性回归模型，并且矩阵复杂时计算复杂度高</li></ul><p><strong>梯度下降法：</strong></p><ul><li>需要设置学习率进行一步步迭代，求得局部最小值或者是全局最优解</li><li>适用于任何模型，只要是凸函数均可以求求出解</li></ul><h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><p>这里想起来分类为什么不适合用最小二乘法求解？</p><p><strong>最小二乘法<code>(y-y-true)^2</code>有个平方，对于离群的点平方会很致命，尽量拟合数据就会导致错误出现</strong></p><hr><p><strong>2020年4月7日夜</strong></p></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 最小二乘法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数学中的李群初探</title>
      <link href="/2020/04/01/%E6%95%B0%E5%AD%A6%E4%B8%AD%E7%9A%84%E6%9D%8E%E7%BE%A4%E5%88%9D%E6%8E%A2/"/>
      <url>/2020/04/01/%E6%95%B0%E5%AD%A6%E4%B8%AD%E7%9A%84%E6%9D%8E%E7%BE%A4%E5%88%9D%E6%8E%A2/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><h2 id="李群"><a href="#李群" class="headerlink" title="李群"></a>李群</h2><h2 id="直观上的李群"><a href="#直观上的李群" class="headerlink" title="直观上的李群"></a>直观上的李群</h2><p>首先李群也是一种降维算法。降维就是为了使用更低维的向量最大程度上表示原来的特征，在机器学习中有很多降维算法：</p><ul><li><code>PCA(Principal Component Analysis)</code>算法处理的是<strong>方形</strong>的矩阵(n*n)；</li><li><p><code>奇异值分解 SVD (Singular Value Decomposition)</code> 可以处理<strong>任意</strong>形状的矩阵(m*n)；</p></li><li><p>李群则可以处理<code>张量</code>,对张量进行降维度。</p></li></ul><h2 id="李群计算流程"><a href="#李群计算流程" class="headerlink" title="李群计算流程"></a>李群计算流程</h2><h3 id="李群运动链模型"><a href="#李群运动链模型" class="headerlink" title="李群运动链模型"></a>李群运动链模型</h3><p><a href="https://user-images.githubusercontent.com/60562661/78159789-a0715900-7475-11ea-8170-80db8de764e7.png" data-fancybox="group" data-caption="1585753553835" class="fancybox"><img alt="1585753553835" title="1585753553835" data-src="https://user-images.githubusercontent.com/60562661/78159789-a0715900-7475-11ea-8170-80db8de764e7.png" class="lazyload"></a></p><p>这里以老鼠为例，假设老鼠身上一共有四根骨头，<strong>AB</strong>,<strong>BC</strong>,<strong>CD</strong>,<strong>DE</strong>，以每根骨头自身作为x轴，单独建立每根骨头的三维坐标系，<strong>C</strong>的坐标在AB骨头坐标系表示就是：</p><script type="math/tex; mode=display">\begin{bmatrix}{q^*}\\{1}\end{bmatrix}\begin{bmatrix}{R}&{t}\\{0}&{1}\\\end{bmatrix} *\begin{bmatrix}{q}\\{1}\end{bmatrix}</script><p>其中，</p><ul><li>q是<strong>C</strong>在BC三维坐标系下的，形状是<strong><code>3*1</code></strong>；</li><li>q^是<strong>C</strong>在AB坐标系下的坐标，形状是   <code>3*1</code></li><li>R是旋转矩阵，形状是   <code>3*3</code></li><li><p>t是平移矩阵，形状是<code>3*1</code></p></li><li><p>中间的矩阵就是变换矩阵，整体维度就是 <code>4*1 = 4*4 * 4*1</code></p></li></ul><p><strong>更一般的坐标变换：</strong></p><script type="math/tex; mode=display">\begin{bmatrix}{x^*}\\{1}\end{bmatrix}\begin{bmatrix}{R_i}&{t_i}\\{0}&{1}\\\end{bmatrix} *\begin{bmatrix}{x}\\{1}\end{bmatrix}=g_i*\begin{bmatrix}{x}\\{1}\end{bmatrix}</script><p><code>gi</code>就是上图中的<strong>g1，g2…….</strong></p><p><strong>姿态变换：</strong></p><p>两种姿态都可以映射到全局的一个三维坐标系上，就可以进行转换。</p><h3 id="旋转矩阵-R"><a href="#旋转矩阵-R" class="headerlink" title="旋转矩阵 R"></a>旋转矩阵 R</h3><p>首先R属于三阶特殊正交阵，(满足6个条件) 而本来的维度是9，所以自由度为3，所以可以用一个向量来代替这个旋转矩阵。</p><p><strong>所以下面的工作就变成了R的降维工作。</strong></p><hr><h4 id="预备知识1：斜对角矩阵"><a href="#预备知识1：斜对角矩阵" class="headerlink" title="预备知识1：斜对角矩阵"></a>预备知识1：斜对角矩阵</h4><script type="math/tex; mode=display">\mu = (\mu_1,\mu_2,\mu_3)</script><script type="math/tex; mode=display">\hat{\mu} =\begin{bmatrix} {0}&{-\mu_3}&{\mu_2}\\{\mu_3}&{0}&{-\mu_1}\\{-\mu_2}&{\mu_1}&{0}\end{bmatrix}</script><ul><li>对于任意的μ，总有唯一的μ^与之对应；</li><li>对于任意的μ^ ，总有唯一的μ与之对应；</li></ul><h4 id="预备知识2-：e-w"><a href="#预备知识2-：e-w" class="headerlink" title="预备知识2 ：e^w ^"></a>预备知识2 ：e^w ^</h4><p><a href="https://user-images.githubusercontent.com/60562661/78159799-a49d7680-7475-11ea-8c58-f2e028894ab3.png" data-fancybox="group" data-caption="1585756692993" class="fancybox"><img alt="1585756692993" title="1585756692993" data-src="https://user-images.githubusercontent.com/60562661/78159799-a49d7680-7475-11ea-8c58-f2e028894ab3.png" class="lazyload"></a></p><hr><h4 id="R的变换"><a href="#R的变换" class="headerlink" title="R的变换"></a>R的变换</h4><p><a href="https://user-images.githubusercontent.com/60562661/78159795-a2d3b300-7475-11ea-9e3b-f06e8f8cae00.png" data-fancybox="group" data-caption="1585755919172" class="fancybox"><img alt="1585755919172" title="1585755919172" data-src="https://user-images.githubusercontent.com/60562661/78159795-a2d3b300-7475-11ea-9e3b-f06e8f8cae00.png" class="lazyload"></a></p><h2 id="直觉理解"><a href="#直觉理解" class="headerlink" title="直觉理解"></a>直觉理解</h2><p><a href="https://user-images.githubusercontent.com/60562661/78159804-a6ffd080-7475-11ea-9526-4575bcd8efae.png" data-fancybox="group" data-caption="1585756802921" class="fancybox"><img alt="1585756802921" title="1585756802921" data-src="https://user-images.githubusercontent.com/60562661/78159804-a6ffd080-7475-11ea-9526-4575bcd8efae.png" class="lazyload"></a></p><ul><li>首先因为旋转矩阵的自由度为3，所以是在3维流形中；</li><li>在流形曲面处的一个很小的切平面就是<strong>李代数</strong>，可以用三维坐标表示处原来在流形中的坐标；</li><li>整个三维流形就是李群</li></ul></body></html>]]></content>
      
      
      <categories>
          
          <category> Math </category>
          
          <category> 李群 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 李群 </tag>
            
            <tag> 李代数 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>一套针对人体姿态估计的在视频上的关键点标注流程</title>
      <link href="/2020/04/01/%E4%B8%80%E5%A5%97%E7%94%A8%E4%BA%8E%E4%BA%BA%E4%BD%93%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1%E7%9A%84%E5%85%B3%E9%94%AE%E7%82%B9%E6%A0%87%E6%B3%A8%E6%B5%81%E7%A8%8B/"/>
      <url>/2020/04/01/%E4%B8%80%E5%A5%97%E7%94%A8%E4%BA%8E%E4%BA%BA%E4%BD%93%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1%E7%9A%84%E5%85%B3%E9%94%AE%E7%82%B9%E6%A0%87%E6%B3%A8%E6%B5%81%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><p>最近我们项目需要标注数据集的人体关键点，所以我们开发了一套标注的简单流程，这里来记录一下。</p><p>因为关键点太多，不可能人为的取标注很多东西，所以我们要借助现有的算法先计算在矫正。</p><h2 id="一、标注工具-LabelMe"><a href="#一、标注工具-LabelMe" class="headerlink" title="一、标注工具 LabelMe"></a>一、标注工具 LabelMe</h2><p><strong>项目地址：</strong> <a href="https://github.com/wkentaro/labelme" target="_blank" rel="noopener">https://github.com/wkentaro/labelme</a></p><p><strong>安装：</strong><br>建议在python3环境下运行，python2我自己未测试过，具体的相关的可以到项目地址看</p><p>1.创建虚拟环境</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create -n labelme python=<span class="number">3.6</span></span><br></pre></td></tr></tbody></table></figure></div><p>2.激活环境</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source activate labelme</span><br></pre></td></tr></tbody></table></figure></div><p>3.安装<code>labelme</code></p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install labelme</span><br></pre></td></tr></tbody></table></figure></div><p><strong>使用：</strong></p><p>激活虚拟环境后，输入 <code>labelme</code> 打开软件</p><h2 id="二、数据标注流程"><a href="#二、数据标注流程" class="headerlink" title="二、数据标注流程"></a>二、数据标注流程</h2><ol><li>用写好的脚本把视频拆分成单帧；</li><li>用<code>OpenPose</code>跑出所有的图片的帧（或者<code>OpenPose</code>直接在视频上跑）,会得到每张图片的关键点的一个<code>json</code>文件；</li><li>用我们写好的脚本把<code>json</code>转换成<code>labelme</code>格式的<code>json</code>;</li><li>用<code>labelme</code>打开文件夹进行标注</li><li>标注完成后在执行一次脚本，补充删除得点</li></ol><p>labelme之后的标注流程可以参考下面的gif动图：</p><p><a href="https://user-images.githubusercontent.com/60562661/78142369-6f862980-745f-11ea-80b3-4118d153b0b7.gif" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/78142369-6f862980-745f-11ea-80b3-4118d153b0b7.gif" class="lazyload"></a></p><hr><p><strong>目前这套流程已经开始测试使用。</strong></p><p>关于上面提到的脚本，我回头都会集成到实用工具类下面，或者会单独一个labelme的项目上传到github。</p><h2 id="三、标注指南"><a href="#三、标注指南" class="headerlink" title="三、标注指南"></a>三、标注指南</h2><h3 id="一、关键点位置"><a href="#一、关键点位置" class="headerlink" title="一、关键点位置"></a>一、关键点位置</h3><p><strong>Body</strong><br><a href="https://user-images.githubusercontent.com/60562661/78350627-14c40d80-75d8-11ea-8169-acee4a9de517.jpg" data-fancybox="group" data-caption="undefined" class="fancybox"><img style="zoom:50%;" data-src="https://user-images.githubusercontent.com/60562661/78350627-14c40d80-75d8-11ea-8169-acee4a9de517.jpg" class="lazyload"></a><a href="https://user-images.githubusercontent.com/60562661/78350612-0fff5980-75d8-11ea-87dd-e15f7b781405.png" data-fancybox="group" data-caption="undefined" class="fancybox"><img style="zoom:60%;" data-src="https://user-images.githubusercontent.com/60562661/78350612-0fff5980-75d8-11ea-87dd-e15f7b781405.png" class="lazyload"></a></p><p><strong>Hand</strong></p><ul><li>手的坐标用原来的21个太多了，人也看不清楚，所以选取了其中11个点(手指尖、手心)，需要矫正</li></ul><p><a href="https://user-images.githubusercontent.com/60562661/78350619-1261b380-75d8-11ea-985b-11b8574edfca.png" data-fancybox="group" data-caption="1585815119386" class="fancybox"><img alt="1585815119386" style="zoom:67%;" title="1585815119386" data-src="https://user-images.githubusercontent.com/60562661/78350619-1261b380-75d8-11ea-985b-11b8574edfca.png" class="lazyload"></a><a href="https://user-images.githubusercontent.com/60562661/78350632-155ca400-75d8-11ea-901a-7dae752cb30e.png" data-fancybox="group" data-caption="1585815119386" class="fancybox"><img alt="1585815119386" style="zoom:97%;" title="1585815119386" data-src="https://user-images.githubusercontent.com/60562661/78350632-155ca400-75d8-11ea-901a-7dae752cb30e.png" class="lazyload"></a></p><hr><h3 id="二、标注相关"><a href="#二、标注相关" class="headerlink" title="二、标注相关"></a>二、标注相关</h3><h4 id="1-遮挡问题"><a href="#1-遮挡问题" class="headerlink" title="1.遮挡问题"></a>1.遮挡问题</h4><p>如果遇到手部遮挡，这样人也是标不出来的，所以直接删除被遮挡的手关节，(<strong>身体关节被遮挡、出画后如果检测不出来是(0,0)坐标，这时候就不用管</strong>)一个个点的删除比较慢，如果需要批量删除，可以如下操作：（动图pdf无法播放，会在群里再发一份）</p><p><strong>注意：</strong> 所有的左上角(0,0)的点都可以不用去考虑</p><p><a href="https://user-images.githubusercontent.com/60562661/78350639-17266780-75d8-11ea-96bf-0073a266210f.gif" data-fancybox="group" data-caption="undefined" class="fancybox"><img style="zoom: 67%;" data-src="https://user-images.githubusercontent.com/60562661/78350639-17266780-75d8-11ea-96bf-0073a266210f.gif" class="lazyload"></a></p><p><strong>其中，如果没有polygon Labels这个控制框，可以再view菜单下调出来</strong></p><h4 id="2-运动模糊问题"><a href="#2-运动模糊问题" class="headerlink" title="2.运动模糊问题"></a>2.运动模糊问题</h4><p>碰到人的手很模糊，人眼都很难分辨出来，手的点又比较大，这时候标注会很困难，碰到这种情况，直接保留手的关键点，可以跳过手的标注。例如下图：</p><p><a href="https://user-images.githubusercontent.com/60562661/78350623-1392e080-75d8-11ea-806f-060a60f12540.png" data-fancybox="group" data-caption="1585816044541" class="fancybox"><img alt="1585816044541" title="1585816044541" data-src="https://user-images.githubusercontent.com/60562661/78350623-1392e080-75d8-11ea-806f-060a60f12540.png" class="lazyload"></a></p><h2 id="附加：服务器与本地同步"><a href="#附加：服务器与本地同步" class="headerlink" title="附加：服务器与本地同步"></a>附加：服务器与本地同步</h2><p>关于服务器与本地同步很慢的问题，可以在服务器使用百度云即可。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> labelme </tag>
            
            <tag> 关键点标注 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>X-Particles 4.0 粒子</title>
      <link href="/2020/03/29/X-Particles-4-0-%E7%B2%92%E5%AD%90/"/>
      <url>/2020/03/29/X-Particles-4-0-%E7%B2%92%E5%AD%90/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><p>最近学习到了X-Particles4.0粒子的破解流程，虽然我目前已经不做<code>CG</code>了，但是还是值得记录一下，因为这个插件是我当时<code>交智商税交的最多的</code>一个东西,我记得是花了我<strong>380还是390大洋</strong>!</p><p>这里只是记录一下流程，至于具体的破解文件、工具之类的就不放出来了。</p><p><a href="https://user-images.githubusercontent.com/60562661/77853841-f1384600-7218-11ea-9467-d7e1a97a7191.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/77853841-f1384600-7218-11ea-9467-d7e1a97a7191.png" class="lazyload"></a></p><h2 id="下载插件"><a href="#下载插件" class="headerlink" title="下载插件"></a>下载插件</h2><p>首先下载好<code>X-Particles 7.3.2</code>,放入C4D的插件目录</p><h2 id="破解"><a href="#破解" class="headerlink" title="破解"></a>破解</h2><p>输入用户名、邮箱、<code>序列号</code>， 关于序列号这里照常不写出来。</p><h2 id="定时"><a href="#定时" class="headerlink" title="定时"></a>定时</h2><p>修改C4D时间，定时到某一个点，即可破解成功</p><h2 id="Tips"><a href="#Tips" class="headerlink" title="Tips"></a>Tips</h2><p>打开C4D 一定要断网打开，然后再联网即可正常使用。</p><h2 id><a href="#" class="headerlink" title></a><a href="https://user-images.githubusercontent.com/60562661/77853838-eda4bf00-7218-11ea-95a6-9bf0f36c459a.jpg" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/77853838-eda4bf00-7218-11ea-95a6-9bf0f36c459a.jpg" class="lazyload"></a></h2></body></html>]]></content>
      
      
      <categories>
          
          <category> VFX-视效 </category>
          
          <category> 插件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> X-Particle4.0 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>直方图均衡化算法</title>
      <link href="/2020/03/26/%E7%9B%B4%E6%96%B9%E5%9B%BE%E5%9D%87%E8%A1%A1%E5%8C%96%E7%AE%97%E6%B3%95/"/>
      <url>/2020/03/26/%E7%9B%B4%E6%96%B9%E5%9B%BE%E5%9D%87%E8%A1%A1%E5%8C%96%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><p>首先推荐一个知乎回答：<a href="https://www.zhihu.com/question/37204742/answer/221844779" target="_blank" rel="noopener">https://www.zhihu.com/question/37204742/answer/221844779</a> 我觉得讲得很不错。</p><h2 id="为什么需要均衡化？"><a href="#为什么需要均衡化？" class="headerlink" title="为什么需要均衡化？"></a>为什么需要均衡化？</h2><p>直方图均衡化就是因为本来的图像可能像素都集中在某一个或者一两个灰度级，其他灰度级都没有像素信息，此时图片呈现就不会很正常。<strong>（这里不能说不好，直方图没有好坏，它只是反映了图像的信息，而图像则可能是艺术效果而故意为之。）</strong>此时就需要所有的灰度级都有信息，因此均衡化就可以认为是把原来的直方图做了拉伸。</p><p><a href="https://user-images.githubusercontent.com/60562661/77671749-fef48e00-6fc2-11ea-9a7d-1004370c0b2d.png" data-fancybox="group" data-caption="1585238407011" class="fancybox"><img alt="1585238407011" title="1585238407011" data-src="https://user-images.githubusercontent.com/60562661/77671749-fef48e00-6fc2-11ea-9a7d-1004370c0b2d.png" class="lazyload"></a></p><p>而直方图均衡化，也就是增强了图像的对比度，简单的理解就是<strong>偏黑的更黑，偏白的更白</strong>。</p><h2 id="均衡化算法"><a href="#均衡化算法" class="headerlink" title="均衡化算法"></a>均衡化算法</h2><p>下面讨论单色(黑白)图直方图均衡化的一般性算法。</p><p>假设图像 <strong>f,g</strong>,输入图像为<code>f(x,y)</code>,输出为<code>g(x,y)</code>,目标就是用<code>T函数</code>把f变换到g，即<strong>s = T(r)</strong>,g比f更分散。</p><p>设任意灰度值 <strong>t</strong> 在 <strong>f</strong> 中出现的概率为函数    $p_f(t)$,在<strong>g</strong>中概率为：$p_g(t)$, 这两个函数很容易计算，然后定义：</p><script type="math/tex; mode=display">S_f(n) = \int_1^np_f(t)dt</script><p>表示图像f中灰度值小于n的概率</p><script type="math/tex; mode=display">S_g(n) = \int_1^np_g(t)dt</script><p>表示图像g中灰度值小于n的概率</p><p>则可以得出：</p><script type="math/tex; mode=display">S_f(r) = S_g(T(r)) \implies S_f(r) = S_g(s)     \tag{1}</script><p>这个公式很容易理解，举个例子：图像f灰度值小于0.5的像素出现的概率是0.7，映射到图像g后灰度值小于0.7的概率也是0.7。</p><p>对这一式子求微分：</p><script type="math/tex; mode=display">p_f(r)*dr = p_g(s)*ds \tag{2}</script><p>接下来令    $T(r) = L<em>S_f(r)$，即变换公式T = 灰度级数量L </em> f图像中小于灰度r的概率，则：</p><script type="math/tex; mode=display">s = T(r) = L*S_f(r) = L*\int_1^rp_f(t)dt \\\implies \frac{ds}{dr} = L*p_f(r) \tag{3}</script><p>由公式2、3(最后两个公式)得：</p><script type="math/tex; mode=display">p_f(r) = p_g(s)*L*p_f(r) \\\implies p_g(s) = 1/L</script><p>这时候神奇得事情出现了：图像g中各个灰度级像素出现的概率相等，为1/L，也就是说所有灰度级都会出现，有信息。</p><p>总结一下流程：</p><ol><li>计算各个灰度值出现的概率pf；</li><li>用映射函数  $s = T(r) = L<em>S_f(r) = L</em>\int_1^rp_f(t)dt$, 计算所有灰度值的输出即可。</li></ol><p>现实中数字图像的灰度值是<strong>离散</strong>的，同理，把积分改为求和即可。即：</p><script type="math/tex; mode=display">S_f(n) = \sum_{i=1}^np_f(i)</script><script type="math/tex; mode=display">S_g(n) = \sum_{i=1}^np_g(i)</script><script type="math/tex; mode=display">T(r) = L*\sum_{i=1}^rp_f(i)</script><p>现实中由于是离散的，r、s均为整数，所以各个灰度级出现的概率不一定相等。但确定的是，<code>g灰度级信息一定比f更分散了。</code></p></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 图像处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数字图像 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>图像直方图理解</title>
      <link href="/2020/03/26/%E5%9B%BE%E5%83%8F%E7%9B%B4%E6%96%B9%E5%9B%BE%E5%8F%8A%E5%85%B6%E5%9D%87%E8%A1%A1%E5%8C%96%E7%AE%97%E6%B3%95/"/>
      <url>/2020/03/26/%E5%9B%BE%E5%83%8F%E7%9B%B4%E6%96%B9%E5%9B%BE%E5%8F%8A%E5%85%B6%E5%9D%87%E8%A1%A1%E5%8C%96%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><h2 id="直方图-Histogram"><a href="#直方图-Histogram" class="headerlink" title="直方图 Histogram"></a>直方图 Histogram</h2><p>每张图像都对应有直方图，再Ps软件、单反都可以轻易地看到图像的直方图，直方图则可以看出图像得风格。</p><p><code>图像的直方图代表了不同灰度级的像素出现的次数</code>。</p><p><strong>首先看一下灰度级是什么意思？</strong></p><p><a href="https://user-images.githubusercontent.com/60562661/77671759-0156e800-6fc3-11ea-94f9-ec57ac5df32e.jpg" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/77671759-0156e800-6fc3-11ea-94f9-ec57ac5df32e.jpg" class="lazyload"></a></p><p>这张图就清晰的展示了灰度级的概念，通俗来说就是明亮的程度。</p><p><strong>然后看一下直方图长什么样子？</strong></p><p><a href="https://user-images.githubusercontent.com/60562661/77671737-fbf99d80-6fc2-11ea-9930-b89e1408c2a6.png" data-fancybox="group" data-caption="1585236990450" class="fancybox"><img alt="1585236990450" title="1585236990450" data-src="https://user-images.githubusercontent.com/60562661/77671737-fbf99d80-6fc2-11ea-9930-b89e1408c2a6.png" class="lazyload"></a></p><p>这里面对三个颜色通道都画了出来，横坐标代表灰度级，纵坐标代表数量，数量越多图像就越高。</p><p><strong>如何理解直方图？</strong></p><p><a href="https://user-images.githubusercontent.com/60562661/77671928-3bc08500-6fc3-11ea-809f-4313c587180d.png" data-fancybox="group" data-caption="1585237212885" class="fancybox"><img alt="1585237212885" style="zoom:67%;" title="1585237212885" data-src="https://user-images.githubusercontent.com/60562661/77671928-3bc08500-6fc3-11ea-809f-4313c587180d.png" class="lazyload"></a></p><p>如图，再PS的Camera滤镜中把灰度级做了一个区分，它把直方图分成了五类，从左到右分别是：<strong>黑色、阴影、曝光、高光、白色</strong>，鼠标悬浮即会高亮一片区域并且显示该区域代表图像的什么部分。所以就很容易理解直方图了，调整图像的高光等都会使得直方图放生改变。</p><p><code>这里有一个误区是不能把从左到右直方图对应到图像从左到右。</code>因为图像的阴影、高光区域位置都很不规则。如果图像真的从左到右与直方图对应，那么就变成了第一张图这种形式了。</p><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ------------------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"># # @Time    : 2020/3/22 上午 11:33</span></span><br><span class="line"><span class="comment"># # @Author  : fry</span></span><br><span class="line"><span class="comment"># @FileName: 6_2_his_rgb.py</span></span><br><span class="line"><span class="comment"># ------------------------------------------------------------------------------</span></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">image_hist</span><span class="params">(image)</span>:</span> <span class="comment">#画三通道图像的直方图</span></span><br><span class="line">   color = (<span class="string">"blue"</span>, <span class="string">"green"</span>, <span class="string">"red"</span>)<span class="comment">#画笔颜色的值可以为大写或小写或只写首字母或大小写混合</span></span><br><span class="line">   <span class="keyword">for</span> i, color <span class="keyword">in</span> enumerate(color):</span><br><span class="line">       <span class="comment"># 计算直方图函数</span></span><br><span class="line">       <span class="comment"># src-img; channel; mask; bin多少个灰度级; range[0-256],像素值范围； 除了mask其他都要 []</span></span><br><span class="line">       hist = cv2.calcHist([image], [i], <span class="literal">None</span>, [<span class="number">256</span>], [<span class="number">0</span>, <span class="number">256</span>])</span><br><span class="line">       plt.plot(hist, color=color)</span><br><span class="line">       plt.xlim([<span class="number">0</span>, <span class="number">256</span>])</span><br><span class="line">   plt.show()</span><br><span class="line"></span><br><span class="line">image = cv2.imread(<span class="string">'./img/5.jpg'</span>, <span class="number">1</span>)</span><br><span class="line">cv2.namedWindow(<span class="string">"img"</span>,cv2.WINDOW_NORMAL)</span><br><span class="line">cv2.imshow(<span class="string">'img'</span>, image)</span><br><span class="line">image_hist(image)</span><br><span class="line">cv2.waitKey(<span class="number">0</span>)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></tbody></table></figure></div><p>三通道直方图：</p><p><a href="https://user-images.githubusercontent.com/60562661/77671744-fe5bf780-6fc2-11ea-864f-23d315de5e4c.png" data-fancybox="group" data-caption="1585237602654" class="fancybox"><img alt="1585237602654" style="zoom:67%;" title="1585237602654" data-src="https://user-images.githubusercontent.com/60562661/77671744-fe5bf780-6fc2-11ea-864f-23d315de5e4c.png" class="lazyload"></a></p></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 图像处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数字图像 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>高斯混合模型</title>
      <link href="/2020/03/24/%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B/"/>
      <url>/2020/03/24/%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><h2 id="Gaussion-Distribution"><a href="#Gaussion-Distribution" class="headerlink" title="Gaussion Distribution"></a>Gaussion Distribution</h2><p>首先复习一下高斯分布：</p><script type="math/tex; mode=display">N(x,\mu,\sigma) = \frac{1}{\sqrt {2\pi\sigma}}\exp(-\frac{(x-\mu)^2}{2\sigma^2})</script><p>用高斯分布估计数据分布是有很大的局限的，它一定对称，只有一个峰值，这些使得它再估计真实数据时表现很乏力，因此引入了高斯混合模型。</p><h2 id="Gaussion-Mixture-Model"><a href="#Gaussion-Mixture-Model" class="headerlink" title="Gaussion Mixture Model"></a>Gaussion Mixture Model</h2><p>顾名思义，高斯混合模型就是很多个高斯模型混合在一起</p><p><a href="https://user-images.githubusercontent.com/60562661/77444240-92dd2300-6e26-11ea-8243-7ddad8a9cd80.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/77444240-92dd2300-6e26-11ea-8243-7ddad8a9cd80.png" class="lazyload"></a></p><p>如图，黑色的分布就是下面彩色高斯分布混合而成。实际上就是很多高斯的加权和：</p><script type="math/tex; mode=display">p(x) = \sum_{k=1}^K W_k*g_k(x|\mu_k,\sigma_k)</script><p>其中，</p><ul><li><p>g_k表示第k个高斯分布，具体公式就是上面列的高斯分布公式；</p></li><li><p>w_k是它的权重系数，因此满足：</p></li></ul><script type="math/tex; mode=display">W_k>0 \space\space\space\space\space\space\space\space\space\space\sum_{k=1}^K W_k = 1</script></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Gaussion Mixture Model </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>softmax函数详解</title>
      <link href="/2020/03/23/softmax%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3/"/>
      <url>/2020/03/23/softmax%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><h2 id="softmax-作用"><a href="#softmax-作用" class="headerlink" title="softmax 作用"></a>softmax 作用</h2><p><code>softmax</code> 函数一般用在分类场景，尤其是多分类，它接受一组任意值作为输入，然后输出对应的一组<strong>0-1</strong>之间的数值，并且加起来为1，也就是做了归一化，实际上输出的值代表概率值。</p><h2 id="softmax-计算方式"><a href="#softmax-计算方式" class="headerlink" title="softmax 计算方式"></a>softmax 计算方式</h2><p><a href="https://user-images.githubusercontent.com/60562661/77334644-0e27d180-6d60-11ea-9844-be15700132e4.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/77334644-0e27d180-6d60-11ea-9844-be15700132e4.png" class="lazyload"></a></p><p>如上图，z1,z2,z3 作为输入，分别取<code>exp</code>, 然后加起来作为分母，分别的除以分母就得到对应的值。即zi的softmax值为：</p><script type="math/tex; mode=display">S_{z_i} = \frac{\exp(z_i)}{\sum_{j=1}^3 \exp(z_j)  }</script><p>推广一下：</p><script type="math/tex; mode=display">S_{z_i} = \frac{ \exp(z_i)}{\sum_{j} \exp(z_j)  }</script><p>其中，$\sum<em>{i} S</em>{z_i} = 1$</p><h2 id="再看交叉熵"><a href="#再看交叉熵" class="headerlink" title="再看交叉熵"></a>再看交叉熵</h2><p>对于二分类问题，交叉熵函数为：</p><script type="math/tex; mode=display">L = \hat{y_i}*\ln {y_i} + (1-\hat{y_i})*\ln{(1- y_i)}</script><p>对于多分类问题：</p><script type="math/tex; mode=display">L = -\hat{y}*\ln(y)</script><p>其中，$\hat{y}$表示label，y表示预测的值，由softmax函数计算得到</p><h2 id="softmax求导"><a href="#softmax求导" class="headerlink" title="softmax求导"></a>softmax求导</h2><p>上面已经知道多分类时交叉熵的公式，预测第i个时，认为它的label是1，则：</p><script type="math/tex; mode=display">L_i = -\ln(y_i)</script><p>则：</p><script type="math/tex; mode=display">\frac{\partial L_i}{\partial i} = -\frac{\partial{\ln(y_i)}}{\partial i} = \frac{\partial \ln (\frac{e^i}{\sum_j e^j})}{\partial i} =··· ···=y_i-1</script><p>具体推导如下图：</p><p><a href="https://user-images.githubusercontent.com/60562661/77334662-14b64900-6d60-11ea-9b3d-beca92583e36.png" data-fancybox="group" data-caption="undefined" class="fancybox"><img style="zoom:70%;" data-src="https://user-images.githubusercontent.com/60562661/77334662-14b64900-6d60-11ea-9b3d-beca92583e36.png" class="lazyload"></a></p><hr><p>以上便是softmax函数的相关知识了。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> softmax </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch常用的几个操作</title>
      <link href="/2020/03/21/pytorch%E5%B8%B8%E7%94%A8%E7%9A%84%E5%87%A0%E4%B8%AA%E5%87%BD%E6%95%B0/"/>
      <url>/2020/03/21/pytorch%E5%B8%B8%E7%94%A8%E7%9A%84%E5%87%A0%E4%B8%AA%E5%87%BD%E6%95%B0/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><p>目前写的工程遇到这些比较多，后面再丰富。</p><h2 id="Pytorch保存模型、载入模型"><a href="#Pytorch保存模型、载入模型" class="headerlink" title="Pytorch保存模型、载入模型"></a>Pytorch保存模型、载入模型</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># save model</span></span><br><span class="line">model = LSTM_Cycle().cuda()</span><br><span class="line">path = <span class="string">'./models_new/lstm_'</span> + <span class="string">'epoch_'</span> + str(epoch) +<span class="string">'Iteration_'</span> + str(i)+<span class="string">'_.pth'</span></span><br><span class="line">torch.save(model.state_dict(), path)</span><br><span class="line"></span><br><span class="line"><span class="comment"># load model</span></span><br><span class="line">model = test.demo_model.LSTM_Cycle_Test()</span><br><span class="line">pre_train = torch.load(<span class="string">'./models_correct/lstm_epoch_9Iteration_240_.pth'</span>)</span><br><span class="line">model.load_state_dict(pre_train)</span><br><span class="line">model.cuda()</span><br></pre></td></tr></tbody></table></figure></div><h2 id="查看pytorch张量"><a href="#查看pytorch张量" class="headerlink" title="查看pytorch张量"></a>查看pytorch张量</h2><p>tensor不能直接看，一般会转换为numpy看：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(tensor.cpu().detach().numpy())</span><br></pre></td></tr></tbody></table></figure></div><p>这里有一个技巧就是一般tensor输出中间是省略号，若想看全部的tensor数据，则如下操作：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">np.set_printoptions(threshold=np.inf)</span><br><span class="line">print(tensor.cpu().detach().numpy())</span><br></pre></td></tr></tbody></table></figure></div><h2 id="忽略pytorch警告"><a href="#忽略pytorch警告" class="headerlink" title="忽略pytorch警告"></a>忽略pytorch警告</h2><p>pytorch版本不同会有很多警告，会比较烦，在代码开头加上如下代码即可忽略：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">warnings.filterwarnings(<span class="string">"ignore"</span>)</span><br></pre></td></tr></tbody></table></figure></div><h2 id="pytorch-指定多GPU-训练"><a href="#pytorch-指定多GPU-训练" class="headerlink" title="pytorch 指定多GPU 训练"></a>pytorch 指定多GPU 训练</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 多个gpu</span></span><br><span class="line">os.environ[<span class="string">"CUDA_VISIBLE_DEVICES"</span>] = <span class="string">"0,1"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 单 gpu</span></span><br><span class="line">os.environ[<span class="string">"CUDA_VISIBLE_DEVICES"</span>] = <span class="string">"0"</span></span><br></pre></td></tr></tbody></table></figure></div><h2 id="Pytorch数据标准化"><a href="#Pytorch数据标准化" class="headerlink" title="Pytorch数据标准化"></a>Pytorch数据标准化</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"></span><br><span class="line">transform = transforms.Compose([</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize(mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>],</span><br><span class="line">                             std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>]),</span><br><span class="line">    ])</span><br><span class="line">    </span><br><span class="line">input = transform(input).unsqueeze(<span class="number">0</span>).permute(<span class="number">0</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>) <span class="comment"># 维度变换</span></span><br></pre></td></tr></tbody></table></figure></div></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch编程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>图像仿射变换后的坐标求解</title>
      <link href="/2020/03/21/%E5%9B%BE%E5%83%8F%E4%BB%BF%E5%B0%84%E5%8F%98%E6%8D%A2%E5%90%8E%E7%9A%84%E5%9D%90%E6%A0%87%E6%B1%82%E8%A7%A3/"/>
      <url>/2020/03/21/%E5%9B%BE%E5%83%8F%E4%BB%BF%E5%B0%84%E5%8F%98%E6%8D%A2%E5%90%8E%E7%9A%84%E5%9D%90%E6%A0%87%E6%B1%82%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><p>我是做人体姿态估计的方向，在姿态估计中有必不可少的 一步，就是坐标变换。最直观的从原始不规则图像变换到45<em>45（或者其他）尺寸的<code>heatmap</code>，原始图像的人体关键点的坐标就需要做相应的变换才可以生成正确的新的坐标，从而生成正确的<em>*heatmap</em></em>。</p><p>而这一问题看似很容易，却是在一直困扰着我，我在做的项目里这一问题一直没彻底解决，而今天经过反复测试找到一个比较合适的实现方案，实现由原图变换到heatmap，heatmap解出原坐标。下面进入正文。</p><h2 id="简单的坐标变换"><a href="#简单的坐标变换" class="headerlink" title="简单的坐标变换"></a>简单的坐标变换</h2><p>首先，图像直接resize变换，是可以直接用坐标除以比例得到新的坐标。注意直接用<code>cv2.resize()</code>图像可能会发生形变，如下图：</p><p><a href="https://user-images.githubusercontent.com/60562661/77230391-cf164680-6bce-11ea-94da-3979ac3883c7.jpg" data-fancybox="group" data-caption="d" class="fancybox"><img alt="d" title="d" data-src="https://user-images.githubusercontent.com/60562661/77230391-cf164680-6bce-11ea-94da-3979ac3883c7.jpg" class="lazyload"></a></p><p>这是我1280<em>720图像直接resize到 368\</em>368的结果，红点是在原始图像画上去的，resize后到了上图中，上图中绿色的圈圈(下面的)则是经过简单的坐标计算：</p><script type="math/tex; mode=display">ratio_{width} = width / 368\\ratio_{height} = height / 368\\x' = x / ratio_{width} \\y' = y / ratio_{height}</script><h2 id="仿射变换"><a href="#仿射变换" class="headerlink" title="仿射变换"></a>仿射变换</h2><p>仿射变换（Affine Transformation或 Affine Map）是二维情况下坐标之间的变换。它保持了二维图形的“平直性”（即：直线经过变换之后依然是直线）和“平行性”（即：二维图形之间的相对位置关系保持不变，平行线依然是平行线，且直线上点的位置顺序不变）。</p><p>数学上，仿射变换就是用2*3的变换矩阵来计算。</p><p>仿射变换可以写为如下的形式：<code>(x,y)为原始坐标 （x',y'）为变换后的坐标</code></p><script type="math/tex; mode=display">\left\{\begin{aligned}x'& = ax + by + m\\y'& = cx + dy + n\end{aligned}\right.</script><p>矩阵计算比较常用，可以写为：</p><script type="math/tex; mode=display">\begin{bmatrix}{u}\\{v}\\\end{bmatrix} = \begin{bmatrix}{a_2}&{a_1}&{a_0}\\{b_2}&{b_1}&{b_0}\\\end{bmatrix} *\begin{bmatrix}{x}\\{y}\\{1}\end{bmatrix}</script><p>也就是简单的新的坐标 = 变换矩阵 * 原始坐标。而在姿态估计中，GT坐标都是三维，第三维为0胡总和1.1表示坐标正确，0表示不可信。因此很容易用仿射变换来求解变换后的坐标。</p><p>仿射变换是一系列原子操作组合而成，平移、缩放、旋转、反转、错切 。这些操作组合可以完成各种变换。</p><h2 id="姿态估计中的坐标变换"><a href="#姿态估计中的坐标变换" class="headerlink" title="姿态估计中的坐标变换"></a>姿态估计中的坐标变换</h2><p>姿态估计中自上而下的方法，需要先从原图把每个人切出来，然后切出来的图片一般要变换成正方形，然后再缩放到对应的<code>heatmap</code>尺寸，一般是(64*64)。所以上面提到的直接求比例是行不通的。</p><p>如果用常规方法去做，会非常麻烦，因为不只是需要<code>heatmap</code>的时候进行变换，再最后预测出heatmap后，依然需要求出坐标而且变换到原图。我之前都是直接做，所以一直出错。而如果借助仿射变换，这件事就很容易了。我借助的别人一个函数，来求仿射矩阵，变换图像；同时由heatmap反求坐标变换到原始图像。代码在我的工具类可以看到。下面看一下我的测试结果：</p><hr><p><strong><1> 原始图像</strong>（忽略上面的蓝色点，是我刚开始求出的错误的）：</p><p><a href="https://user-images.githubusercontent.com/60562661/77230393-d178a080-6bce-11ea-81fe-dec05a0c4d61.jpg" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/77230393-d178a080-6bce-11ea-81fe-dec05a0c4d61.jpg" class="lazyload"></a></p><p><strong><2> 裁剪后的图像以及坐标变换</strong>：</p><p><a href="https://user-images.githubusercontent.com/60562661/77230395-d2113700-6bce-11ea-80f6-a92bd30fe478.jpg" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/77230395-d2113700-6bce-11ea-80f6-a92bd30fe478.jpg" class="lazyload"></a></p><p>可以看出计算出的坐标是正确的。</p><p><strong><3> 裁剪后的图像关键点生成heatmap再反变换到原始图像：</strong></p><p><a href="https://user-images.githubusercontent.com/60562661/77230396-d2a9cd80-6bce-11ea-869f-9fcc65abbb34.jpg" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/77230396-d2a9cd80-6bce-11ea-869f-9fcc65abbb34.jpg" class="lazyload"></a></p><p><strong>可以看出是正确的坐标了。</strong></p><h2 id="踩坑"><a href="#踩坑" class="headerlink" title="踩坑"></a>踩坑</h2><p>在上面<2>中，手动求坐标就是一开始提到公式，这里有两个坑：</p><ul><li><code>新的坐标 = 变换矩阵 * 原始坐标</code>  , 我之前这一步错在用原始坐标 去乘 变换矩阵，不懂原理嘛。</li><li>这里的乘法是正式的矩阵乘法，用numpy实现就是：<code>np.dot(M,a)</code> , 这样算出来的就是二维坐标，即 (x,y),我之前这里也错了，如果直接用 M <em> a就是对应位置相乘，得到的是 2</em>3形状的矩阵。</li><li>还有就是以前求不对变换矩阵，后面需要就直接调用即可</li></ul><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">new_coordinates = np.dot(trans_final, coordinates)</span><br></pre></td></tr></tbody></table></figure></div><p><strong>有个心得，就是在做姿态估计准备训练模型前，先试几组坐标变换看对不对在做后面的事。</strong></p><p>至此，困扰很久的坐标问题终于得到解决！</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 仿射变换 </tag>
            
            <tag> 坐标 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Attention方法</title>
      <link href="/2020/03/19/Attention%E6%96%B9%E6%B3%95/"/>
      <url>/2020/03/19/Attention%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><h2 id="Attention背景"><a href="#Attention背景" class="headerlink" title="Attention背景"></a>Attention背景</h2><p>RNN循环神经网络，具有一定的记忆性，但是有一个固有的缺点就是不能并行运算，要算后一个必须就要先算出前一个。显示提出了CNN假设，用CNN替代RNN，此时已经可以并行计算，但是CNN必要有很多层才可以看更长时间的东西。</p><p>因此出现了Attention这种方法，成为RNN的代替方案。</p><p><a href="https://user-images.githubusercontent.com/60562661/77137835-82394f80-6aaa-11ea-8142-cb7137e2d776.png" data-fancybox="group" data-caption="1584675106927" class="fancybox"><img alt="1584675106927" style="zoom:67%;" title="1584675106927" data-src="https://user-images.githubusercontent.com/60562661/77137835-82394f80-6aaa-11ea-8142-cb7137e2d776.png" class="lazyload"></a></p><h2 id="计算流程"><a href="#计算流程" class="headerlink" title="计算流程"></a>计算流程</h2><h3 id="计算出-Q-K-V"><a href="#计算出-Q-K-V" class="headerlink" title="计算出 Q,K,V"></a>计算出 Q,K,V</h3><p>首先输入x计算出a，a分别乘上三个矩阵得到q，k，v。</p><p><a href="https://user-images.githubusercontent.com/60562661/77137839-85344000-6aaa-11ea-9891-181565f8ac57.png" data-fancybox="group" data-caption="1584675959648" class="fancybox"><img alt="1584675959648" title="1584675959648" data-src="https://user-images.githubusercontent.com/60562661/77137839-85344000-6aaa-11ea-9891-181565f8ac57.png" class="lazyload"></a></p><script type="math/tex; mode=display">q_i = W_q *a_i,\space \space k_i = w_k*a_i,\space \space v_i = w_v*a_i</script><ul><li>其中q表示query，查询，也就是用来做匹配；</li><li>k表示key，是被匹配的对象；</li><li>v表示value，是要被抽取出来的信息</li></ul><h3 id="用每个q对k做Attention"><a href="#用每个q对k做Attention" class="headerlink" title="用每个q对k做Attention"></a>用每个q对k做Attention</h3><p><a href="https://user-images.githubusercontent.com/60562661/77137840-85ccd680-6aaa-11ea-8081-dd2b4e99974d.png" data-fancybox="group" data-caption="1584676364224" class="fancybox"><img alt="1584676364224" style="zoom: 50%;" title="1584676364224" data-src="https://user-images.githubusercontent.com/60562661/77137840-85ccd680-6aaa-11ea-8081-dd2b4e99974d.png" class="lazyload"></a></p><script type="math/tex; mode=display">\alpha_{1,i} = q_1 \cdot k_i / \sqrt d</script><p>其中，q和k做内积除以它们的维度。d是q和k的维度。这个注意力计算公式也可以是其他的。</p><p><a href="https://user-images.githubusercontent.com/60562661/77137842-86656d00-6aaa-11ea-9d05-84d9f9eff4ab.png" data-fancybox="group" data-caption="1584676778515" class="fancybox"><img alt="1584676778515" style="zoom:67%;" title="1584676778515" data-src="https://user-images.githubusercontent.com/60562661/77137842-86656d00-6aaa-11ea-9d05-84d9f9eff4ab.png" class="lazyload"></a></p><p>其中<code>α</code>经过<code>softmax</code>层得到<code>α帽</code></p><p><a href="https://user-images.githubusercontent.com/60562661/77137843-87969a00-6aaa-11ea-969f-6ce4068b99d4.png" data-fancybox="group" data-caption="1584676981736" class="fancybox"><img alt="1584676981736" style="zoom:67%;" title="1584676981736" data-src="https://user-images.githubusercontent.com/60562661/77137843-87969a00-6aaa-11ea-969f-6ce4068b99d4.png" class="lazyload"></a></p><p>α帽和相应的v做一个加权和得到b，即：</p><script type="math/tex; mode=display">b_1 =\sum_i \hat a_{1,i} * v_i</script><p>此时，b1就已经考虑了整个的次序。</p><p>b2,b3,b4流程和b1一模一样，即：</p><script type="math/tex; mode=display">b_j =\sum_i \hat a_{j,i} * v_i</script><p>并且是可以并行计算的。</p><h3 id="并行运算细节"><a href="#并行运算细节" class="headerlink" title="并行运算细节"></a>并行运算细节</h3><p><a href="https://user-images.githubusercontent.com/60562661/77137844-882f3080-6aaa-11ea-8749-5761729c56ba.png" data-fancybox="group" data-caption="1584677516392" class="fancybox"><img alt="1584677516392" title="1584677516392" data-src="https://user-images.githubusercontent.com/60562661/77137844-882f3080-6aaa-11ea-8749-5761729c56ba.png" class="lazyload"></a></p><p>首先是Q，K，V三个矩阵，把a堆起来乘以w矩阵得到Q矩阵，K,V类似，这就可以同时计算。</p><p><a href="https://user-images.githubusercontent.com/60562661/77137847-88c7c700-6aaa-11ea-9972-ed2c8c284444.png" data-fancybox="group" data-caption="1584677805635" class="fancybox"><img alt="1584677805635" title="1584677805635" data-src="https://user-images.githubusercontent.com/60562661/77137847-88c7c700-6aaa-11ea-9972-ed2c8c284444.png" class="lazyload"></a></p><p>把k堆起来乘以q可以得到α，经过softmax得到α帽。</p><p><a href="https://user-images.githubusercontent.com/60562661/77137849-89605d80-6aaa-11ea-8687-b6b9d8dbb332.png" data-fancybox="group" data-caption="1584677978747" class="fancybox"><img alt="1584677978747" title="1584677978747" data-src="https://user-images.githubusercontent.com/60562661/77137849-89605d80-6aaa-11ea-8687-b6b9d8dbb332.png" class="lazyload"></a></p><p>此时把v堆起来，就可以计算得出b1，b2，b3，b4.堆起来就是最后的输出。</p><h3 id="位置信息"><a href="#位置信息" class="headerlink" title="位置信息"></a>位置信息</h3><p>此时Attention其实是没有考虑时间次序的，因为q对每一个k都会做Attention，不管远近都会做，所以时序信息是没有考虑进去的。</p><p><a href="https://user-images.githubusercontent.com/60562661/77137851-89f8f400-6aaa-11ea-98b8-fb9eeb63f627.png" data-fancybox="group" data-caption="1584678717485" class="fancybox"><img alt="1584678717485" title="1584678717485" data-src="https://user-images.githubusercontent.com/60562661/77137851-89f8f400-6aaa-11ea-98b8-fb9eeb63f627.png" class="lazyload"></a></p><p>此时只要给ai加上一个ei矩阵即可。</p><p><a href="https://user-images.githubusercontent.com/60562661/77137852-8a918a80-6aaa-11ea-9ae6-ab692a30e297.png" data-fancybox="group" data-caption="1584678784655" class="fancybox"><img alt="1584678784655" title="1584678784655" data-src="https://user-images.githubusercontent.com/60562661/77137852-8a918a80-6aaa-11ea-9ae6-ab692a30e297.png" class="lazyload"></a></p><p>此时可以解释为给输入xi拼上了一个onehot向量，用来代表是哪个输入，然后得到上面的式子。</p><p>这只是大概讲了一下 Attention怎么计算，具体的NLP中怎么应用可以深究一下，但我不是做NLP的，所以大概了解就可以。</p><p><strong>不求甚解如我。关于封面，Attention顾名思义，注意力，所以封面更能体现Attention。</strong></p></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Attention </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>均值与期望</title>
      <link href="/2020/03/19/%E5%9D%87%E5%80%BC%E4%B8%8E%E6%9C%9F%E6%9C%9B/"/>
      <url>/2020/03/19/%E5%9D%87%E5%80%BC%E4%B8%8E%E6%9C%9F%E6%9C%9B/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><p>在深度学习经常会听到期望这个词，而且总觉得与均值差不多，在这里记录一下做一个区分。</p><ul><li>平均数是一个统计学概念</li><li>期望则是一个概率论概念</li></ul><p>平均数是根据实验结果统计的样本的平均值，期望则是实验前根据样本概率分布预测样本的平均值。</p><p>之所以说“预测”是因为在实验前能得到的期望与实际实验得到的样本的平均数总会不可避免地存在偏差，毕竟随机实验的结果永远充满着不确定性。如果我们能进行无穷次随机实验并计算出其样本的平均数的话，那么这个平均数其实就是期望。当然实际上根本不可能进行无穷次实验，但是实验样本的平均数会随着实验样本的增多越来越接近期望，就像频率随着实验样本的增多会越来越接近概率一样。</p><p><code>如果说概率是频率随样本趋于无穷的极限，那么期望就是平均数随样本趋于无穷的极限。</code></p></body></html>]]></content>
      
      
      <categories>
          
          <category> Math </category>
          
          <category> 概率论 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数学期望 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>似然估计-Likelyhood</title>
      <link href="/2020/03/19/%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1-Likelyhood/"/>
      <url>/2020/03/19/%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1-Likelyhood/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><p>参考：<a href="https://zhuanlan.zhihu.com/p/36824006" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/36824006</a></p><h2 id="概率-Probability-amp-似然-Likelyhood"><a href="#概率-Probability-amp-似然-Likelyhood" class="headerlink" title="概率 (Probability) & 似然 (Likelyhood)"></a>概率 (Probability) & 似然 (Likelyhood)</h2><p>概率就是随机事件发生的可能性的度量，根据实验或者已知的模型来计算某种可能性，可以称之为<strong>概率。</strong></p><p>似然则是已经知道数据结果分布，由结果来推测模型的参数，这个过程就是<strong>似然。</strong></p><p>所以这两个过程大概上是相反的。似然更通俗的说就是给定样本$X = x$下参数 $\theta = \theta_1$相对于参数取另外的值$\theta = \theta_2$为真实值的可能性。</p><h2 id="似然函数"><a href="#似然函数" class="headerlink" title="似然函数"></a>似然函数</h2><p>设模型参数为θ，则：</p><script type="math/tex; mode=display">L(\theta|x) = P(X=x|\theta)</script><p>也就是说估计θ值使得实验结果X=x。</p><p>对于某一实验，我们可能包含多种情况，其中每个实验结果的概率可记为一个集合 ：</p><script type="math/tex; mode=display">P = \{p_1,p_2,p_3,...p_n\} \  (\sum_{i=1}^np_i = 1)</script><p>假设做了m次实验，则实验结果出现概率为：</p><script type="math/tex; mode=display">E = \prod_{l=2}^mp_k,\space p_k \in P</script><h2 id="极大似然估计"><a href="#极大似然估计" class="headerlink" title="极大似然估计"></a>极大似然估计</h2><p>似然函数L最大化时就是极大似然估计。极大似然估计因为是连乘，所以一般是取log之后变为求和，然后再去求最大值，具体可以参考文章开始提到的链接中的抓豆子实验，很形象。</p><h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><p>在深度学习中，用神经网络作分类问题实际上也就是建立了一个模型，这个模型的参数(w)就相当于似然估计中的参数θ，用大量的数据去学习，去调整w，也就是已经知道结果，由结果去估计参数(w),使得取参数w后可以更准确的估计真实数据概率。也就是在做最大似然估计，而最大似然估计已经证明就是最小化交叉熵。</p><p><strong>所以极大似然估计就是根据经验来推断规律。</strong></p></body></html>]]></content>
      
      
      <categories>
          
          <category> Math </category>
          
          <category> 概率论 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> likelyhood </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux下常用命令</title>
      <link href="/2020/03/19/Hello,World/"/>
      <url>/2020/03/19/Hello,World/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><h2 id="Linux-Ubuntu-操作指令"><a href="#Linux-Ubuntu-操作指令" class="headerlink" title="Linux(Ubuntu) 操作指令"></a>Linux(Ubuntu) 操作指令</h2><p>记录一下我自己在Linux下常用的操作指令，会一直更新。</p><h3 id="Python环境、库安装"><a href="#Python环境、库安装" class="headerlink" title="Python环境、库安装"></a>Python环境、库安装</h3><p><strong>source activate HPEG_PT</strong>      激活虚拟环境</p><p> <strong>mkvirtualenv</strong>     创建虚拟环境</p><p><strong>conda create -n NEW_Nmae python=3.6</strong>      conda创建虚拟环境</p><p><strong>conda install pytorch=0.4.0 torchvision cudatoolkit=9.0 -c pytorch</strong>       安装pytorch</p><p><strong>pip install tensorflow-gpu==1.12</strong>  安装任意版本tensorflow</p><p><strong>pip install -i <a href="https://pypi.tuna.tsinghua.edu.cn/simple" target="_blank" rel="noopener">https://pypi.tuna.tsinghua.edu.cn/simple</a> numpy(指定的库)</strong>    pip使用清华镜像安装库，不能翻墙可提高下载速度</p><hr><h3 id="程序监控、进程"><a href="#程序监控、进程" class="headerlink" title="程序监控、进程"></a>程序监控、进程</h3><p><strong>htop F4 f9 9 Enter</strong>   杀死某个指定进程</p><ul><li>htop 打开任务监视器</li></ul><p><strong>watch -n 1 nvidia-smi</strong>          查看显卡使用情况，每隔一秒刷新一次情况</p><p> <strong>nohup python -u train.py &>nohup.out&</strong>  命令调到后台执行，并且输出信息写到<code>nohup.out</code>文件中，这个很有用，操作服务器时本地窗口可以关掉不影响服务器运行</p><h3 id="Net-网络相关"><a href="#Net-网络相关" class="headerlink" title="Net 网络相关"></a>Net 网络相关</h3><hr><p><strong>ifconfig -a</strong>          查看ip地址、端口等网络相关信息</p><p><strong>ssh jion@1.tcp.cpolar.cn -p 20279</strong>  ssh远程连接 ssh username@ip -p(端口)</p><p><strong>服务器文件与本地同步</strong></p><p>复制到本地：   <strong>scp -r -P 端口号  用户名@ip:服务器文件夹地址/ /本地文件夹地址/</strong></p><p>复制到服务器    <strong>scp  -P 端口号 文件  用户名@ip:服务器文件夹地址/</strong></p><p>eg: </p><p><strong>scp -r -P 20279 jion@1.tcp.cpolar.cn:/media/jion/D/chenhaoming/DataSet/DouYin/images/dance.zip D:/Server</strong></p></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch、numpy中的shape和size</title>
      <link href="/2020/03/18/pytorch-numpt%E4%B8%AD%E7%9A%84shape%E5%92%8Csize/"/>
      <url>/2020/03/18/pytorch-numpt%E4%B8%AD%E7%9A%84shape%E5%92%8Csize/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><p>每次在获得图片尺寸时我都会写错，因此来记录一下shape、size。</p><h2 id="Pytorch"><a href="#Pytorch" class="headerlink" title="Pytorch"></a>Pytorch</h2><p><code>.size()</code>是方法(function),可以传参数，例如：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"> c = torch.randn(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line"><span class="comment"># c</span></span><br><span class="line"><span class="comment">#tensor([[ 1.4753, -0.5479, -0.4448],</span></span><br><span class="line"><span class="comment">#        [ 0.1452,  0.9948,  0.1481]])</span></span><br><span class="line">c.size(<span class="number">0</span>)</span><br><span class="line"><span class="comment">#2</span></span><br><span class="line">c.size(<span class="number">1</span>)</span><br><span class="line"><span class="comment">#3</span></span><br><span class="line">c.size[<span class="number">0</span>]</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">"<stdin>"</stdin></span>, line <span class="number">1</span>, <span class="keyword">in</span> <module></module></span><br><span class="line">TypeError: <span class="string">'builtin_function_or_method'</span> object <span class="keyword">is</span> <span class="keyword">not</span> subscriptable</span><br><span class="line">c.size[<span class="number">1</span>]</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">"<stdin>"</stdin></span>, line <span class="number">1</span>, <span class="keyword">in</span> <module></module></span><br><span class="line">TypeError: <span class="string">'builtin_function_or_method'</span> object <span class="keyword">is</span> <span class="keyword">not</span> subscriptable</span><br></pre></td></tr></tbody></table></figure></div><p><code>.shape则是属性</code></p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">c.shape</span><br><span class="line"><span class="comment"># torch.Size([2, 3])</span></span><br><span class="line">c.shape(<span class="number">0</span>)</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">"<stdin>"</stdin></span>, line <span class="number">1</span>, <span class="keyword">in</span> <module></module></span><br><span class="line">TypeError: <span class="string">'torch.Size'</span> object <span class="keyword">is</span> <span class="keyword">not</span> callable</span><br><span class="line">c.shape[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># 2</span></span><br><span class="line">c.shape[<span class="number">1</span>]</span><br><span class="line"><span class="comment"># 3</span></span><br><span class="line">type(c.shape)</span><br><span class="line"><<span class="class"><span class="keyword">class</span> '<span class="title">torch</span>.<span class="title">Size</span>'></span></span><br></pre></td></tr></tbody></table></figure></div><p>故如果是torch的张量，在需要调用图像尺寸时，应该写：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">c.size(<span class="number">0</span>)</span><br><span class="line">c.size(<span class="number">1</span>)</span><br><span class="line"><span class="comment">#或者</span></span><br><span class="line">c.shape[<span class="number">0</span>]</span><br><span class="line">c.shape[<span class="number">1</span>]</span><br></pre></td></tr></tbody></table></figure></div><h2 id="Numpy"><a href="#Numpy" class="headerlink" title="Numpy"></a>Numpy</h2><p>numpy中，<code>.size()</code>是属性，用来输出元素个数 </p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">a = np.array([<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">a</span><br><span class="line"><span class="comment">#array([2, 3])</span></span><br><span class="line">a.size</span><br><span class="line"><span class="comment">#2</span></span><br><span class="line">a.size()</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">"<stdin>"</stdin></span>, line <span class="number">1</span>, <span class="keyword">in</span> <module></module></span><br><span class="line">TypeError: <span class="string">'int'</span> object <span class="keyword">is</span> <span class="keyword">not</span> callable</span><br><span class="line"><span class="meta">>>> </span>a.size(<span class="number">0</span>)</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">"<stdin>"</stdin></span>, line <span class="number">1</span>, <span class="keyword">in</span> <module></module></span><br><span class="line">TypeError: <span class="string">'int'</span> object <span class="keyword">is</span> <span class="keyword">not</span> callable</span><br></pre></td></tr></tbody></table></figure></div><p><code>.shape</code>也是属性</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">a.shape(<span class="number">0</span>)</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">"<stdin>"</stdin></span>, line <span class="number">1</span>, <span class="keyword">in</span> <module></module></span><br><span class="line">TypeError: <span class="string">'tuple'</span> object <span class="keyword">is</span> <span class="keyword">not</span> callable</span><br><span class="line"><span class="meta">>>> </span>a.shape</span><br><span class="line">(<span class="number">2</span>,)</span><br><span class="line"><span class="meta">>>> </span>a.shape[<span class="number">0</span>]</span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="meta">>>> </span>a.shape[<span class="number">1</span>]</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">"<stdin>"</stdin></span>, line <span class="number">1</span>, <span class="keyword">in</span> <module></module></span><br><span class="line">IndexError: tuple index out of range</span><br></pre></td></tr></tbody></table></figure></div><p>故如果是numpy类型的数组，获取图片尺寸应用：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a.shape[<span class="number">0</span>]</span><br><span class="line">a.shape[<span class="number">1</span>]</span><br></pre></td></tr></tbody></table></figure></div><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><ul><li><p><strong>torch</strong>的<strong>Tensor</strong>形状可以用<code>size</code>，也可以用<code>shape</code>；</p></li><li><p><strong>numpy</strong>则只用<code>shape</code></p></li></ul></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch编程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习实践</title>
      <link href="/2020/03/18/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5/"/>
      <url>/2020/03/18/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><p>这里是自己实现过的深度学习代码，放上github地址：</p><p><a href="https://github.com/tzwx/DeepLearning" target="_blank" rel="noopener">https://github.com/tzwx/DeepLearning</a></p><p><strong>会不断更新代码。</strong></p><h4 id="1-Cartoon-GAN"><a href="#1-Cartoon-GAN" class="headerlink" title="1. Cartoon_GAN"></a><strong>1. Cartoon_GAN</strong></h4><p>实现简单的GAN网络，生成动漫头像，这是DC-GAN的原型。</p><p><a href="https://user-images.githubusercontent.com/60562661/75624471-56cfed00-5bef-11ea-9518-2a8b9e6fc747.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/75624471-56cfed00-5bef-11ea-9518-2a8b9e6fc747.png" class="lazyload"></a></p><p><strong>网络结构：</strong></p><p><a href="https://user-images.githubusercontent.com/60562661/78143357-bc1e3480-7460-11ea-9e86-843fb4f922bb.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/78143357-bc1e3480-7460-11ea-9e86-843fb4f922bb.png" class="lazyload"></a></p><p><strong>遗留的问题：</strong></p><ul><li>关于反卷积，padding等参数设置现在依然未搞清楚</li></ul><h4 id="2-Regression"><a href="#2-Regression" class="headerlink" title="2. Regression"></a><strong>2. Regression</strong></h4><p>一个简单的回归案例，用到了<code>Adagrad</code>算法。原理可以看<a href="https://huaqi.blue/2020/02/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%B3%BB%E5%88%97%E4%B8%80-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95-%E2%91%A1/#%E4%BB%A3%E7%A0%81%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E7%BB%86%E8%8A%82">梯度下降法2</a> 这篇文章。</p><p><strong>3. Back Propagation</strong></p><p>手动实现一个简单的反向传播BP算法，理清楚原理之后发现就是矩阵的连乘。具体原理可以参考<a href="https://huaqi.blue/2020/02/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%B3%BB%E5%88%974-%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%ADBP%E7%AE%97%E6%B3%95/">反向传播bp算法</a>这篇文章。</p><h4 id="4-My-Tools"><a href="#4-My-Tools" class="headerlink" title="4. My Tools"></a><strong>4. My Tools</strong></h4><p>实用工具类，我自己最常用的工具，包括图像、视频、姿态估计、可视化相关。</p><p><strong>已实现功能：</strong></p><ul><li><p>[x] 视频分解成图片</p></li><li><p>[x] 图片合成视频</p></li><li><p>[x] 图片裁剪</p></li><li><p>[x] 热图得到坐标</p></li><li><p>[x] 坐标生成热图</p></li><li><p>[x] 2D关键点可视化</p></li><li><p>[x] Json文件读写</p></li></ul><p><strong>5. LSTM Cycle网络</strong></p><p>利用CycleLoss进行人体姿态估计。以下是大致的网络结构。</p><p><a href="https://user-images.githubusercontent.com/60562661/78142337-62693a80-745f-11ea-95c6-f06f129805fb.jpg" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/78142337-62693a80-745f-11ea-95c6-f06f129805fb.jpg" class="lazyload"></a></p><p><a href="https://user-images.githubusercontent.com/60562661/78142373-701ec000-745f-11ea-96f6-394ceabc5730.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/78142373-701ec000-745f-11ea-96f6-394ceabc5730.png" class="lazyload"></a></p><p>LSTM_Cycle <strong>项目情况</strong></p><ul><li><p>项目初衷是做弱监督下的人体姿态估计，但是事实上并不是弱监督，事实上训练弱监督效果太差，一方面是idea本身比较弱，另一方面则可能是代码的问题，我也不知道是哪方面原因。</p></li><li><p>这个项目是我做的第一个比较完整的项目，从0开始手撸，未用到现在任何的经典卷积网络，都是自己搭建起来的。</p></li><li><p>但是现在由于种种原因可能要放弃了，所以在这里来记录一下原理，防止遗忘。</p></li></ul></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 编程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GAN_4 f-GAN推导</title>
      <link href="/2020/03/15/GAN-4-f-GAN%E6%8E%A8%E5%AF%BC/"/>
      <url>/2020/03/15/GAN-4-f-GAN%E6%8E%A8%E5%AF%BC/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><h2 id="为什么要引入f-GAN？"><a href="#为什么要引入f-GAN？" class="headerlink" title="为什么要引入f-GAN？"></a>为什么要引入f-GAN？</h2><p>之前谈到GAN基础理论，可以知道GAN的生成器其实就是在最小化 <strong>P_data</strong> 和 <strong>P_G</strong> 的 JS散度。而事实上不一定要用<code>JS-Divergence</code> 来测量，<strong>KL-Divergence、JS-Divergence</strong>等都是属于<strong>f-Divergence</strong>，故f-GAN其实就是想要换掉GAN中的分布之间的距离测度函数。</p><h2 id="f-Divergence"><a href="#f-Divergence" class="headerlink" title="f-Divergence"></a>f-Divergence</h2><script type="math/tex; mode=display">D_f(P||Q) = \int_x q(x)*f(\frac{p(x)}{q(x)})dx</script><p>其中，f是<code>convex凸函数</code>, f(1) = 0，故：<br><a href="https://user-images.githubusercontent.com/60562661/76704169-fb831c00-6711-11ea-94ea-6a4b4879e385.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/76704169-fb831c00-6711-11ea-94ea-6a4b4879e385.png" class="lazyload"></a></p><p>其中<code>>=</code>用到了詹森不等式.</p><ul><li>若p(x),q(x)相等，则值为0；</li><li>若其不相等，则<strong>Df>=0</strong>  因此 Df可以用来测量分布之间的距离</li></ul><p><a href="https://user-images.githubusercontent.com/60562661/76704155-ee662d00-6711-11ea-8e2e-17e4da092990.png" data-fancybox="group" data-caption="1584260831145" class="fancybox"><img alt="1584260831145" style="zoom:67%;" title="1584260831145" data-src="https://user-images.githubusercontent.com/60562661/76704155-ee662d00-6711-11ea-8e2e-17e4da092990.png" class="lazyload"></a></p><p>此时f(x)取不同的表达式，得到不同的散度。</p><h2 id="共轭函数"><a href="#共轭函数" class="headerlink" title="共轭函数"></a>共轭函数</h2><p><a href="https://user-images.githubusercontent.com/60562661/76704159-f1f9b400-6711-11ea-9639-528670025d24.png" data-fancybox="group" data-caption="1584260962776" class="fancybox"><img alt="1584260962776" style="zoom: 80%;" title="1584260962776" data-src="https://user-images.githubusercontent.com/60562661/76704159-f1f9b400-6711-11ea-9639-528670025d24.png" class="lazyload"></a></p><p>每一个凸函数<code>f</code>都有一个共轭函数<code>f*</code></p><p>对于函数f(x),</p><ul><li>首先t取t1，x取遍定义域内所有的值x1…xn,找出最大的$f^*(t1) = x_1t_1-f(x)$</li><li>对于每一个t都用相同的方法计算，就可以知道最终的f*</li></ul><p>这样计算太麻烦，于是：</p><p><a href="https://user-images.githubusercontent.com/60562661/76704161-f32ae100-6711-11ea-8892-daa86908a963.png" data-fancybox="group" data-caption="1584261338486" class="fancybox"><img alt="1584261338486" title="1584261338486" data-src="https://user-images.githubusercontent.com/60562661/76704161-f32ae100-6711-11ea-8892-daa86908a963.png" class="lazyload"></a></p><p>如上图，画出所有的函数图像，取得图像上界即可。</p><p><a href="https://user-images.githubusercontent.com/60562661/76704163-f4f4a480-6711-11ea-840f-774ec211ec48.png" data-fancybox="group" data-caption="1584280774347" class="fancybox"><img alt="1584280774347" title="1584280774347" data-src="https://user-images.githubusercontent.com/60562661/76704163-f4f4a480-6711-11ea-840f-774ec211ec48.png" class="lazyload"></a></p><p>当$f(x) = x\log(x)$时，求的其共轭函数为：$f^*(t) = exp(t-1)$</p><h2 id="Connection-with-GAN"><a href="#Connection-with-GAN" class="headerlink" title="Connection with GAN"></a>Connection with GAN</h2><p><a href="https://user-images.githubusercontent.com/60562661/76704164-f58d3b00-6711-11ea-9e3f-aa670f1f3445.png" data-fancybox="group" data-caption="1584281621663" class="fancybox"><img alt="1584281621663" title="1584281621663" data-src="https://user-images.githubusercontent.com/60562661/76704164-f58d3b00-6711-11ea-9e3f-aa670f1f3445.png" class="lazyload"></a></p><p>这块的逻辑是这样：</p><ul><li>首先 f(x) 于 f* 互为共轭函数，故可以有第一行的公式，然后把它代入D中，得到上图中得第三行的公式，目前问题变为：找一个t，使得这个积分项最大；</li><li>直接找t不好找，所以训练一个判别器D，输入是x，输出是t，D(x) = t,便得到上图下部分得公式，所以问题又转化为寻找一个D，可以最大两个积分项做减法得值</li><li>简单来说，就是把寻找t变为寻找D(x)</li></ul><p><a href="https://user-images.githubusercontent.com/60562661/76704165-f756fe80-6711-11ea-8701-537bbba1819e.png" data-fancybox="group" data-caption="1584282526678" class="fancybox"><img alt="1584282526678" title="1584282526678" data-src="https://user-images.githubusercontent.com/60562661/76704165-f756fe80-6711-11ea-8701-537bbba1819e.png" class="lazyload"></a></p><p>这里就很顺理成章了，P_data 和 P_G 之间的f-divergence就可以求出来了;<strong>而D(x)、f*()取不同的表达式 ，得到的就是不同的f-divergence。</strong></p><p>对于生成器来说，就是最小化真实数据和生成数据之间的<code>f-divergence</code></p><p><a href="https://user-images.githubusercontent.com/60562661/76704167-f9b95880-6711-11ea-9b66-0b6a6fb6e0ca.png" data-fancybox="group" data-caption="1584284110315" class="fancybox"><img alt="1584284110315" title="1584284110315" data-src="https://user-images.githubusercontent.com/60562661/76704167-f9b95880-6711-11ea-9b66-0b6a6fb6e0ca.png" class="lazyload"></a></p><p>其中，Generator f(u) 就是上面公式中的D(x)表达式；f<em>(t)就是上面公式的 f\</em>.</p><p>以上就是f-GAN得数学推导过程。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GAN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Auto Encoder in DeepLearning</title>
      <link href="/2020/03/06/Auto-Encoder-in-DeepLearning/"/>
      <url>/2020/03/06/Auto-Encoder-in-DeepLearning/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><p>VAE部分公式推导省略的可以观看李宏毅老师的课：<a href="https://www.bilibili.com/video/av9770190?p=18" target="_blank" rel="noopener">https://www.bilibili.com/video/av9770190?p=18</a></p><h2 id="Back-Ground"><a href="#Back-Ground" class="headerlink" title="Back Ground"></a>Back Ground</h2><p>首先自编码器的意义是什么呢？</p><p>以CV举例，在影像处理中，人脸识别一张普通的200<em>200像素的图，就有40000维向量要处理，显然不实际，因此如果可以有一个编码器可以输入一张图，输出一个30维的向量；再将这个30维向量输出成200\</em>200的图，尽量与原图接近。也就是说30维的向量代表了40000维的图，并且尽量保持图片特征、不失真，这就是自编码器的应用。</p><h2 id="Auto-Encoder"><a href="#Auto-Encoder" class="headerlink" title="Auto Encoder"></a>Auto Encoder</h2><p>最初的 Auto Encoder设计结构如下图：</p><p><a href="https://user-images.githubusercontent.com/60562661/76104292-15d04200-600e-11ea-8aee-705cbc26107b.jpg" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/76104292-15d04200-600e-11ea-8aee-705cbc26107b.jpg" class="lazyload"></a></p><p>只要让输出尽可能的接近输入即可，然后改造成深度自编码器，如下：</p><p><a href="https://user-images.githubusercontent.com/60562661/76104294-1668d880-600e-11ea-825c-53ce6dd24f79.jpg" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/76104294-1668d880-600e-11ea-825c-53ce6dd24f79.jpg" class="lazyload"></a></p><p>loss依然是最初的。这便是<code>Auto Encoder</code></p><h2 id="Problem-in-Auto-Encoder"><a href="#Problem-in-Auto-Encoder" class="headerlink" title="Problem in Auto Encoder"></a>Problem in Auto Encoder</h2><p>首先，Auto Encoder存在一个问题，它把所有训练的图片都是对应到了一个高维空间中的一个点，可以这么理解，本来图像是40000维空间的一个点，经过编码变成30维空间的一个点，如果采样正好采了这个点，则可以比较精确的用解码器还原图像；但是如果在30维空间中，采样到了一个从未训练过的点，那么解码器就大概率只会解码出一堆噪音，如下图：</p><p><a href="https://user-images.githubusercontent.com/60562661/76104295-17016f00-600e-11ea-9845-bc047ffaeb5e.jpg" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/76104295-17016f00-600e-11ea-9845-bc047ffaeb5e.jpg" class="lazyload"></a></p><p>如果采样到 code中间未训练过的点，解码出来的图像就不像是一张真实图像，会是一堆乱码，而VAE做的事情就是每张图片不在是对应一个点，而是一个区间，在这个区间内都可以解码出这张图片，如下图：</p><p><a href="https://user-images.githubusercontent.com/60562661/76104298-179a0580-600e-11ea-8905-cd6403150473.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/76104298-179a0580-600e-11ea-8905-cd6403150473.png" class="lazyload"></a></p><p>这就引入了VAE.</p><h2 id="Variance-Auto-Encoder-VAE"><a href="#Variance-Auto-Encoder-VAE" class="headerlink" title="Variance Auto Encoder(VAE)"></a>Variance Auto Encoder(VAE)</h2><p>先看一下VAE的整体架构：</p><p><a href="https://user-images.githubusercontent.com/60562661/76104300-18329c00-600e-11ea-97d8-8040afde0995.png" data-fancybox="group" data-caption="1583506317352" class="fancybox"><img alt="1583506317352" title="1583506317352" data-src="https://user-images.githubusercontent.com/60562661/76104300-18329c00-600e-11ea-97d8-8040afde0995.png" class="lazyload"></a></p><p>首先是输入经过一个编码器，产生一组m，一组σ，然后一组e是从高斯分布采样的，即：</p><script type="math/tex; mode=display">m_i+\exp(\sigma_i)+e_i = c_i</script><p>也就是原始编码加上噪音，而σ则是控制噪音的方差，即$\exp(\sigma_i)$就是噪音的方差，是自动学习的；同时损失函数在原来的基础上，加上了上图右下角一项。</p><p>直观上，如果不加限制的让机器自己去学习，那么机器肯定会认为噪音对原图像干扰越小越好，于是会给exp(σ)赋值为0或者很接近0的数，但是这也就失去了意义。因此加上这一项，$\exp(\sigma_i)-(1+\sigma_i)$的最小值在σ=0时得到最小值，也就是说σ=0loss最小，此时方差=1,所以机器自己学习就不会让Variance太小；$m_i^2$可以认为是L2正则化。这就是直观上VAE这样设计的原理，下面从数学上理解VAE的原理。</p><h2 id="VAE的原理"><a href="#VAE的原理" class="headerlink" title="VAE的原理"></a>VAE的原理</h2><p>首先，我们的工作任务是可以采样到需要的图像，也就是要估计原始图像的概率分布P(X),如果知道了原始图像的分布，那么我们只要让我们的生成的图像分布尽量接近原始图像也就是计算它们的KL散度即可。所以为题转化为求P(X).</p><p>高斯混合模型认为，任何一个分布都可以由多种高斯分布混合(加权和)而成。则此时；</p><script type="math/tex; mode=display">P(X) =\sum_m P(m)*P(x|m)\\x|m\approx N(\mu_m,\sigma_m)</script><p>这件事更像是对图像做了一个分类，我们所看到的x都来自于某一类，这是不好的，更好的方法应该是用一个向量来表示图像。</p><p>则此时引出了z，z是一个隐向量，是服从高斯分布的；向量的每一个维度对应图像的某一些特征。<strong>注意，这里之所以z取高斯分布，是因为逻辑上说，没有特色的东西占多数，图像每种属性的分布其实大概率是服从高斯分布的，因此z取高斯分布也是比较合理的，但是z可以是任何分布。</strong></p><p>同时，z有无穷多个，是连续的，不再是高斯混合模型那样有固定个z；每一个z对应的均值μ、方差σ都是由神经网络学来的。</p><p>所以此时，</p><script type="math/tex; mode=display">P(X) =\int_z P(z)*P(X|z)dz\\P(z)\approx N(0,1)\\X|z\approx N(\mu(z),\sigma(z))</script><p>真正要求的就是μ(z)、σ(z)，最大化P(X):</p><script type="math/tex; mode=display">L = \sum_X\log P(X)</script><p><a href="https://user-images.githubusercontent.com/60562661/76104281-11a42480-600e-11ea-9576-56fff9f9fc18.png" data-fancybox="group" data-caption="1583509685308" class="fancybox"><img alt="1583509685308" title="1583509685308" data-src="https://user-images.githubusercontent.com/60562661/76104281-11a42480-600e-11ea-9576-56fff9f9fc18.png" class="lazyload"></a></p><p>所以，此时z经过一个伸进和网络输出均值和方差，目的是最大化L；这时候需要引入另外一个分布q(z|x),也就是输入图像，提取它的高斯分布；所以，上图中蓝色的就是<strong>Decoder</strong>，绿色的就是<strong>Encoder</strong>。然后继续用数学推导：</p><p><strong>注意以下公式推导有跳步，具体可以看一下李宏毅老师的视频讲解。</strong></p><script type="math/tex; mode=display">\log P(x) = \int_z q(z|x)\log P(x)dz = \int_zq(z|x)\log\frac{P(z,x)}{q(z|x)}dz+KL(q(z|x)||p(z|x))</script><p>其中，KL散度一项大于等于0，故前面的一项就是$\log P(x)$的下限(lower bound).这个下限记为Lb:</p><script type="math/tex; mode=display">L_b=\int_zq(z|x)\log\frac{P(z,x)}{q(z|x)}dz=\int_zq(z|x)\log\frac{P(z)*P(x|z)}{q(z|x)}dz</script><p>则原式化作:</p><script type="math/tex; mode=display">\log P(x) = L_b + KL(q(z|x)||p(z|x))</script><p><strong>这里就真正的体现了VAE的精妙之处：</strong></p><p>本来是要寻找P(x|z)来最大化L，但是现在需要同时寻找P(x|z)、q(z|x)两项，来最大化Lb，从而最大化L。</p><p>q分布实际上与 <code>log P(x)</code> 是无关的，log P(x)至于P分布有关。所以q无论取什么值，log P(x) 都不变，如下图：</p><p><a href="https://user-images.githubusercontent.com/60562661/76104286-149f1500-600e-11ea-9125-d9cd58c1fa8f.png" data-fancybox="group" data-caption="1583510884527" class="fancybox"><img alt="1583510884527" title="1583510884527" data-src="https://user-images.githubusercontent.com/60562661/76104286-149f1500-600e-11ea-9125-d9cd58c1fa8f.png" class="lazyload"></a></p><p>所以当P固定，q最大化Lb时，KL会越来越小，最后消失不见，也就是q(z|x)和p(z|x)的分布完全相同，此时在上升下限，Likelyhood也会最大化。<strong>所以也就是说损失函数中实际起作用的就是Lb这一项。</strong></p><p>所以此时，就是寻找P(x|z)、q(z|x)最大化Lb来最大化似然估计，同时顺便会找到q(z|x)相似于p(z|x)。</p><script type="math/tex; mode=display">L_b=\int_zq(z|x)\log\frac{P(z,x)}{q(z|x)}dz = -KL(q(z|x)||P(z))+\int_zq(z|x)\log P(x|z)dz</script><p>此时最大化Lb，也就是要最小化q(z|x)和P(z)的相似度，其中q是一个神经网络，用来提取输入x所服从的高斯分布，所以这里最小化的散度就是要调节q所对应的神经网络，让它产生的高斯分布与z这个高斯分布越接近越好，最小化散度这一项可以推导为：</p><script type="math/tex; mode=display">KL(q(z|x)||P(z)) = \sum_{i=1}^3(\exp(\sigma_i)-(1+\sigma_i)+(m_i)^2)</script><p>这就是文章一开始提到的VAE架构中新增的需要最小化的损失函数。</p><p>而Lb另外一项积分也要最大化，即：</p><script type="math/tex; mode=display">\max \space \int_zq(z|x)\log P(x|z)dz</script><p>直观上就是从q中采样一个z分布，使得在在z分布下采样到的x的概率越大越好。这实际上就是Auto Encoder在做的事情。</p><p><a href="https://user-images.githubusercontent.com/60562661/76104288-1537ab80-600e-11ea-805b-f8f4c316caa4.png" data-fancybox="group" data-caption="1583512456046" class="fancybox"><img alt="1583512456046" title="1583512456046" data-src="https://user-images.githubusercontent.com/60562661/76104288-1537ab80-600e-11ea-805b-f8f4c316caa4.png" class="lazyload"></a></p><p>通俗的描述一下，就是说，首先q会从输入图像x中采样出一个(Normal Distribution )z,然后要最大化z分布产生x的概率，就是会把z作为NN的输入，输出一组高斯分布，使得这个高斯分布产生x的概率最大 。所以现在就是如何让这组高斯产生的x概率最大。</p><p>实际上在训练时，我们不会取考虑方差，只需要让Decoder输出的均值<strong>(mean)μ=x(Input)</strong>即可，因为高斯分布在均值μ处采样的可能性最大，所以只需要让x=μ即可。<strong>也就是说这一部分就是让输入的x与输出尽可能的接近。</strong></p><p><strong>同时，因为Encoder和Decoder的输出3都是一组分布，即现在图片对应的是一个分布，所以也就解决了把图片对应到了一个点上的问题，也就解决了Auto Encoder的存在的问题。</strong></p><p>所以Lb这两项合起来，就是文章一开始提到的VAE的两个损失函数。所以说VAE就精妙在损失函数的设计上面。</p><p><strong>妙哉妙哉！</strong></p></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> VAE </tag>
            
            <tag> Auto Encoder </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>概率论的贝叶斯公式</title>
      <link href="/2020/03/06/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%85%AC%E5%BC%8F/"/>
      <url>/2020/03/06/%E6%A6%82%E7%8E%87%E8%AE%BA%E7%9A%84%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%85%AC%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><p>概率论是深度学习的基础，但是我发现已经忘记了概率论中很多知识，所以复习了一下，做一下记录，也算是想起一些以前疑惑的东西。</p><p>关于贝叶斯与全概率，</p><p>数学上张宇讲的比较透彻，也比较容易理解：<a href="https://www.bilibili.com/video/av9735632?p=5" target="_blank" rel="noopener">https://www.bilibili.com/video/av9735632?p=5</a></p><p>但是可以从另外一个给人启发的角度看待：<a href="https://www.bilibili.com/video/av84799361" target="_blank" rel="noopener">https://www.bilibili.com/video/av84799361</a></p><h2 id="互斥与独立"><a href="#互斥与独立" class="headerlink" title="互斥与独立"></a>互斥与独立</h2><ul><li><code>两个事件互斥 == 两个事件互不相容</code> , 这一点可以从几何关系理解，也就是说两个集合没有交集；</li><li>两个事件独立则是从概率的角度来讲的，举一个简单的公式，若A、B事件互相独立，则：</li></ul><script type="math/tex; mode=display">P(AB) = P(A) * P(B)</script><p>然后由条件概率可以知道，在A发生的条件下，B发生的概率为：</p><script type="math/tex; mode=display">P(B|A) = \frac {P(AB)}{P(A)}\\P(AB) = P(A)*P(B|A)</script><p>若AB事件独立，可以推出</p><script type="math/tex; mode=display">P(B) = P(B|A)</script><p><strong>通俗来说，就是B发生的概率与在A发生的条件下B发生的概率相同，也就是A事件发生并不影响B，这就是AB相互独立。</strong></p><p>这两者其实是没什么关系的，不用刻意去区分这两个概念。</p><h2 id="贝叶斯公式"><a href="#贝叶斯公式" class="headerlink" title="贝叶斯公式"></a>贝叶斯公式</h2><p>数学上理解，贝叶斯公式就是条件概率，执果索因：</p><script type="math/tex; mode=display">P(H|E) = \frac {P(H)P(E|H)}{P(E)} = \frac{P(H)P(E|H)}{P(H)P(E|H)+P(\neg H)P(E|\neg H)}</script><p>其中，</p><ol><li><p>P(H)也叫<strong>先验概率</strong>，H常被视为导致试验结果E发生的”原因“</p></li><li><p>P(E|H)也叫似然概率，likelyhood</p></li><li>P(H|E)这个计算出来的概率则成为<strong>后验概率</strong>，当试验产生了结果A之后，再对各种原因概率的新认识，故称后验概率。</li></ol><p>贝叶斯公式给我们的思考是：</p><ul><li><strong>见到所有的证据从而限制了概率空间之后，在考虑比例，这就是贝叶斯公式的精髓</strong></li><li><strong>证据不应该直接决定了你的看法，而是应该更新你的看法</strong></li></ul></body></html>]]></content>
      
      
      <categories>
          
          <category> Math </category>
          
          <category> 概率论 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 贝叶斯 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Recurrent Neural Network(RNN)</title>
      <link href="/2020/03/05/Recurrent-Neural-Network-RNN/"/>
      <url>/2020/03/05/Recurrent-Neural-Network-RNN/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><p>RNN,循环神经网络，一般用来处理序列化任务。例如一个句子就是一个词序列；一段视频就是一个图像序列；人讲一句话也是一个序列，处理序列就考虑到了时间维的信息。</p><h2 id="SIMPLE-RNN"><a href="#SIMPLE-RNN" class="headerlink" title="SIMPLE RNN"></a>SIMPLE RNN</h2><p>最简单的一个<strong>RNN循环神经网络</strong>就是存储了上一时刻的隐藏状态的值。简单的讨论一下RNN的设计结构。</p><p><a href="https://user-images.githubusercontent.com/60562661/75954684-41103f80-5eef-11ea-9846-59ada03ace43.png" data-fancybox="group" data-caption="1583384720030" class="fancybox"><img alt="1583384720030" style="zoom:80%;" title="1583384720030" data-src="https://user-images.githubusercontent.com/60562661/75954684-41103f80-5eef-11ea-9846-59ada03ace43.png" class="lazyload"></a></p><p>假设只有一个隐藏层，有两个句子：</p><ul><li>leave <strong>Taipei</strong></li><li>arrive <strong>Taipei</strong></li></ul><p>如果采用一般的神经网络，见到<strong>Taipei</strong>这同一个词汇，输出的值都是相同的，与预期任务就不符合了。</p><p>首先leave作为第一时刻的输入，产生一个值；隐藏状态值是a1要存储起来，如上图的蓝色a1，然后下一时刻输入<strong>Taipei</strong>就同时收到<code>x2、a1</code> 的影响。后面的也同理，因此同一个输入就有不同的输出。</p><p>上面是一个简单的单向的RNN，还有双向的RNN，如下图：</p><p><a href="https://user-images.githubusercontent.com/60562661/75954689-42da0300-5eef-11ea-8ffc-c46500154632.png" data-fancybox="group" data-caption="1583385188547" class="fancybox"><img alt="1583385188547" style="zoom:67%;" title="1583385188547" data-src="https://user-images.githubusercontent.com/60562661/75954689-42da0300-5eef-11ea-8ffc-c46500154632.png" class="lazyload"></a></p><p>训练一个正向的和一个反向的循环神经网络，然后把同一时刻(xt)两个网络的隐藏层拿出来同时计算该时刻的输出(yt).也就是说计算每一时刻的输出都要考虑到整个序列。</p><h2 id="Long-Short-term-Memory（LSTM）"><a href="#Long-Short-term-Memory（LSTM）" class="headerlink" title="Long Short-term Memory（LSTM）"></a>Long Short-term Memory（LSTM）</h2><p>上面的RNN是一个简单的循环神经网络的结构，它的记忆非常非常有限，只能记住前一个时刻的，这对我们来说仍然是不足的，因此需要记住更久的东西，就有了LSTM。（<strong>注意名字，是多个短期记忆，一般叫长短期记忆网络，应该是很长的短期记忆网络，而不是长-短 期记忆网络。</strong>）</p><p>LSTM网络结构如下：</p><p><a href="https://user-images.githubusercontent.com/60562661/75954691-43729980-5eef-11ea-8dce-c0976f87aa09.png" data-fancybox="group" data-caption="1583385772848" class="fancybox"><img alt="1583385772848" style="zoom:67%;" title="1583385772848" data-src="https://user-images.githubusercontent.com/60562661/75954691-43729980-5eef-11ea-8dce-c0976f87aa09.png" class="lazyload"></a></p><p><strong>它的核心在于中间蓝色部分的记忆细胞。</strong></p><p>它的计算过程观察上图，首先有 $z,z_i,z_f,z_o$ 四个gate，这四个门可以理解为四个控制信号，其中</p><ul><li>$z$ 表示的是要输入的信息的信号；</li><li>$z_i$ 表示的是输入门的信号；</li><li>$z_f$ 表示的是遗忘门的信号；</li><li>$z_o$ 表示的是输出门的信号；</li></ul><script type="math/tex; mode=display">Cell = \sigma(z) * \tanh(z_i) + c * \sigma(z_f)\\Out = \tanh(Cell) * \sigma(z_o)</script><p>其中， $z,z_i,z_f,z_o$的值就是输入$x_t$ 乘上四个矩阵得到的，整个流程如下图：</p><p><a href="https://user-images.githubusercontent.com/60562661/75954692-44a3c680-5eef-11ea-9e4f-8663edfda312.png" data-fancybox="group" data-caption="1583386846200" class="fancybox"><img alt="1583386846200" style="zoom: 80%;" title="1583386846200" data-src="https://user-images.githubusercontent.com/60562661/75954692-44a3c680-5eef-11ea-9e4f-8663edfda312.png" class="lazyload"></a></p><p>细胞贯穿主线，xt的输入得到输出yt嘛，中间经过一系列的组合计算；<strong>注意上图中z其实也是有激活函数的，z激活函数是tanh()</strong>.</p><p>上图只是展示了LSTM计算过程，实际操作时会照以下操作（单个LSTM）：</p><p><a href="https://user-images.githubusercontent.com/60562661/75954698-453c5d00-5eef-11ea-9b2f-872c5c166771.png" data-fancybox="group" data-caption="1583387314831" class="fancybox"><img alt="1583387314831" style="zoom:78%;" title="1583387314831" data-src="https://user-images.githubusercontent.com/60562661/75954698-453c5d00-5eef-11ea-9b2f-872c5c166771.png" class="lazyload"></a></p><p>会把前一时刻的输出值($h<em>{t-1}$)、记忆单元值($c</em>{t-1}$)、这一时刻的输入值 ($x_T$)堆在一起，一起再去计算，堆在一起就是torch中的级联：<code>torch.cat()</code></p><p>在实际训练网络时单个LSTM肯定是不够的，所以需要计算多个的，此时：</p><p><a href="https://user-images.githubusercontent.com/60562661/75954700-45d4f380-5eef-11ea-9a49-40ac10040c87.png" data-fancybox="group" data-caption="1583387631495" class="fancybox"><img alt="1583387631495" style="zoom:90%;" title="1583387631495" data-src="https://user-images.githubusercontent.com/60562661/75954700-45d4f380-5eef-11ea-9a49-40ac10040c87.png" class="lazyload"></a></p><p>横向的都是同一个LSTM，纵向的是堆起来的不同的LSTM模块。</p><p><strong>下面总结一下LSTM模块：</strong></p><p><a href="https://user-images.githubusercontent.com/60562661/75954701-47062080-5eef-11ea-9419-26acce47dc07.png" data-fancybox="group" data-caption="1583387847413" class="fancybox"><img alt="1583387847413" title="1583387847413" data-src="https://user-images.githubusercontent.com/60562661/75954701-47062080-5eef-11ea-9419-26acce47dc07.png" class="lazyload"></a></p><p>这张图实际上前一时刻的细胞状态是没有和输入叠在一起的。以上就是整个LSTM架构，而它的几个变体都是大同小异。</p><h2 id="Why-Lstm-not-Simple-RNN"><a href="#Why-Lstm-not-Simple-RNN" class="headerlink" title="Why Lstm not Simple-RNN?"></a>Why Lstm not Simple-RNN?</h2><p>RNN基础模型一般不是很容易训练起来，面临梯度弥散、梯度爆炸的问题。</p><p> <a href="https://user-images.githubusercontent.com/60562661/75954702-479eb700-5eef-11ea-9372-eca219db0d1c.png" data-fancybox="group" data-caption="1583388071831" class="fancybox"><img alt="1583388071831" style="zoom: 80%;" title="1583388071831" data-src="https://user-images.githubusercontent.com/60562661/75954702-479eb700-5eef-11ea-9372-eca219db0d1c.png" class="lazyload"></a></p><p>如图，绿色的线条是实验的RNN的loss，它震荡不收敛。造成这个的原因在于<strong>Error Surface is rough：</strong></p><p><a href="https://user-images.githubusercontent.com/60562661/75954705-48374d80-5eef-11ea-9842-0f01ffaf2a53.png" data-fancybox="group" data-caption="1583388245860" class="fancybox"><img alt="1583388245860" style="zoom:80%;" title="1583388245860" data-src="https://user-images.githubusercontent.com/60562661/75954705-48374d80-5eef-11ea-9842-0f01ffaf2a53.png" class="lazyload"></a>**</p><p>如图，如果梯度下降法刚好更新到断层上，此时梯度骤升，学习率比较大就会飞出去很远，就直接没有了</p><p><a href="https://user-images.githubusercontent.com/60562661/75954707-48cfe400-5eef-11ea-86fd-f8fe8c1ab044.png" data-fancybox="group" data-caption="1583388353972" class="fancybox"><img alt="1583388353972" style="zoom:80%;" title="1583388353972" data-src="https://user-images.githubusercontent.com/60562661/75954707-48cfe400-5eef-11ea-86fd-f8fe8c1ab044.png" class="lazyload"></a></p><p>这就很直观的解释了原因，每次RNN都会用前一次的输出不加控制的影响下一个结果，也就是护送每次都hi把Memory的值完全变化掉。w是指数级就很容易有<code>Gradient Vanish(explore)</code> 的问题。</p><p>而LSTM，</p><ul><li><p>它把Memory的值<em>一个值+input\</em>一个值更新到Cell中，也就是说它的Memory和input是相加的；</p></li><li><p>如果weight影响到记忆细胞的值，则一直会存在，除非遗忘门决定遗忘。而RNN则会一直洗掉。因此LSTM解决了梯度弥散问题。</p></li><li><p>一般遗忘门经常要开着，bias要比较大。</p></li></ul></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RNN </tag>
            
            <tag> LSTM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>卷积、反卷积图像尺寸计算</title>
      <link href="/2020/03/02/%E5%8D%B7%E7%A7%AF%E3%80%81%E5%8F%8D%E5%8D%B7%E7%A7%AF%E5%9B%BE%E5%83%8F%E5%B0%BA%E5%AF%B8%E8%AE%A1%E7%AE%97/"/>
      <url>/2020/03/02/%E5%8D%B7%E7%A7%AF%E3%80%81%E5%8F%8D%E5%8D%B7%E7%A7%AF%E5%9B%BE%E5%83%8F%E5%B0%BA%E5%AF%B8%E8%AE%A1%E7%AE%97/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><p>一般在设计深度网络架构时，神经网络中无非也就是卷积层和全连接层，而网络一般会对图像尺寸有限制，卷积改变图像的尺寸比较重要，需要会计算。因此来计算一下卷积和反卷积的尺寸计算。以<code>pytorch</code>为例.</p><h2 id="Convolution"><a href="#Convolution" class="headerlink" title="Convolution"></a>Convolution</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.Conv2D(in_channels,out_channels,kernel_size,stride,padding,bias)</span><br><span class="line"><span class="comment">#以上几个参数比较常用</span></span><br></pre></td></tr></tbody></table></figure></div><p>卷积操作后图像计算尺寸为：</p><script type="math/tex; mode=display">W_{out} = \frac {W_{input} - W_{filter} + 2*padding}{stride + 1}</script><script type="math/tex; mode=display">H_{out} = \frac {H_{input} - H_{filter} + 2*padding}{stride + 1}</script><ul><li>一般情况下，均为正方形，即<code>W = H</code></li><li>如果计算结果不是正数，则向下取整</li></ul><h2 id="Deconvolution"><a href="#Deconvolution" class="headerlink" title="Deconvolution"></a>Deconvolution</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.ConvTranspose2D(in_channels, out_channels, kernel_size, stride, padding,  output_padding，bias)</span><br><span class="line"><span class="comment"># 其中，padding是输入图片补0个数，output_padding是输出图像补0个数</span></span><br><span class="line"><span class="comment"># 直观上是扩大图片，边上填充0也可以用来扩大图像</span></span><br></pre></td></tr></tbody></table></figure></div><p>反卷积图像尺寸计算公式：</p><script type="math/tex; mode=display">W_{out} = (W_{input} - 1)*stride + Padding_{output} - 2*Padding_{input} + W_{Kernelsize}</script><script type="math/tex; mode=display">H_{out} = (H_{input} - 1)*stride + Padding_{output} - 2*Padding_{input} + H_{Kernelsize}</script><p>其中，</p><ul><li>$Padding_{output}$ 指的是<code>ConvTranspose2D</code>这个函数中的<code>output_padding</code> 参数；</li><li>$Padding_{input}$ 指的是上述函数的<code>padding</code> 参数</li></ul></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Resnet 网络分析</title>
      <link href="/2020/03/01/Resnet-%E7%BD%91%E7%BB%9C%E5%88%86%E6%9E%90/"/>
      <url>/2020/03/01/Resnet-%E7%BD%91%E7%BB%9C%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><p>Resnet，网络层数非常深，是比较经典的CNN模型，Rennet实现了很深层次的网络的训练。本文主要讨论一下resnet的核心思想。</p><h2 id="Universal-approximation-theorem"><a href="#Universal-approximation-theorem" class="headerlink" title="Universal approximation theorem"></a>Universal approximation theorem</h2><p>万能近似定理，也称通用近似定理，指的是：一个具有两层的神经网络，即一个隐藏层、一个输出层，理论上就可以模拟任何的函数，无论多复杂的函数都可以，只要神经元数量够多。</p><p>这个可以理解为 每个神经元都是一个线性的函数，<code>w*x+b</code>，但是当很多神经元组合在一起，就可以模拟出曲线，神经元越多，拟合出的曲线也就会越平滑，这里有点类似于微分，认为曲线是无线可切分的，切到最后会近似成直线，反之，无限多个线性函数自然可以拟合出很平滑的曲线。</p><p>但是这只是理论上的，实际上如果真的只采用两层的神经网络，在可行性上就会有很大的问题，比如由于参数量过多可能根本训练不起来。</p><h2 id="Residual-Block"><a href="#Residual-Block" class="headerlink" title="Residual Block"></a>Residual Block</h2><h3 id="退化问题"><a href="#退化问题" class="headerlink" title="退化问题"></a>退化问题</h3><p>首先，一般认为神经网络层数越深，表达能力会越强。但是实际上，随着神经网络层数加深，却可能出现准确率降低，注意不是过拟合，称为退化问题。因此这种网络结构设计主要是解决了退化问题。而这个方法的出现，也意味着 更深的神经网络可以训练起来了。</p><p><a href="https://user-images.githubusercontent.com/60562661/75651146-cba83300-5c92-11ea-89dd-d2079e49198f.png" data-fancybox="group" data-caption="1583123998907" class="fancybox"><img alt="1583123998907" title="1583123998907" data-src="https://user-images.githubusercontent.com/60562661/75651146-cba83300-5c92-11ea-89dd-d2079e49198f.png" class="lazyload"></a></p><p>上图便是残差模块。x是输入，经过中间的隐藏层后不直接输出F(x)，而是输入x两一个分支连接到输出出，最终输出F(x)+x,即：</p><script type="math/tex; mode=display">H(x) = F(x) + x</script><p>因为之前的层表现已经很好了，这个多出来的层的本来的学习目标是：让H(x)=x，也就是说尽量让输出不变，但是实际上很难学习到这一点，所以现在的目标就变成了让<code>F(x)->0</code></p><p>为什么说F(x)趋近于0更好训练呢？(借鉴别人)我认为可以从以下两方面考虑：</p><ul><li>Hidden Layer 权重初始化都在0附近，输出的值自然会比较靠近0，因此可能会更好的训练；</li><li>在该结构中，所有的激活函数都是 <code>RELU</code>, 而relu函数的特性是：小于等于0都置0，这就说明不管怎么样总有一半的概率可以直接置0，不用去计算</li></ul><p><a href="https://user-images.githubusercontent.com/60562661/75651148-ce0a8d00-5c92-11ea-95f6-543f0458f5d1.png" data-fancybox="group" data-caption="1583126154433" class="fancybox"><img alt="1583126154433" title="1583126154433" data-src="https://user-images.githubusercontent.com/60562661/75651148-ce0a8d00-5c92-11ea-95f6-543f0458f5d1.png" class="lazyload"></a></p><p>这张图可以看出来，解决了退化问题后，34层的误差明显低于18层</p><h3 id="梯度弥散"><a href="#梯度弥散" class="headerlink" title="梯度弥散"></a>梯度弥散</h3><p>关于梯度弥散这个问题我纠结了比较久，发现问题在于我把x理解的狭隘了。从数学上理解一下这个问题 ：</p><script type="math/tex; mode=display">X_{l+1} = X_l + F(X_l,W_l)</script><script type="math/tex; mode=display">X_{l+2} = X_{l+1} + F(X_{l+1},W_{l+1}) =X_l + F(X_l,W_l) + F(X_{l+1},W_{l+1})</script><p>故可以推出：</p><script type="math/tex; mode=display">X_L = X_l + \sum_{i=1}^{L-1}F(X_i,W_i)</script><p>此时反向传播计算，假设损失函数是C，此时反向传播要对w求导，就先对后面一个节点求导，然后链式法则再求导W，即：</p><script type="math/tex; mode=display">\frac{\partial C}{\partial X_l} = \frac{\partial C}{\partial X_L}*\frac{\partial X_L}{\partial X_l} =  \frac{\partial C}{\partial X_L}*(1+\frac{\partial}{\partial x} \sum_{i=1}^{L-1}F(X_i,W_i))</script><p>实际上X_l就是一个节点，比如 wx+b，所以对w、b求导就可以求出来了。</p><p>此时梯度里面多了一个1，而正是因为这个1的存在，使得梯度存在，可以很容易回流到千层，也就是说算出浅层 的梯度、更细参数。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GAN3_手动实现网络生成动漫头像</title>
      <link href="/2020/03/01/%E6%89%8B%E5%8A%A8%E5%AE%9E%E7%8E%B0GAN%E7%BD%91%E7%BB%9C%E7%94%9F%E6%88%90%E5%8A%A8%E6%BC%AB%E5%A4%B4%E5%83%8F/"/>
      <url>/2020/03/01/%E6%89%8B%E5%8A%A8%E5%AE%9E%E7%8E%B0GAN%E7%BD%91%E7%BB%9C%E7%94%9F%E6%88%90%E5%8A%A8%E6%BC%AB%E5%A4%B4%E5%83%8F/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><p>学习了GAN的基本原理后，手动实现一个相当于GAN的 <code>hello，world</code> , 具体的工程见：</p><p><a href="https://github.com/tzwx/DeepLearning" target="_blank" rel="noopener">https://github.com/tzwx/DeepLearning</a> </p><p>这里主要分析一下代码逻辑，贴上训练代码。</p><p>写代码的时候发现自己很生疏了，所以总结一下流程</p><p>先上图：训练了69个epoch的结果，设定的时2500epoch</p><p><a href="https://user-images.githubusercontent.com/60562661/75624471-56cfed00-5bef-11ea-9518-2a8b9e6fc747.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/75624471-56cfed00-5bef-11ea-9518-2a8b9e6fc747.png" class="lazyload"></a></p><h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><h3 id="定义网络结构"><a href="#定义网络结构" class="headerlink" title="定义网络结构"></a>定义网络结构</h3><ul><li>判别器就是几个卷积层（Conv）</li><li>生成器则是几个反卷积层（_deConv），最后接一个sigma函数分类</li></ul><h3 id="训练流程"><a href="#训练流程" class="headerlink" title="训练流程"></a>训练流程</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">trans = transforms.Compose(</span><br><span class="line">    [</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize((<span class="number">.5</span>, <span class="number">.5</span>, <span class="number">.5</span>), (<span class="number">.5</span>, <span class="number">.5</span>, <span class="number">.5</span>))</span><br><span class="line">    ]</span><br><span class="line">)</span><br></pre></td></tr></tbody></table></figure></div><h4 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h4><ul><li>数据预处理，数据要先经过以上代码</li><li>定义label，用1表示<strong>realimg</strong>，0表示<strong>fakeimg</strong>，维度就是<code>BATCH_SIZE</code></li><li>获取数据集，循环把100张图作为一个Batch，然后开始训练流程。</li></ul><h4 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h4><ul><li>定义损失函数 <code>BCELoss</code> ，也就是二值的交叉熵</li><li>定义优化器Adam</li><li>定义学习率</li><li>优化器梯度清0</li><li>求得数据输出</li><li>用<code>loss function</code>计算损失loss</li><li>loss 反向传播</li><li>更新参数</li></ul><p>这个训练流程也是分类的流程。</p><h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><p>在训练过程中，判别器loss一直是比较小的(0.1,0.01,…)，而生成器loss很大，(7-11不等)，同时是一个互相博弈的过程，判别器loss减小时，生成器loss增加，反之亦然。</p><p><strong>因为之训练了69个epoch，所以看不到最终的比较优化的结果，最后的结果应该是判别器的loss很大，生成器的loss很小才算训练结束。</strong></p><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># @Time    : 2020/2/29 17:31</span></span><br><span class="line"><span class="comment"># @Author  : FRY--</span></span><br><span class="line"><span class="comment"># @FileName: train.py</span></span><br><span class="line"><span class="comment"># @Software: PyCharm</span></span><br><span class="line"><span class="comment"># @Blog    ：https://fryddup.github.io</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> data_loader <span class="keyword">import</span>  get_img</span><br><span class="line"><span class="keyword">from</span> net.net <span class="keyword">import</span> Generator</span><br><span class="line"><span class="keyword">from</span> net.net <span class="keyword">import</span> Discriminator</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"></span><br><span class="line">BATCH_SIZE = <span class="number">100</span></span><br><span class="line">G_LEARNING_RATE = <span class="number">0.0001</span></span><br><span class="line">D_LEARNING_RATE = <span class="number">0.0001</span></span><br><span class="line">EPOCHS = <span class="number">2500</span></span><br><span class="line"></span><br><span class="line">trans = transforms.Compose(</span><br><span class="line">    [</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize((<span class="number">.5</span>, <span class="number">.5</span>, <span class="number">.5</span>), (<span class="number">.5</span>, <span class="number">.5</span>, <span class="number">.5</span>))</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"><span class="comment"># Instance</span></span><br><span class="line">g = Generator().cuda()</span><br><span class="line">d = Discriminator().cuda()</span><br><span class="line"></span><br><span class="line"><span class="comment"># define loss</span></span><br><span class="line">g_loss = nn.BCELoss() <span class="comment"># Binary crossEntropy</span></span><br><span class="line">d_loss = nn.BCELoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># define optimizer</span></span><br><span class="line">g_optimizer = torch.optim.Adam(g.parameters(),lr=G_LEARNING_RATE)</span><br><span class="line">d_optimizer = torch.optim.Adam(d.parameters(),lr=D_LEARNING_RATE)</span><br><span class="line"></span><br><span class="line"><span class="comment"># define labels</span></span><br><span class="line">label_real = torch.ones(BATCH_SIZE).cuda()</span><br><span class="line">label_fake = torch.zeros(BATCH_SIZE).cuda()</span><br><span class="line"></span><br><span class="line"><span class="comment">#all images</span></span><br><span class="line">images_truth = get_img()</span><br><span class="line">data_length = len(images_truth)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(EPOCHS):</span><br><span class="line">        <span class="comment"># shuffle</span></span><br><span class="line">        np.random.shuffle(images_truth)</span><br><span class="line">        images_real_loader = []</span><br><span class="line">        count = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> index <span class="keyword">in</span> range(data_length):</span><br><span class="line">            count = count + <span class="number">1</span></span><br><span class="line">            images_real_loader.append(trans(images_truth[index]).numpy())</span><br><span class="line">            <span class="comment"># images_real_loader[100,3,96,96]</span></span><br><span class="line">            <span class="keyword">if</span> count == BATCH_SIZE:</span><br><span class="line">                count = <span class="number">0</span> <span class="comment"># reset</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># Train Discriminator</span></span><br><span class="line">                <span class="comment"># train real data to gpu</span></span><br><span class="line">                <span class="comment"># if real -> d(real_img) = 1</span></span><br><span class="line">                images_real_loader_tensor = torch.Tensor(images_real_loader)</span><br><span class="line">                images_real_loader_tensor = images_real_loader_tensor.permute(<span class="number">0</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>).cuda()</span><br><span class="line">                images_real_loader.clear()</span><br><span class="line">                <span class="comment"># graddient _ zero</span></span><br><span class="line">                d_optimizer.zero_grad()</span><br><span class="line">                <span class="comment"># real image output_66</span></span><br><span class="line">                realimage_d = d(images_real_loader_tensor).squeeze() <span class="comment"># descent  [100，1，1，1] -> [100,1]</span></span><br><span class="line">                <span class="comment"># loss</span></span><br><span class="line">                d_realimg_loss = d_loss(realimage_d, label_real)</span><br><span class="line">                <span class="comment"># loss backward</span></span><br><span class="line">                d_realimg_loss.backward()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># train generate data</span></span><br><span class="line">                <span class="comment"># if generator d(generate_img) = 0</span></span><br><span class="line">                images_fake_loader = torch.randn(BATCH_SIZE, <span class="number">100</span>, <span class="number">1</span>, <span class="number">1</span>).cuda()</span><br><span class="line">                <span class="comment"># detach() g no gradient -> fix generator</span></span><br><span class="line">                images_fake_loader_tensor = g(images_fake_loader).detach()</span><br><span class="line">                fakeimg_d = d(images_fake_loader_tensor).squeeze()</span><br><span class="line">                d_fakeimg_loss = d_loss(fakeimg_d, label_fake)</span><br><span class="line">                d_fakeimg_loss.backward()</span><br><span class="line"></span><br><span class="line">                d_optimizer.step()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Train Generator</span></span><br><span class="line">                fake_data = torch.randn(BATCH_SIZE, <span class="number">100</span>, <span class="number">1</span>, <span class="number">1</span>).cuda()</span><br><span class="line">                g_optimizer.zero_grad()</span><br><span class="line">                generator_images = g(fake_data)</span><br><span class="line">                generator_images_score = d(generator_images).squeeze()</span><br><span class="line">                gen_loss = g_loss(generator_images_score, label_real)</span><br><span class="line">                gen_loss.backward()</span><br><span class="line">                g_optimizer.step()</span><br><span class="line"></span><br><span class="line">                print(<span class="string">"Current epoch:%d, Iteration: %d, Discriminator Loss: %f, Generator Loss: %f"</span></span><br><span class="line">                      % (epoch, (index//BATCH_SIZE)+<span class="number">1</span>,</span><br><span class="line">                         (d_realimg_loss+d_fakeimg_loss).detach().cpu().numpy(),</span><br><span class="line">                         gen_loss.detach().cpu().numpy()))</span><br><span class="line"></span><br><span class="line">                torch.save(g, <span class="string">"pkl"</span>+str(epoch)+<span class="string">"generator.pkl"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    train()</span><br></pre></td></tr></tbody></table></figure></div></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GAN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GAN2_Basic_Theory</title>
      <link href="/2020/02/28/GAN-Basic-Theory/"/>
      <url>/2020/02/28/GAN-Basic-Theory/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><p>这篇文章主要来讨论下GAN基础的理论、公式推导。</p><h2 id="KL-散度"><a href="#KL-散度" class="headerlink" title="KL 散度"></a>KL 散度</h2><p><code>KL Divergence</code> 指的是相对熵，其用来衡量两个取值为正的函数或概率分布之间的差异；</p><p><code>相对熵 = 某个策略的交叉熵 - 信息熵（根据系统真实分布计算而得的信息熵，为最优策略）</code>  ,  公式如下:</p><script type="math/tex; mode=display">KL(P || Q) = H(P,Q) - H(P) = \sum_{k=1}^N P_k*log_2\frac {1} {Q_k} - \sum_{k=1}^N P_k*log_2\frac {1} {P_k} = \sum_{k=1}^N P_k*log_2\frac {P_k} {Q_k}</script><p>复习一下，交叉熵是使用非真实分布，信息熵是使用真实分布计算得到的。</p><h2 id="JS-散度"><a href="#JS-散度" class="headerlink" title="JS 散度"></a>JS 散度</h2><p><code>JS Divergence</code>  是 KL散度的变体，衡量两个分布之间的相似性。公式如下：</p><script type="math/tex; mode=display">JS(P||Q) = \frac 1 2 KL(P||\frac{P+Q}{2}) + \frac 1 2 KL(Q||\frac{P+Q}{2})</script><h2 id="Formula-Of-GAN"><a href="#Formula-Of-GAN" class="headerlink" title="Formula Of GAN"></a>Formula Of GAN</h2><p>首先，生成器要做的事情就是生成一个最靠近真实data的分布，这在之前可以用最大似然估计来找这样的一个分布，最大似然估计实际上可以与KL散度扯上关系：</p><p><a href="https://user-images.githubusercontent.com/60562661/75565315-af38aa80-5a88-11ea-9673-fcc477934c05.png" data-fancybox="group" data-caption="1582900061983" class="fancybox"><img alt="1582900061983" style="zoom:80%;" title="1582900061983" data-src="https://user-images.githubusercontent.com/60562661/75565315-af38aa80-5a88-11ea-9673-fcc477934c05.png" class="lazyload"></a></p><p>这里面需要注意的是<strong>约等于</strong> 这一步，意思是最大值求和m笔data的概率其实就是求x服从于真实分布的情况下概率的最大值，所以就 = 下面的积分，而下面的积分后边减去的一项不影响求最大值，所以再意思上是相等的，但是真实值上并不相等。然后上面的公式主要是来说明：</p><p><code>最大化最大似然估计概率就是最小化KL散度</code>，即：</p><script type="math/tex; mode=display">G^* = arg\underset G min Div(P_G,P_{data})</script><p>所以要训练<strong>Generator</strong>，也就是要计算出真实数据和生成数据之间的散度，而<strong>Discriminator</strong>则可以做到这一件事。</p><p>在训练Discriminator时，在固定住Generator的情况下进行，定义对象方程：</p><p><a href="https://user-images.githubusercontent.com/60562661/75565318-afd14100-5a88-11ea-8c7f-a035df1a9034.png" data-fancybox="group" data-caption="1582901609500" class="fancybox"><img alt="1582901609500" title="1582901609500" data-src="https://user-images.githubusercontent.com/60562661/75565318-afd14100-5a88-11ea-8c7f-a035df1a9034.png" class="lazyload"></a></p><p>这里后面一项之所以要定义为1-D(x),是因为判别器做的事情是给Pdata高分，给Pg低分，也就是使得生成的数据和真实的数据分布的散度最大。因此在x服从Pg分布时，写1-D(x) 就可以最大化这个式子，比较容易train，即：</p><script type="math/tex; mode=display">D^* = arg\underset D max V(D,G)</script><p>实际上，当生成的图像和真实图像散度比较大，相似度比较小时，判别器是很好训练的，而相似度比较大就比较难训练，所以训练好的判别器其实就是在最大化生成的图像和真实图像的散度。下面证明这一项就是在最大化JS 散度：</p><p><a href="https://user-images.githubusercontent.com/60562661/75565319-b069d780-5a88-11ea-8f2a-a9497fe42922.png" data-fancybox="group" data-caption="1582902722545" class="fancybox"><img alt="1582902722545" style="zoom: 40%;" title="1582902722545" data-src="https://user-images.githubusercontent.com/60562661/75565319-b069d780-5a88-11ea-8f2a-a9497fe42922.png" class="lazyload"></a></p><p><a href="https://user-images.githubusercontent.com/60562661/75565323-b19b0480-5a88-11ea-9fe5-14395438c926.png" data-fancybox="group" data-caption="1582902806605" class="fancybox"><img alt="1582902806605" style="zoom: 90%;" title="1582902806605" data-src="https://user-images.githubusercontent.com/60562661/75565323-b19b0480-5a88-11ea-9fe5-14395438c926.png" class="lazyload"></a></p><p><a href="https://user-images.githubusercontent.com/60562661/75565327-b2cc3180-5a88-11ea-993a-4992d7b378dd.png" data-fancybox="group" data-caption="1582902903882" class="fancybox"><img alt="1582902903882" style="zoom:90%;" title="1582902903882" data-src="https://user-images.githubusercontent.com/60562661/75565327-b2cc3180-5a88-11ea-993a-4992d7b378dd.png" class="lazyload"></a></p><p><a href="https://user-images.githubusercontent.com/60562661/75565330-b364c800-5a88-11ea-92e3-38aadf080966.png" data-fancybox="group" data-caption="1582902953241" class="fancybox"><img alt="1582902953241" style="zoom:90%;" title="1582902953241" data-src="https://user-images.githubusercontent.com/60562661/75565330-b364c800-5a88-11ea-92e3-38aadf080966.png" class="lazyload"></a></p><p>这里最后一步可以参考一开始文章提到的JS散度对比一下公式就会明白。所以此时：</p><script type="math/tex; mode=display">G^* = arg\underset G min (\space \underset D maxV(D,G))</script><p>此时梯度下降法求解G*:</p><p><a href="https://user-images.githubusercontent.com/60562661/75565333-b495f500-5a88-11ea-83a5-f46a4ee2b53b.png" data-fancybox="group" data-caption="1582904545756" class="fancybox"><img alt="1582904545756" style="zoom: 90%;" title="1582904545756" data-src="https://user-images.githubusercontent.com/60562661/75565333-b495f500-5a88-11ea-83a5-f46a4ee2b53b.png" class="lazyload"></a></p><p>这里的max取微分可以看作分段函数求微分。所以现在已经可以铜鼓哦梯度下降法来更新生成器了，然后进行算法：</p><p><a href="https://user-images.githubusercontent.com/60562661/75565339-b52e8b80-5a88-11ea-8b7c-9caa8bed1e9e.png" data-fancybox="group" data-caption="1582905215369" class="fancybox"><img alt="1582905215369" title="1582905215369" data-src="https://user-images.githubusercontent.com/60562661/75565339-b52e8b80-5a88-11ea-8b7c-9caa8bed1e9e.png" class="lazyload"></a></p><p><strong>这里有一个问题，事实上更新G1参数真的是在减小JS散度吗？</strong></p><p><a href="https://user-images.githubusercontent.com/60562661/75565340-b65fb880-5a88-11ea-8dcd-a5366afdb4bb.png" data-fancybox="group" data-caption="1582905319178" class="fancybox"><img alt="1582905319178" title="1582905319178" data-src="https://user-images.githubusercontent.com/60562661/75565340-b65fb880-5a88-11ea-8dcd-a5366afdb4bb.png" class="lazyload"></a></p><p>举个例子如上图，在G更新后，G的分布已经变了(由左到右)，此时的D0<em>依然是固定的未发生变化，因此此时的D0\</em>已经不再是max值了，因此此时<code>（伪）max V(G,D)</code>  便不再是JS散度了。所以有个假设，G的变化不能太大，每次更新一点点，否则误差会过大。</p><p><strong>以是就是GAN的基础理论公式推导。</strong></p><h2 id="Practice"><a href="#Practice" class="headerlink" title="Practice"></a>Practice</h2><p><a href="https://user-images.githubusercontent.com/60562661/75565341-b6f84f00-5a88-11ea-935e-af64fc9f2ab8.png" data-fancybox="group" data-caption="1582905751928" class="fancybox"><img alt="1582905751928" title="1582905751928" data-src="https://user-images.githubusercontent.com/60562661/75565341-b6f84f00-5a88-11ea-935e-af64fc9f2ab8.png" class="lazyload"></a></p><p>最后整体回顾一遍算法流程：</p><p><a href="https://user-images.githubusercontent.com/60562661/75565342-b8297c00-5a88-11ea-8dd5-6d115ff21f5a.png" data-fancybox="group" data-caption="1582905847010" class="fancybox"><img alt="1582905847010" title="1582905847010" data-src="https://user-images.githubusercontent.com/60562661/75565342-b8297c00-5a88-11ea-8dd5-6d115ff21f5a.png" class="lazyload"></a></p><p><strong>注意的是一般Generator只训练一次 </strong>。原因前面说了 。</p><p>以上就是GAN 对抗网络的 Basic Theory，还有其他的一些之后的细节可以看李宏毅老师的视频。有错误欢迎指正！</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GAN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GAN对抗网络1_初识</title>
      <link href="/2020/02/26/GAN%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C%E5%88%9D%E8%AF%86/"/>
      <url>/2020/02/26/GAN%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C%E5%88%9D%E8%AF%86/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><h2 id="GAN基本原理"><a href="#GAN基本原理" class="headerlink" title="GAN基本原理"></a>GAN基本原理</h2><p>参考链接：<a href="https://www.bilibili.com/video/av24011528?from=search&seid=17842693444993179137" target="_blank" rel="noopener">https://www.bilibili.com/video/av24011528?from=search&seid=17842693444993179137</a></p><p>首先，GAN全称是<strong>Generative Adversarial Nets</strong> ，一般叫对抗网络。由两部分组成：<code>Generator(生成器)</code>、<code>Discrimator(判别器)</code>。</p><ul><li><strong>Generator</strong></li></ul><p>生成器可以认为就是一个<code>Neural Network</code>。以CV为例，现在的目标是生成图片，则生成器的工作就是输入一个vector，然后输出一张图像(动漫头像)，其中某一维可能对应头发长短，另一维对应眼睛颜色，这样通过调整向量就可以控制自己需要的头像，类似于下图：</p><p><a href="https://user-images.githubusercontent.com/60562661/75459614-eccf0200-59ba-11ea-97b2-7606b7c07d8a.png" data-fancybox="group" data-caption="1582812383567" class="fancybox"><img alt="1582812383567" style="zoom: 80%;" title="1582812383567" data-src="https://user-images.githubusercontent.com/60562661/75459614-eccf0200-59ba-11ea-97b2-7606b7c07d8a.png" class="lazyload"></a></p><ul><li><strong>Discrimator</strong></li></ul><p>判别器也是一个<code>Neural Network</code>,  顾名思义，是判断生成器生成的东西的好坏，输入是一张<code>image(动漫头像)</code>, 输出一个<code>scalar(标量，数字)</code> , 衡量生成器生成的image的好坏程度。如下图：</p><p><a href="https://user-images.githubusercontent.com/60562661/75459993-db3a2a00-59bb-11ea-9adb-38203a3cb3c2.png" data-fancybox="group" data-caption="1582813278331" class="fancybox"><img alt="1582813278331" style="zoom:80%;" title="1582813278331" data-src="https://user-images.githubusercontent.com/60562661/75459993-db3a2a00-59bb-11ea-9adb-38203a3cb3c2.png" class="lazyload"></a></p><h3 id="GAN算法流程-Algorithm"><a href="#GAN算法流程-Algorithm" class="headerlink" title="GAN算法流程 Algorithm"></a>GAN算法流程 Algorithm</h3><ol><li>初始化 Generator 、Discrimator</li><li>在每一个迭代中：</li></ol><ul><li>固定生成器，训练判别器，生成器目标是欺骗过判别器，也就是生成器生成的图片判别器给出的分数越高越好</li><li>固定判别器，训练生成器</li><li>重复以上步骤，判别器和生成器在同时进行学习，同时进化，相互博弈，直到生成器能瞒过判别器就算是训练好了</li></ul><h2 id="Structured-Learning"><a href="#Structured-Learning" class="headerlink" title="Structured Learning"></a>Structured Learning</h2><p>结构化学习是很有挑战性的，例如生成图像，很重要的一个东西是像素之间的关系，像素本身是没有什么错误的，但是它们之间的关系很重要。</p><ul><li>Generator 是先画每一个部件，最后形成一幅 image；</li></ul><ul><li>Discrimator 则是整体上判断图像好不好，并且可以挑选出来最好的图像；</li></ul><p>两者结合起来就是GAN对抗网络了，可以发挥各自的性能，如下图：</p><p><a href="https://user-images.githubusercontent.com/60562661/75460000-de351a80-59bb-11ea-9c3f-1378a8ebfa19.png" data-fancybox="group" data-caption="1582815125699" class="fancybox"><img alt="1582815125699" style="zoom:80%;" title="1582815125699" data-src="https://user-images.githubusercontent.com/60562661/75460000-de351a80-59bb-11ea-9c3f-1378a8ebfa19.png" class="lazyload"></a></p><h2 id="Q1-为什么Generator-生成器-不自己学习呢？"><a href="#Q1-为什么Generator-生成器-不自己学习呢？" class="headerlink" title="Q1:为什么Generator(生成器)不自己学习呢？"></a>Q1:为什么Generator(生成器)不自己学习呢？</h2><p>首先生成器是输入一个vector，输出是image，这和<code>Auto Encoder</code> (自编码器)技术中的<code>Decoder(解码器)</code>工作室一样的，也就是说Decoder就是一个Generator。</p><p>Auto Encoder自编码器是有缺陷的，也就是说一张图片只是对应到一个点，从这个点解码出图像，如果取一个没有出现过的点进行解码，解码出来的就是noise了，也就是说只能解码出现过的，因此出现了VAE技术：</p><p><a href="https://user-images.githubusercontent.com/60562661/75460012-e0977480-59bb-11ea-809f-538c06783ee0.png" data-fancybox="group" data-caption="1582815415458" class="fancybox"><img alt="1582815415458" style="zoom:80%;" title="1582815415458" data-src="https://user-images.githubusercontent.com/60562661/75460012-e0977480-59bb-11ea-809f-538c06783ee0.png" class="lazyload"></a></p><p>也就是在编码图像时添加了噪音等，这样采样任何一个点都会解码出来比较真实的图像。在这两种技术中都有<code>Decoder</code>, 那么这种技术缺少了什么？</p><p>对于生成器来说，部件之间的关系很重要，而在解码器中神经元相互之间是没有关系的，也就是部件之间很难产生联系，这就直接导致很容易失去大局观，整体性就比较差。</p><p>关于部件之间的练习，可以看这个例子：</p><p><a href="https://user-images.githubusercontent.com/60562661/75460304-45eb6580-59bc-11ea-9cf3-80dfedd688cc.png" data-fancybox="group" data-caption="1582816190206" class="fancybox"><img alt="1582816190206" style="zoom:80%;" title="1582816190206" data-src="https://user-images.githubusercontent.com/60562661/75460304-45eb6580-59bc-11ea-9cf3-80dfedd688cc.png" class="lazyload"></a></p><p>人眼来判断的话当然觉得下面看两幅图比较好，但是Decoder则会认为上面两幅图比较好，因为逐像素比较确实是前两幅图误差小，这就很容易看出来没有考虑到整体性。事实上Decoder很难做到这一点。</p><h2 id="Q2-为什么Discrimator-判别器-不自己生成呢？"><a href="#Q2-为什么Discrimator-判别器-不自己生成呢？" class="headerlink" title="Q2:为什么Discrimator(判别器)不自己生成呢？"></a>Q2:为什么Discrimator(判别器)不自己生成呢？</h2><p>判别器既然可以判断生成的图像好不好，为什么不自己生成呢？</p><p><a href="https://user-images.githubusercontent.com/60562661/75460313-4a178300-59bc-11ea-963b-f7f8f4e5e992.png" data-fancybox="group" data-caption="1582816859692" class="fancybox"><img alt="1582816859692" title="1582816859692" data-src="https://user-images.githubusercontent.com/60562661/75460313-4a178300-59bc-11ea-963b-f7f8f4e5e992.png" class="lazyload"></a></p><p>还是用上面的例子，比如判别器可能有这样一个卷积核，即中心有颜色其他地方没有，看到这样的就给图像低分，判别器很容易判断图像整体性。</p><p>事实上判别器就像是批评家，比较形象的可以说是<strong>“键盘侠”</strong>，不管你说什么他只给说哪里不好，你要问他什么是好的他可能说不出来这样子。严密的论证可以看文章开始的视频链接讲到的，简单来说就是：</p><ol><li>训练判别器首先不能只是正样本，也需要一些负样本，而我们手上是没有负样本的，因此需要生成负样本</li><li>要产生比较好的负样本就需要一个比较好的判别器才能找到比较好的负样本</li></ol><p>因此，就陷入了鸡生蛋、蛋生鸡的问题。因此训练单独的一个判别器首先要假定已经有比较好的负样本。训练流程类似，可以看视频讲解。</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>总结一下，生成器和判别器各自的优势劣势：</p><p><a href="https://user-images.githubusercontent.com/60562661/75460318-4ab01980-59bc-11ea-9ff5-b426c48d3c76.png" data-fancybox="group" data-caption="1582817820048" class="fancybox"><img alt="1582817820048" title="1582817820048" data-src="https://user-images.githubusercontent.com/60562661/75460318-4ab01980-59bc-11ea-9ff5-b426c48d3c76.png" class="lazyload"></a></p><h2 id="Additional"><a href="#Additional" class="headerlink" title="Additional"></a>Additional</h2><ol><li>上面提到GAN训练时要先训练判别器，这是为什么？后面文章会有公式理论说明这个问题。</li><li>上面提到的 <code>Auto Encoder</code> <code>VAE</code> 这两种编码技术随后文章会详细讨论细节问题。</li></ol></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GAN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Cross Entropy 的前世今生</title>
      <link href="/2020/02/26/Cross-Entropy-%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/"/>
      <url>/2020/02/26/Cross-Entropy-%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><p>Deep Learning 中可以分为分类问题和回归问题，而分类问题也可以转化为回归问题，具体可以看<a href="https://huaqi.blue/2020/02/25/Classification/#%E5%88%86%E7%B1%BB%E4%B8%8E%E5%9B%9E%E5%BD%92%E7%9A%84%E8%BD%AC%E5%8C%96">Classification</a> 这篇文章。回归问题一般用均方误差作为损失函数(显而易见)，而分类问题一般则用交叉熵作为损失函数，这是为什么？这一切要从<strong>信息熵</strong>说起…</p><h2 id="信息熵-amp-交叉熵"><a href="#信息熵-amp-交叉熵" class="headerlink" title="信息熵&交叉熵"></a>信息熵&交叉熵</h2><p><a href="https://www.zhihu.com/question/41252833/answer/195901726" target="_blank" rel="noopener">https://www.zhihu.com/question/41252833/answer/195901726</a> 这篇知乎文章很通俗的解释了交叉熵的概念，总结一下：</p><p>信息论中，使用信息熵来对概率分布进行量化。<strong>信息熵代表的是随机变量或整个系统的不确定性，熵越大，随机变量或系统的不确定性就越大。</strong>根据真实分布，我们能够找到一个最优策略，以最小的代价消除系统的不确定性，而这个代价大小就是信息熵，记住，信息熵衡量了系统的不确定性，而我们要消除这个不确定性，所要付出的【最小努力】（猜题次数、编码长度等）的大小就是信息熵。</p><p>但是并不是每次都知道真实分布，在深度学习中是不知道真实的分布的，这时候就引入交叉熵：<strong>交叉熵，其用来衡量在给定的真实分布下，使用非真实分布所指定的策略消除系统的不确定性所需要付出的努力的大小</strong>。</p><p>交叉熵公式如下：</p><script type="math/tex; mode=display">\sum_{k=1}^Np_k * log_2^{\frac 1q_k}</script><p>其中 <a href="https://www.zhihu.com/equation?tex=p_k" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=p_k" class="lazyload"></a> 表示真实分布， <a href="https://www.zhihu.com/equation?tex=q_k" data-fancybox="group" data-caption="[公式]" class="fancybox"><img alt="[公式]" title="[公式]" data-src="https://www.zhihu.com/equation?tex=q_k" class="lazyload"></a> 表示非真实分布。交叉熵最小值就是采用真实分布预测出来的结果，此时</p><p><code>交叉熵 == 信息熵</code> , 因此在机器学习中要最小化交叉熵，此时就最近真最佳策略。</p><h2 id="深度学习中的交叉熵"><a href="#深度学习中的交叉熵" class="headerlink" title="深度学习中的交叉熵"></a>深度学习中的交叉熵</h2><p>举一个最简单的例子，<code>y = w * x + b</code>，目标是输入为1输出为0.经过 σ 函数进行二分类,首先定义损失函数(先用均方误差)：</p><script type="math/tex; mode=display">C = (y-a)^2/2</script><p>其中y为真实值，a为我们算出来的值，因为要经过 σ 函数进行分类，所以 a = σ (w*x + b),令 z =  w*x + b,a = σ(z)，用梯度下降法求w，b就需要先对其求微分，用到链式求导法则：</p><script type="math/tex; mode=display">\frac{\partial C}{\partial w} = \frac{\partial C}{\partial a} *\frac{\partial a}{\partial w} \\\partial C / \partial a = a-y\\\partial a / \partial w =  \sigma'(z)*x</script><p>此时设x=1，相应的y=0，</p><script type="math/tex; mode=display">\partial C / \partial w = a *\sigma'(z)\\\partial C / \partial b = a *\sigma'(z)</script><p>因为经过了sigmoid函数，所以当z较大时，梯度很小，此时会发生梯度弥散,更新参数会很慢，那么如何加快参数更新？交叉熵是凭空出现的吗?若果没有σ这项：</p><script type="math/tex; mode=display">\partial C / \partial w_i = (a-y)*x_i\\\partial C / \partial b = a-y</script><p>考虑之前的推导：</p><script type="math/tex; mode=display">\partial C / \partial w_i = \frac {\partial C}{\partial a} *\sigma'(z)x_i=\frac {\partial C}{\partial a} *a(1-a)x_i</script><p>令（6）和（5）相等可得出:</p><script type="math/tex; mode=display">\partial C / \partial a = \frac {a-y}{a(1-a)}</script><p>此时用积分求出原函数即：</p><script type="math/tex; mode=display">C = -[y\ln a+(1-y)\ln (1-a)] + constant</script><p>这就是二分类中交叉熵的函数形式，伯努利二项分布。</p><p>由此可以知道交叉熵的来源、推导。也解释了分类问题为什么用交叉熵作为损失函数，简而言之，交叉熵作为损失函数，消去了σ这一项，从而变成线性的，解决了更新参数很慢的问题，这时候再引用一张之前的图就一目了然了：</p><p><a href="https://user-images.githubusercontent.com/60562661/74258385-2f44dd80-4d31-11ea-907b-5b5c2bc25f78.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/74258385-2f44dd80-4d31-11ea-907b-5b5c2bc25f78.png" class="lazyload"></a></p></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 交叉熵 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Classification</title>
      <link href="/2020/02/25/Classification/"/>
      <url>/2020/02/25/Classification/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><p>DeepLearning中另外一个常见的问题就是分类问题，这里以二分类为例。</p><p><strong>做二分类可不可以直接当作回归问题来处理呢？</strong>例如人为规定 calss1 对应输出值为1， class2对应值为-1，然后以均方误差为loss，做损失函数，这样直接train是可以train出来的，但是这样有一个问题，回归损失函数会惩罚比较大的正确项，例如一个数得出来结果是10远大于1，但是它和1明显是一类，而用回归做的话就会尽量减小这一loss，导致出现错误的结果，如下图：本来绿色的线是正确的分类，但是因为回归的惩罚会导致偏向紫色。 这是因为回归和分类的判断标准不一样。</p><p><a href="https://user-images.githubusercontent.com/60562661/75210259-88921f80-57bb-11ea-9985-19f163a398c7.png" data-fancybox="group" data-caption="1582596902251" class="fancybox"><img alt="1582596902251" style="zoom: 67%;" title="1582596902251" data-src="https://user-images.githubusercontent.com/60562661/75210259-88921f80-57bb-11ea-9985-19f163a398c7.png" class="lazyload"></a></p><h2 id="分类流程"><a href="#分类流程" class="headerlink" title="分类流程"></a>分类流程</h2><p><a href="https://user-images.githubusercontent.com/60562661/75210541-5208d480-57bc-11ea-8f59-6ba28470aa88.png" data-fancybox="group" data-caption="1582597091411" class="fancybox"><img alt="1582597091411" style="zoom:80%;" title="1582597091411" data-src="https://user-images.githubusercontent.com/60562661/75210541-5208d480-57bc-11ea-8f59-6ba28470aa88.png" class="lazyload"></a></p><ol><li>这里的model直接用的贝叶斯求出概率</li><li>假设x服从高斯分布，此时要求出  <strong>μ，σ</strong>  用最大似然估计使得这个高斯分布所采样出来的这些点的概率最大</li><li>求解最优的μ，σ。<strong>μ 就是一组书的均值mean</strong>  ，  μ，σ都有对应公式，也可以根据微分来求，如下图：</li></ol><p><a href="https://user-images.githubusercontent.com/60562661/75210260-8a5be300-57bb-11ea-9423-008452e862f7.png" data-fancybox="group" data-caption="1582597521938" class="fancybox"><img alt="1582597521938" title="1582597521938" data-src="https://user-images.githubusercontent.com/60562661/75210260-8a5be300-57bb-11ea-9423-008452e862f7.png" class="lazyload"></a></p><h2 id="分类与回归的转化"><a href="#分类与回归的转化" class="headerlink" title="分类与回归的转化"></a>分类与回归的转化</h2><p>这里用图片截图出所有的公式推导，可以从第一张图直接跳到最后一张图看结论</p><p><a href="https://user-images.githubusercontent.com/60562661/75210261-8af47980-57bb-11ea-873f-1021dc6ebb25.png" data-fancybox="group" data-caption="1582597604571" class="fancybox"><img alt="1582597604571" style="zoom: 67%;" title="1582597604571" data-src="https://user-images.githubusercontent.com/60562661/75210261-8af47980-57bb-11ea-873f-1021dc6ebb25.png" class="lazyload"></a></p><p><a href="https://user-images.githubusercontent.com/60562661/75210263-8b8d1000-57bb-11ea-8165-8be93e1efb95.png" data-fancybox="group" data-caption="1582597627023" class="fancybox"><img alt="1582597627023" style="zoom:67%;" title="1582597627023" data-src="https://user-images.githubusercontent.com/60562661/75210263-8b8d1000-57bb-11ea-8165-8be93e1efb95.png" class="lazyload"></a></p><p><a href="https://user-images.githubusercontent.com/60562661/75210265-8c25a680-57bb-11ea-9849-26770bf8584c.png" data-fancybox="group" data-caption="1582597710255" class="fancybox"><img alt="1582597710255" style="zoom:67%;" title="1582597710255" data-src="https://user-images.githubusercontent.com/60562661/75210265-8c25a680-57bb-11ea-9849-26770bf8584c.png" class="lazyload"></a></p><p><a href="https://user-images.githubusercontent.com/60562661/75210268-8d56d380-57bb-11ea-943d-fac3d39d44f8.png" data-fancybox="group" data-caption="1582597747533" class="fancybox"><img alt="1582597747533" style="zoom:67%;" title="1582597747533" data-src="https://user-images.githubusercontent.com/60562661/75210268-8d56d380-57bb-11ea-943d-fac3d39d44f8.png" class="lazyload"></a></p><p><a href="https://user-images.githubusercontent.com/60562661/75210270-8def6a00-57bb-11ea-89c0-bfd800f1c1c0.png" data-fancybox="group" data-caption="1582597839955" class="fancybox"><img alt="1582597839955" style="zoom: 37%;" title="1582597839955" data-src="https://user-images.githubusercontent.com/60562661/75210270-8def6a00-57bb-11ea-89c0-bfd800f1c1c0.png" class="lazyload"></a></p><p><strong>也就是说分类函数经过一系列的转换，最终变成了线性函数，即 <code>P(C1|X) = σ(w * x + b)</code>,之前的方法我们要求五个参数才可以计算到最终结果，现在我们可以直接计算w，b就可以得到最终的概率！此时就变成了回归问题。然后就有了后面的逻辑回归，用交叉熵求出w，b</strong></p><p><strong>同时以上公式也说明了为什么 σ函数可以用来分类!</strong></p></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分类 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>梯度下降法 ③_数学公式起源深入</title>
      <link href="/2020/02/24/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E4%B8%89/"/>
      <url>/2020/02/24/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E4%B8%89/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><p>Gradient Descent 前面的文章讲了基本的流程，可以知道基本的梯度下降法更新参数流程是 <code>w_new = w_origin - のL/のw</code>， 这里为什么是负号呢？为甚要乘以梯度方向呢？这一切要从<strong>泰勒级数</strong>说起。</p><h2 id="Taylor-Series"><a href="#Taylor-Series" class="headerlink" title="Taylor Series"></a>Taylor Series</h2><p>假设函数 h(x) 在 x = x0 处<strong>无限可导</strong>，那么h(x)可以展开成如下：其中，x很接近x0时，后面的高次项边都可以忽略，因此约等于前两项。</p><p><a href="https://user-images.githubusercontent.com/60562661/75151086-d0c02c00-5740-11ea-99de-91d92c032776.png" data-fancybox="group" data-caption="1582543708651" class="fancybox"><img alt="1582543708651" style="zoom:80%;" title="1582543708651" data-src="https://user-images.githubusercontent.com/60562661/75151086-d0c02c00-5740-11ea-99de-91d92c032776.png" class="lazyload"></a></p><p>上图是泰勒级数在只有<strong>一个变量</strong>时的展开式，同样多个变量也可以展开：</p><p><a href="https://user-images.githubusercontent.com/60562661/75151091-d3228600-5740-11ea-94dc-c6122f01fd81.png" data-fancybox="group" data-caption="1582543838152" class="fancybox"><img alt="1582543838152" style="zoom: 80%;" title="1582543838152" data-src="https://user-images.githubusercontent.com/60562661/75151091-d3228600-5740-11ea-94dc-c6122f01fd81.png" class="lazyload"></a></p><h2 id="Based-Taylor-Series"><a href="#Based-Taylor-Series" class="headerlink" title="Based Taylor Series"></a>Based Taylor Series</h2><p><a href="https://user-images.githubusercontent.com/60562661/75151093-d3bb1c80-5740-11ea-86f9-ea1c98811b0b.png" data-fancybox="group" data-caption="1582544427626" class="fancybox"><img alt="1582544427626" style="zoom:80%;" title="1582544427626" data-src="https://user-images.githubusercontent.com/60562661/75151093-d3bb1c80-5740-11ea-86f9-ea1c98811b0b.png" class="lazyload"></a></p><p>如图，在点(a,b)处取一个足够小的圆，此时损失函数 L(θ) 便可以根据泰勒公式在(a,b)处展开，其中 s，u，v, 三项均为常数。u是L在θ1方向的偏导数，v是L在θ2方向的偏导数。</p><p><a href="https://user-images.githubusercontent.com/60562661/75151095-d453b300-5740-11ea-8f7b-016c1949553c.png" data-fancybox="group" data-caption="1582544740168" class="fancybox"><img alt="1582544740168" style="zoom:80%;" title="1582544740168" data-src="https://user-images.githubusercontent.com/60562661/75151095-d453b300-5740-11ea-8f7b-016c1949553c.png" class="lazyload"></a></p><p>此时要最小化L，把上图公式中 <strong>θ 1 -  a </strong>用▲θ1表示，<strong>θ 2 - b </strong>用▲θ2表示，s与θ无关因此可以忽略，公式L 看起来就比较简单了，可以看成是 vector(u, v)  与  vector(▲θ1, ▲θ2) 的内积，则当(▲θ1, ▲θ2)处于圆上(长度最大)，方向相反(cos  = -1)时内积最小，因此可以得到图中最下面的推导公式，乘以 <strong>-n</strong> 表示的是比例，使得(▲θ1, ▲θ2)位于圆上，<strong>负号</strong>则是与(u, v) 方向相反。将(▲θ1, ▲θ2)换算之后便会得出通常的更新参数的公式，因此得出了文章最初的<code>w_new = w_origin - n*のL/のw</code>，因此梯度方向下降最快，要乘以负的学习率。</p><p><strong>至此梯度下降法的来源也都已清楚！</strong></p></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 梯度下降法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>斐波那契数列几种实现方式</title>
      <link href="/2020/02/23/%E6%96%90%E6%B3%A2%E9%82%A3%E5%A5%91%E9%A2%9D%E6%95%B0%E5%88%97%E5%87%A0%E7%A7%8D%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F/"/>
      <url>/2020/02/23/%E6%96%90%E6%B3%A2%E9%82%A3%E5%A5%91%E9%A2%9D%E6%95%B0%E5%88%97%E5%87%A0%E7%A7%8D%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><p>今天在刷题时碰到了斐波那契额数列，然后发现有点忘记了，来记录一下几种实现方式。</p><h2 id="递归法"><a href="#递归法" class="headerlink" title="递归法"></a>递归法</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Fibonacci</span><span class="params">(i)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> i <= <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> i</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> Fibonacci(i<span class="number">-1</span>) + Fibonacci(i<span class="number">-2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    print(Fibonacci(<span class="number">100</span>))</span><br></pre></td></tr></tbody></table></figure></div><p>这种方法非常慢，有大量重复计算，复杂度是指数级</p><h2 id="递推式"><a href="#递推式" class="headerlink" title="递推式"></a>递推式</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Fibonacci</span><span class="params">(i)</span>:</span></span><br><span class="line">   a, b = <span class="number">0</span>, <span class="number">1</span></span><br><span class="line">   <span class="keyword">for</span> i <span class="keyword">in</span> range(i):</span><br><span class="line">       a, b = b, a+b</span><br><span class="line">   <span class="keyword">return</span> a</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">39</span>):</span><br><span class="line">        print(Fibonacci(i))</span><br></pre></td></tr></tbody></table></figure></div><p>该方法复杂度是线性的</p><h2 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a>生成器</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Fibonacci</span><span class="params">(n)</span>:</span></span><br><span class="line">   a, b = <span class="number">0</span>, <span class="number">1</span></span><br><span class="line">   <span class="keyword">while</span>(n><span class="number">0</span>):</span><br><span class="line">       a, b = b, a+b</span><br><span class="line">       <span class="keyword">yield</span> a</span><br><span class="line">       n = n - <span class="number">1</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> Fibonacci(<span class="number">10</span>):</span><br><span class="line">        print(i)</span><br></pre></td></tr></tbody></table></figure></div><p>暂时记录三种方法。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 斐波那契数列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Why Deep</title>
      <link href="/2020/02/23/Why-Deep/"/>
      <url>/2020/02/23/Why-Deep/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><p>相对于机器学习，深度学习为什么要 <strong>Deep</strong> 呢？</p><p>直觉上是因为神经网络层数越多，参数就越多，拟合能力越强，表现也就更好，但是事实上并不是这样。</p><p>要对比<strong>Deep</strong>与<strong>Shallow</strong>  ，首先要保证他们的参数两是一样的，这样对比才比较公平，如下图：</p><p><a href="https://user-images.githubusercontent.com/60562661/75113138-f5a39900-5685-11ea-8aa6-e8668f869b82.png" data-fancybox="group" data-caption="1582463394370" class="fancybox"><img alt="1582463394370" style="zoom: 50%;" title="1582463394370" data-src="https://user-images.githubusercontent.com/60562661/75113138-f5a39900-5685-11ea-8aa6-e8668f869b82.png" class="lazyload"></a></p><p>更深的网络模型确实是有更好的表现，误差会更低。</p><p>事实上更加Deep，有更多的 <strong>Hidden Layer</strong>  ，是在做<code>模组化(Modularization)</code> 这件事，这和模块化、函数式编程很相似，也就是说每层有具体的功能，例如：</p><ul><li>第一层的神经元是比较基础的分类器；第二层则是比较高级的…</li><li>其中第二层以第一层的输出作为输入，第三层以第二层的输出作为输入，以此类推…</li><li>模组化是机器自己学习出来的，模组化可以想象CNN —比较底层可以识别细节信息，高层则可以更好的识别语义信息</li></ul><p><a href="https://user-images.githubusercontent.com/60562661/75113140-05bb7880-5686-11ea-81c6-421e7cc536fd.png" data-fancybox="group" data-caption="1582463874502" class="fancybox"><img alt="1582463874502" title="1582463874502" data-src="https://user-images.githubusercontent.com/60562661/75113140-05bb7880-5686-11ea-81c6-421e7cc536fd.png" class="lazyload"></a></p><p>做<code>Modularization</code>  这件事的好处就是网络可以举一反三，不再需要很多很多的<code>data</code>.</p><p>有一种流行的说法：<code>AI = BigData + DeepLearning</code>  大数据与深度学习相结合所以可以做识别等任务(<strong>深度学习需要很大的数据支撑</strong>)，恰恰相反，深度学习只需要更少的Data，这里的<strong>BigData </strong> 即使有100g，1000g 依然不能包含所有的Data，因此才需要<code>DeepLearning</code>来举一反三 ，如果真的有能包含所有东西的大数据那根本不需要深度学习这件事了，直接做标签分类就实现了。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Batch Normalization</title>
      <link href="/2020/02/22/Batch-Normalization/"/>
      <url>/2020/02/22/Batch-Normalization/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><h2 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h2><p>Batch Normalization 批标准化 ，在传统的深度学习没有批标准化时，存在以下一些问题：</p><ul><li><strong>难以训练、拟合</strong>   例如下图，x1值为比较小，x2则很大， 整体公式是 <code>a = w1*x1 + w2*x2 + b</code> ,此时就是图中左下角的图，w1影响就非常小了，相应的w1方向梯度就很小，w2方向梯度变化就非常大，这会使得模型难以训练、难以拟合。</li></ul><p><a href="https://user-images.githubusercontent.com/60562661/75095600-9be19700-55d1-11ea-86e1-f81c5df25f8b.png" data-fancybox="group" data-caption="undefined" class="fancybox"><img style="zoom:40%;" data-src="https://user-images.githubusercontent.com/60562661/75095600-9be19700-55d1-11ea-86e1-f81c5df25f8b.png" class="lazyload"></a></p><ul><li><p><strong>Internal Covariate Shift 内部协变量偏移</strong> </p><p>神经网络有很多的隐藏层，每层都是以前一层的输出作为自己的输入，因此要对每一层做<code>Feature Scaling</code>, 这样会比较有效的解决该问题。</p><p>Internal Covariate Shift问题 大致意思是强一层便宜会对后续产生很大的影响，每层的输入如果不做特征缩放，很大很小模型就需要一直调整去适应，就需要把每层的输入都固定下来</p></li></ul><h2 id="Feature-Scaling"><a href="#Feature-Scaling" class="headerlink" title="Feature Scaling"></a>Feature Scaling</h2><p>这种方法比较简单，对于每一维数据，计算平均数、标准差，然后每个数减去平均数除以标准差即可标准化。</p><p><a href="https://user-images.githubusercontent.com/60562661/75095605-a8fe8600-55d1-11ea-967a-7596e215d084.png" data-fancybox="group" data-caption="1582385736895" class="fancybox"><img alt="1582385736895" style="zoom: 67%;" title="1582385736895" data-src="https://user-images.githubusercontent.com/60562661/75095605-a8fe8600-55d1-11ea-967a-7596e215d084.png" class="lazyload"></a></p><h2 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h2><h3 id="Note"><a href="#Note" class="headerlink" title="Note :"></a><strong>Note :</strong></h3><ul><li>batch_size 要够大才有意义，估算batch的分布。如batch_size 为1，则没有意义做这件事。</li><li>一般先做标准化在进入激活函数</li></ul><h3 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h3><ol><li>首先计算出 一个batch的平均值、标准差</li></ol><p><a href="https://user-images.githubusercontent.com/60562661/75095608-ab60e000-55d1-11ea-80bc-f10457f65fa2.png" data-fancybox="group" data-caption="1582386527546" class="fancybox"><img alt="1582386527546" style="zoom: 67%;" title="1582386527546" data-src="https://user-images.githubusercontent.com/60562661/75095608-ab60e000-55d1-11ea-80bc-f10457f65fa2.png" class="lazyload"></a></p><ol><li>具体的每个输出 - mean / 标准差</li></ol><p><a href="https://user-images.githubusercontent.com/60562661/75095607-aac84980-55d1-11ea-9a33-963dd56edd8b.png" data-fancybox="group" data-caption="1582386468794" class="fancybox"><img alt="1582386468794" style="zoom: 67%;" title="1582386468794" data-src="https://user-images.githubusercontent.com/60562661/75095607-aac84980-55d1-11ea-9a33-963dd56edd8b.png" class="lazyload"></a></p><ol><li><p>train：训练时反向传播需要考虑到 <strong>σ μ</strong></p></li><li><p>test：测试</p><p><a href="https://user-images.githubusercontent.com/60562661/75095604-a7cd5900-55d1-11ea-829b-06ca53b71ee1.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/75095604-a7cd5900-55d1-11ea-829b-06ca53b71ee1.png" class="lazyload"></a></p><ul><li>首先计算出训练过程中所有的 <strong>σ μ </strong></li><li>如上图的右上角 取三个 μ，靠近后面的 μ 给一个比较大的权值，靠近初始化的给比较小的权值以此来估计整个网络的 <strong>μ</strong></li></ul></li></ol><h2 id="Batch-Normalization好处"><a href="#Batch-Normalization好处" class="headerlink" title="Batch Normalization好处"></a>Batch Normalization好处</h2><ol><li>解决了  Internal Covariate Shift 问题，可以设置比较大的学习率，增加训练速度</li><li>可以有效防止梯度弥散 。之前讲sigmoid函数在比较深的网络是训练不起来的，因为梯度会消失，而每次采取了标准化，数据分布会比较靠近0附近，函数在此处斜率比较大，梯度会一直比较大</li><li>对参数初始化不是那么敏感。例如所有的w都变成 w*k，但是经过公式推导经过标准化最终并无任何影响</li><li>一定程度上解决过拟合  标准化从其实一定程度相当于正则化。</li></ol><p><strong>Batch Normalization 在训练效果不好时可以使用，而测试效果不好则不一定要采用该方法。</strong></p></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Batch Normal </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>win10环境下detectron2配置</title>
      <link href="/2020/02/18/win10%E7%8E%AF%E5%A2%83%E4%B8%8Bdetectron2%E9%85%8D%E7%BD%AE/"/>
      <url>/2020/02/18/win10%E7%8E%AF%E5%A2%83%E4%B8%8Bdetectron2%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><p>最强目标检测平台Detectron2 ，基于PyTorch完全重构，windows上很不友好，很难配置，配置好就算装好这个库依然不能使用<code>nms</code>,回头再想办法解决。安装过程曲折，记录一哈。</p><p><a href="https://user-images.githubusercontent.com/60562661/74744277-ee067d80-529c-11ea-8e3c-40dbae5c9348.jpg" data-fancybox="group" data-caption="undefined" class="fancybox"><img style="zoom:50%;" data-src="https://user-images.githubusercontent.com/60562661/74744277-ee067d80-529c-11ea-8e3c-40dbae5c9348.jpg" class="lazyload"></a></p><p><a href="http://www.luyixian.cn/news_show_240401.aspx我主要参考的这个链接" target="_blank" rel="noopener">http://www.luyixian.cn/news_show_240401.aspx我主要参考的这个链接</a></p><p><a href="https://github.com/conansherry/detectron2" target="_blank" rel="noopener">https://github.com/conansherry/detectron2</a> 这个链接在我踩坑也不可或缺</p><p>我自己电脑是cuda9.0,cudnn7,上面第二个链接要墙置换成cuda10，很难搞，所以我就按第一个来</p><h2 id="安装依赖"><a href="#安装依赖" class="headerlink" title="安装依赖"></a>安装依赖</h2><p>依赖的库：<code>pytorch1.3</code> <code>opencv</code>  <code>pycocotools</code>  <code>fvcore</code>，其中最后两个安装不同于以往，这里提一下。</p><p><code>pip install git+https://github.com/facebookresearch/fvcore</code></p><p><code>pip install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'</code></p><p>其中，pycocotools安装很是麻烦，这个命令可能不会成功，所以需要自己探索一下，装不好可以评论留言找我要。</p><h2 id="确认gcc-gt-4-9"><a href="#确认gcc-gt-4-9" class="headerlink" title="确认gcc>=4.9"></a>确认gcc>=4.9</h2><p><code>gcc --version</code></p><h2 id="修改lib文件"><a href="#修改lib文件" class="headerlink" title="修改lib文件"></a>修改lib文件</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bat</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bat"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">file1: </span></span><br><span class="line"><span class="function">  {<span class="title">your</span> <span class="title">evn</span> <span class="title">path</span>}\<span class="title">Lib</span>\<span class="title">site</span>-<span class="title">packages</span>\<span class="title">torch</span>\<span class="title">include</span>\<span class="title">torch</span>\<span class="title">csrc</span>\<span class="title">jit</span>\<span class="title">argument_spec.h</span></span></span><br><span class="line"><span class="function">  <span class="title">example</span>:</span></span><br><span class="line"><span class="function">  {<span class="title">C</span>:\<span class="title">Miniconda3</span>\<span class="title">envs</span>\<span class="title">py36</span>}\<span class="title">Lib</span>\<span class="title">site</span>-<span class="title">packages</span>\<span class="title">torch</span>\<span class="title">include</span>\<span class="title">torch</span>\<span class="title">csrc</span>\<span class="title">jit</span>\<span class="title">argument_spec.h</span>(190)</span></span><br><span class="line"><span class="function">    <span class="title">static</span> <span class="title">constexpr</span> <span class="title">size_t</span> <span class="title">DEPTH_LIMIT</span> = 128;</span></span><br><span class="line"><span class="function">      <span class="title">change</span> <span class="title">to</span> --></span></span><br><span class="line"><span class="function">    <span class="title">static</span> <span class="title">const</span> <span class="title">size_t</span> <span class="title">DEPTH_LIMIT</span> = 128;</span></span><br><span class="line"><span class="function"><span class="title">file2</span>: </span></span><br><span class="line"><span class="function">  {<span class="title">your</span> <span class="title">evn</span> <span class="title">path</span>}\<span class="title">Lib</span>\<span class="title">site</span>-<span class="title">packages</span>\<span class="title">torch</span>\<span class="title">include</span>\<span class="title">pybind11</span>\<span class="title">cast.h</span></span></span><br><span class="line"><span class="function">  <span class="title">example</span>:</span></span><br><span class="line"><span class="function">  {<span class="title">C</span>:\<span class="title">Miniconda3</span>\<span class="title">envs</span>\<span class="title">py36</span>}\<span class="title">Lib</span>\<span class="title">site</span>-<span class="title">packages</span>\<span class="title">torch</span>\<span class="title">include</span>\<span class="title">pybind11</span>\<span class="title">cast.h</span>(1449)</span></span><br><span class="line"><span class="function">    <span class="title">explicit</span> <span class="title">operator</span> <span class="title">type</span>&() { <span class="title">return</span> *(<span class="title">this</span>-><span class="title">value</span>); }</span></span><br><span class="line"><span class="function">      <span class="title">change</span> <span class="title">to</span> --></span></span><br><span class="line"><span class="function">    <span class="title">explicit</span> <span class="title">operator</span> <span class="title">type</span>&() { <span class="title">return</span> *((<span class="title">type</span>*)<span class="title">this</span>-><span class="title">value</span>); }</span></span><br></pre></td></tr></tbody></table></figure></div><h2 id="克隆检测器并安装"><a href="#克隆检测器并安装" class="headerlink" title="克隆检测器并安装"></a>克隆检测器并安装</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/facebookresearch/detectron2.git</span><br><span class="line">cd detectron2</span><br><span class="line">python setup.py build develop</span><br></pre></td></tr></tbody></table></figure></div><p>这期间提示缺少什么 就补什么就行。</p><p>至此安装完成，<code>pip list</code> 可以看到 <code>detectron2</code> 这个包</p><h2 id="踩坑"><a href="#踩坑" class="headerlink" title="踩坑"></a>踩坑</h2><p>按着第一个链接教程搞，编译一直出错，各种莫名其妙的错误，编译不成功；然后我按照第二个教程修改了文件，就成功安装了。</p><p>不同电脑环境不同，可能是环境问题导致。这个可能也只适用于我自己的电脑。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 软件环境配置 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>win10 home docker-destop安装</title>
      <link href="/2020/02/16/win10-home-docker-destop-%E5%AE%89%E8%A3%85%EE%97%8A/"/>
      <url>/2020/02/16/win10-home-docker-destop-%E5%AE%89%E8%A3%85%EE%97%8A/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><p>docker容器是一种虚拟化技术，我自己也不是很懂，但是最近有一些项目要用，所以我就在使用了。docker-desktop在win10专业版是可以很轻易安装的，但是在win10 home 也就是家庭版就很难了，缺失一堆功能，等等，所以记录一下安装过程。</p><h2 id="开启-Hyper-V"><a href="#开启-Hyper-V" class="headerlink" title="开启 Hyper-V"></a>开启 Hyper-V</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bat</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bat"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">pushd</span> "%~dp0"</span><br><span class="line"></span><br><span class="line"><span class="built_in">dir</span> /b <span class="variable">%SystemRoot%</span>\servicing\Packages\*Hyper-V*.mum >hyper-v.txt</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> /f <span class="variable">%%i</span> <span class="keyword">in</span> ('<span class="built_in">findstr</span> /i . hyper-v.txt <span class="number">2</span>^><span class="built_in">nul</span>') <span class="keyword">do</span> dism /online /norestart /add-package:"<span class="variable">%SystemRoot%</span>\servicing\Packages\<span class="variable">%%i</span>"</span><br><span class="line"></span><br><span class="line"><span class="built_in">del</span> hyper-v.txt</span><br><span class="line"></span><br><span class="line">Dism /online /enable-feature /featurename:Microsoft-Hyper-V-All /LimitAccess /ALL</span><br></pre></td></tr></tbody></table></figure></div><h2 id="伪装成专业版"><a href="#伪装成专业版" class="headerlink" title="伪装成专业版"></a>伪装成专业版</h2><p>docker-desktop安装会检测，因此需要伪装为专业版绕过检测</p><p>打开注册表，定位到HKEY_LOCAL_MACHINE\software\Microsoft\Windows NT\CurrentVersion，点击current version，在右侧找到EditionId，右键点击EditionId 选择“修改“，在弹出的对话框中将第二项”数值数据“的内容改为Professional，然后点击确定。</p><p><strong>注意：</strong>  </p><ul><li>重启电脑此项value会还原，但并不影响docker; </li><li>同时如果需要重装，那就再改一次即可</li></ul><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p><a href="https://hub.docker.com/editions/community/docker-ce-desktop-windows" target="_blank" rel="noopener">https://hub.docker.com/editions/community/docker-ce-desktop-windows</a></p><p>到这个网址来下载docker一步步安装</p><h2 id="踩坑"><a href="#踩坑" class="headerlink" title="踩坑"></a>踩坑</h2><ol><li>我安装的时候提示container不可用，经过百度这也是和hyper-V方法一样，到csdn百度一下问题就有结果，很容易；没遇到该问题就正好；</li><li>我当时安装完 打开docker一直提示<code>hyper-V</code>没有完全开启，是因为我之前在其他网站找的开启<code>hyper-V</code>的代码，代码有问题，按照文章中的代码就没问题</li><li>之前安装的<code>Docker Toolbox</code> pull 镜像很慢，但是安装了桌面版之后很快(一直可以翻墙)</li></ol><p><a href="https://user-images.githubusercontent.com/60562661/74741075-23a86800-5297-11ea-9e55-827a2d34176b.jpg" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/74741075-23a86800-5297-11ea-9e55-827a2d34176b.jpg" class="lazyload"></a></p></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 软件环境配置 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Tips For DeepLearning_2</title>
      <link href="/2020/02/14/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%B3%BB%E5%88%978-Tips-For-DeepLearning-2-%E5%85%A8%E7%A8%8B%E9%AB%98%E8%83%BD/"/>
      <url>/2020/02/14/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%B3%BB%E5%88%978-Tips-For-DeepLearning-2-%E5%85%A8%E7%A8%8B%E9%AB%98%E8%83%BD/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><p>前一篇中文讨论到，在深度学习过程中如果在训练集效果差怎么办，这里接着讨论后半部分，在训练集得到了想要了的效果，但是测试集（<strong>验证集，或者是有标签的一些数据</strong>）效果并不理想应该怎么办？有如下几种方案、方法可以参考一下：</p><ul><li>Early Stopping</li><li>Regularization</li><li>Dropout</li></ul><h2 id="Early-Stopping"><a href="#Early-Stopping" class="headerlink" title="Early Stopping"></a>Early Stopping</h2><p><a href="https://user-images.githubusercontent.com/60562661/74507861-997b9f00-4f38-11ea-91fa-f16cb7862228.png" data-fancybox="group" data-caption="1581651442213" class="fancybox"><img alt="1581651442213" style="zoom: 80%;" title="1581651442213" data-src="https://user-images.githubusercontent.com/60562661/74507861-997b9f00-4f38-11ea-91fa-f16cb7862228.png" class="lazyload"></a></p><p>这个方法大致提一下。深度学习中我们有一个假设：训练集和测试集分布是一样的。但是实际上可能并不会如此，我们训练模型应该在验证机loss最低的时候停下来，这就是这个方法的基本思想，具体的可以查阅下 文档。这里我自己主要也是了解一下即可，知道有这么一回事。</p><h2 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h2><ol><li>正则化的目的是使得函数更加的平滑，因此正则化一般不对 bias 偏置做；</li><li>正则化会使得参数变小</li><li>正则化并不是非常的重要，效果不会非常显著</li></ol><h3 id="L2-正则化"><a href="#L2-正则化" class="headerlink" title="L2 正则化"></a>L2 正则化</h3><p><a href="https://user-images.githubusercontent.com/60562661/74507869-9d0f2600-4f38-11ea-9383-46421037d9da.png" data-fancybox="group" data-caption="1581651915129" class="fancybox"><img alt="1581651915129" style="zoom: 67%;" title="1581651915129" data-src="https://user-images.githubusercontent.com/60562661/74507869-9d0f2600-4f38-11ea-9383-46421037d9da.png" class="lazyload"></a></p><p>首先是右上角L2范数，是w的平方和。</p><p>然后是下面的公式推导，L‘是损失函数，L’对某一个w微分，就是后面的结果，然后更新参数公式也很顺理成章，整理到最后就是会在w之前✖一个系数，并且这个系数通常是一个很小的值，整个这个系数接近1，因此每个参数每次更新前会越来越接近0；第一项与第二项最后会实现平衡。</p><p><strong>这个手段也成为 Weight Decay，权重衰减</strong></p><h3 id="L1-正则化"><a href="#L1-正则化" class="headerlink" title="L1 正则化"></a>L1 正则化</h3><p>L1范数是绝对值求和。那么绝对值微分问题就是在真的走到0时直接随便丢一个value比如0当作微分。</p><p><a href="https://user-images.githubusercontent.com/60562661/74507871-9ed8e980-4f38-11ea-9820-1248212f60f4.png" data-fancybox="group" data-caption="1581652966101" class="fancybox"><img alt="1581652966101" title="1581652966101" data-src="https://user-images.githubusercontent.com/60562661/74507871-9ed8e980-4f38-11ea-9820-1248212f60f4.png" class="lazyload"></a></p><p>L‘对于某一个w的微分就是上图中所推导的，后面的sgn(w)意为：w为正则为1，w为负则为-1.</p><p>更新参数时总是在后面减去一项学习率 <em> 权重 </em> （1或-1），w为正数时减去一个数，w为负数时加上一个数，总之就是使得参数更加地接近0</p><h3 id="Contrast"><a href="#Contrast" class="headerlink" title="Contrast"></a>Contrast</h3><p>L1、L2正则化都是使得参数变小，但是略有不同；</p><ul><li>L1每次剪掉固定的值，</li><li>L2则是每次乘以一个固定的值，</li></ul><p>如果有一个参数很大，那么用L2正则化更新就比较快；用L1正则化更新依然很慢；</p><p>如果有一个参数很小，那么L2正则化更新就很慢；L1正则化 更新会比较快</p><p><strong>正则化中的权值衰减，与人的神经网络有异曲同工之妙</strong></p><h2 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h2><p><a href="https://user-images.githubusercontent.com/60562661/74508193-5f5ecd00-4f39-11ea-9ce8-7ec0eb6d8384.png" data-fancybox="group" data-caption="1581653771487" class="fancybox"><img alt="1581653771487" title="1581653771487" data-src="https://user-images.githubusercontent.com/60562661/74508193-5f5ecd00-4f39-11ea-9ce8-7ec0eb6d8384.png" class="lazyload"></a></p><p>Dropout方法训练流程是这样：</p><ul><li><p>设置一个 dropout rate ：p%,也就是说在训练时每层会有 p% 的神经元被丢掉；</p></li><li><p>然后每次更新参数都会重新采样丢掉的神经元。</p></li></ul><p>Dropout的测试：</p><p>测试期间所有的神经元保留，然后最后丢失率是多少，每个w 都要乘上（1 - 丢失率）。</p><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>dropout可以解释为训练了一系列的神经网络，然后最后输出的值取了个平均</p><p><a href="https://user-images.githubusercontent.com/60562661/74507874-9f718000-4f38-11ea-8097-eedc538b23e9.png" data-fancybox="group" data-caption="1581661977792" class="fancybox"><img alt="1581661977792" style="zoom: 50%;" title="1581661977792" data-src="https://user-images.githubusercontent.com/60562661/74507874-9f718000-4f38-11ea-8097-eedc538b23e9.png" class="lazyload"></a></p><p>如上图，dropout在所有的weight✖ (1-p%) 就取得了数个神经网络做平均的相近的结果。这也就是这个方法最神奇的地方。</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>在深度学习中遇到的问题分为 <code>training data set</code>  <code>test set data</code> 效果差</p><h3 id="在训练集效果差"><a href="#在训练集效果差" class="headerlink" title="在训练集效果差"></a>在训练集效果差</h3><h4 id="梯度弥散"><a href="#梯度弥散" class="headerlink" title="梯度弥散"></a>梯度弥散</h4><ul><li>relu 激活函数</li><li>maxout 激活函数</li></ul><h4 id="学习率"><a href="#学习率" class="headerlink" title="学习率"></a>学习率</h4><ul><li>Adagrad</li><li>RMSProp</li></ul><h4 id="局部最小化"><a href="#局部最小化" class="headerlink" title="局部最小化"></a>局部最小化</h4><ul><li>Momentum 算法</li><li>Adam </li></ul><h3 id="在训练集效果好但是在测试集效果差-过拟合"><a href="#在训练集效果好但是在测试集效果差-过拟合" class="headerlink" title="在训练集效果好但是在测试集效果差(过拟合)"></a>在训练集效果好但是在测试集效果差(过拟合)</h3><ul><li>Easy Stopping</li><li>L1、L2正则化</li><li>Dropout</li></ul></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 正则化 </tag>
            
            <tag> Dropout </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Tips For DeepLearning_1</title>
      <link href="/2020/02/13/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%B3%BB%E5%88%977-Tips-For-DeepLearning-%E5%85%A8%E7%A8%8B%E9%AB%98%E8%83%BD/"/>
      <url>/2020/02/13/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%B3%BB%E5%88%977-Tips-For-DeepLearning-%E5%85%A8%E7%A8%8B%E9%AB%98%E8%83%BD/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><p>本文主要讲深度学习中常见的一些但是又理解不透彻的方法原理以及用途，全程高能！</p><p>主要有：</p><ul><li>深度学习流程</li><li>Activation Function（各种）</li><li>各种梯度下降法</li><li>L1、L2 正则化</li><li>dropout</li></ul><h2 id="DeepLearning-流程"><a href="#DeepLearning-流程" class="headerlink" title="DeepLearning 流程"></a>DeepLearning 流程</h2><p><a href="https://user-images.githubusercontent.com/60562661/74453826-ed956d80-4ebd-11ea-8ce3-89ece01340d1.png" data-fancybox="group" data-caption="1581604363019" class="fancybox"><img alt="1581604363019" style="zoom:50%;" title="1581604363019" data-src="https://user-images.githubusercontent.com/60562661/74453826-ed956d80-4ebd-11ea-8ce3-89ece01340d1.png" class="lazyload"></a></p><ol><li>首先是之前文章提到过的深度学习的三个步骤，这三个步骤会搭建起一个神经网络；</li><li>训练神经网络，检测网络对于训练集的效果,此时如果效果很差就要回去调整模型，继续训练，知道得到比较好的结果</li><li>此时在训练集效果达到了，开始在测试集(<strong>验证集</strong>)进行测试，如果效果不好就说明过拟合了，需要采取一些措施。</li></ol><p><strong>这里要注意，不是说效果一差就是过拟合，要理性分析。</strong></p><h2 id="Training-set-效果差的原因及其解决"><a href="#Training-set-效果差的原因及其解决" class="headerlink" title="Training set 效果差的原因及其解决"></a>Training set 效果差的原因及其解决</h2><h3 id="Vanishing-Gradient"><a href="#Vanishing-Gradient" class="headerlink" title="Vanishing Gradient"></a>Vanishing Gradient</h3><p>首先思考一个问题，为什么需要激活函数？ </p><p>一个普通的全连接网络，如果没有激活函数，那么所有的操作都是乘积、求和，这就是一个线性的网络，表达能力非常差，也不是我们所需要的，因此传统的在每个层后面输出时会加个sigmoid这样的非线性函数。也就是说，激活函数可以使我们的网络编程非线性的。</p><h4 id="Sigmoid-函数"><a href="#Sigmoid-函数" class="headerlink" title="Sigmoid 函数"></a>Sigmoid 函数</h4><p><a href="https://user-images.githubusercontent.com/60562661/74453819-ea9a7d00-4ebd-11ea-9848-b5bbf6ac7e49.jpg" data-fancybox="group" data-caption="undefined" class="fancybox"><img style="zoom:50%;" data-src="https://user-images.githubusercontent.com/60562661/74453819-ea9a7d00-4ebd-11ea-9848-b5bbf6ac7e49.jpg" class="lazyload"></a></p><p>如图所示，所有的输入经过sigmoid会强行压缩到0-1之间，这样会使函数变成非线性的，但是也随之带来了问题：强行将所有之压缩到0-1，随着网络层数的加深，反向传播时靠近输出层的梯度值还比较大，但是输入层附近的层梯度都会很小，梯度从后往前越来越小直到消失，这就是<strong>梯度弥散</strong> (<strong>gradient Vanish</strong> )问题.</p><ul><li>靠近输出层的参数更新幅度比较快，但是此时靠近输入层的梯度已经很小接近于0，参数基本无更新，也就是还是随机值的状态来更新后面的参数，所以此时后面更新的参数问题就很大！</li><li>当输入层某个w发生变化就算变化非常大，而sigmoid的值变化幅度确非常的小，因为函数曲线很缓，如下图</li></ul><p><a href="https://user-images.githubusercontent.com/60562661/74453863-f8e89900-4ebd-11ea-9a69-9dbe824afeab.png" data-fancybox="group" data-caption="undefined" class="fancybox"><img style="zoom: 67%;" data-src="https://user-images.githubusercontent.com/60562661/74453863-f8e89900-4ebd-11ea-9a69-9dbe824afeab.png" class="lazyload"></a></p><h4 id="ReLu-函数"><a href="#ReLu-函数" class="headerlink" title="ReLu 函数"></a>ReLu 函数</h4><p><a href="https://user-images.githubusercontent.com/60562661/74453834-eff7c780-4ebd-11ea-92b4-a3e606985972.png" data-fancybox="group" data-caption="1581605904109" class="fancybox"><img alt="1581605904109" style="zoom: 50%;" title="1581605904109" data-src="https://user-images.githubusercontent.com/60562661/74453834-eff7c780-4ebd-11ea-92b4-a3e606985972.png" class="lazyload"></a></p><p>如图所示，输出值a小于0，则 <code>Relu(a) = 0</code>  否则，<code>Relu(a) = a</code></p><p>这个激活函数的出现解决了梯度弥散问题</p><p><a href="https://user-images.githubusercontent.com/60562661/74453841-f2f2b800-4ebd-11ea-9560-0a34ec5c413e.png" data-fancybox="group" data-caption="1581606094265" class="fancybox"><img alt="1581606094265" style="zoom:50%;" title="1581606094265" data-src="https://user-images.githubusercontent.com/60562661/74453841-f2f2b800-4ebd-11ea-9560-0a34ec5c413e.png" class="lazyload"></a></p><p>解决方式如图，值为0的神经元可以去掉，整个网络就是一个线性函数了。</p><p>这里有一个问题是：0的神经元消除，整个网络就是一个线性函数，这不符合我们要求啊？</p><p>可以这样解释，改变了数据输入，神经元的连线发生变化，整个网络依然是非线性的。</p><p><strong>着重理解Relu，它的一系列的变体函数就不说了，比较相似</strong></p><p>CNN文章提到的<code>Max Pooling</code> 不可导，和这个就很相似了，每次都是取最大值，然后其他的神经元都丢掉，整个网络又是一个细长的线性神经网络。<strong>其实是和下面的 Max-out函数比较相似</strong></p><h4 id="Max-Out-函数"><a href="#Max-Out-函数" class="headerlink" title="Max-Out 函数"></a>Max-Out 函数</h4><p><a href="https://user-images.githubusercontent.com/60562661/74454478-ede23880-4ebe-11ea-820a-d34dbd2c3cf6.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/74454478-ede23880-4ebe-11ea-820a-d34dbd2c3cf6.png" class="lazyload"></a></p><p>这个方法是打组思想，Relu就是它的一个个例，这里就不细说了，relu用的多一点。</p><p><strong>有个问题：这个每次只取最大的这样有的神经元就不会被train到。因为每次数据不同得到的最大值也会不同，所以所有的weight都会得到更新，都会被train到。</strong></p><h3 id="Learning-Rate"><a href="#Learning-Rate" class="headerlink" title="Learning Rate"></a>Learning Rate</h3><p>梯度下降法的时候，会有局学习率问题，所以出现了一些梯度下降法的变体。</p><p><a href="https://huaqi.blue/2020/02/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%B3%BB%E5%88%97%E4%B8%80-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/#%E6%A6%82%E8%BF%B0%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%B5%81%E7%A8%8B">Gradient Descent</a>、<a href="https://huaqi.blue/2020/02/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%B3%BB%E5%88%97%E4%B8%80-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95-%E2%91%A1/#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96">Adagrad Gradient Descent</a> 、以及 <a href="[https://huaqi.blue/2020/02/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%B3%BB%E5%88%97%E4%B8%80-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95-%E2%91%A1/#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96](https://huaqi.blue/2020/02/10/深度学习入门系列一-梯度下降法-②/#梯度下降法及其优化">SGD</a>) 在之前文章都有讲过,不清楚可以返回看一下。</p><p>Adagrad梯度下降法实现了自适应的学习率，但是实际上我们面对的比这个所能解决的问题更加复杂，如下图。</p><p><a href="https://user-images.githubusercontent.com/60562661/74453867-fab25c80-4ebd-11ea-9131-f4a5cc825046.jpg" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/74453867-fab25c80-4ebd-11ea-9131-f4a5cc825046.jpg" class="lazyload"></a></p><ul><li>左边的在w1方向，从左到右是比较平坦的，所以一个学习率就可以；</li><li>右边的图同样在w1方向比较缓的地方学习率就应该小点儿，突然陡峭学习率又应该大一点。<strong>因此需要更加动态的调整学习率。</strong></li></ul><h4 id="Root-Mean-Square-Prop-RMSProp"><a href="#Root-Mean-Square-Prop-RMSProp" class="headerlink" title="Root Mean Square Prop(RMSProp)"></a>Root Mean Square Prop(RMSProp)</h4><p><a href="https://user-images.githubusercontent.com/60562661/74453848-f5551200-4ebd-11ea-8508-f858952d1793.png" data-fancybox="group" data-caption="1581608584478" class="fancybox"><img alt="1581608584478" style="zoom: 67%;" title="1581608584478" data-src="https://user-images.githubusercontent.com/60562661/74453848-f5551200-4ebd-11ea-8508-f858952d1793.png" class="lazyload"></a></p><p>与之前的Adagrad方法非常类似，不同的是，这个方法可以控制权重，更偏向于过去的信息还是新的梯度信息，可以通过设置权重值来控制</p><h3 id="Local-Minimum"><a href="#Local-Minimum" class="headerlink" title="Local  Minimum"></a>Local  Minimum</h3><h4 id="Momentum-冲量、惯性-算法"><a href="#Momentum-冲量、惯性-算法" class="headerlink" title="Momentum (冲量、惯性)算法"></a>Momentum (冲量、惯性)算法</h4><p>如下图，在求出当前阶段的梯度值后，不只是考虑当前的梯度方向，同时考虑了前一个梯度方向，然后做个加权和得到新的方向。</p><p><a href="https://user-images.githubusercontent.com/60562661/74453853-f6863f00-4ebd-11ea-959d-a1dc06789b2e.png" data-fancybox="group" data-caption="1581609144187" class="fancybox"><img alt="1581609144187" style="zoom: 40%;" title="1581609144187" data-src="https://user-images.githubusercontent.com/60562661/74453853-f6863f00-4ebd-11ea-959d-a1dc06789b2e.png" class="lazyload"></a></p><p>这可以说是根据现实生活中的惯性，会继续向前走一点。</p><h4 id="Adam-优化算法"><a href="#Adam-优化算法" class="headerlink" title="Adam 优化算法"></a>Adam 优化算法</h4><p>Adam则是 RMSProp、Momentum两个梯度下降算法的集大成者。在深度学习框架中是已经封装好的。这个并未深究，我觉得理解了基础的就可以。</p><h2 id="关于测试集效果差，且听下回分解。"><a href="#关于测试集效果差，且听下回分解。" class="headerlink" title="关于测试集效果差，且听下回分解。"></a>关于测试集效果差，且听下回分解。</h2><p><a href="https://user-images.githubusercontent.com/60562661/74454502-f5094680-4ebe-11ea-9a65-ca37f68a6660.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/74454502-f5094680-4ebe-11ea-9a65-ca37f68a6660.png" class="lazyload"></a></p><p>主要讲正则化、Dropout这两块。上图中前两种方法都是比较经典的，不只是深度学习的，而正则化用的多一点，所以主要理解一下正则化； Dropout则是非常具有深度学习风格，所以需要深究。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> sigmoid </tag>
            
            <tag> relu </tag>
            
            <tag> max-out </tag>
            
            <tag> Learning-Rate </tag>
            
            <tag> Local Minimum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Convolution Neural Network(CNN)卷积神经网络</title>
      <link href="/2020/02/13/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%B3%BB%E5%88%976-Convolution-Neural-Network-CNN-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
      <url>/2020/02/13/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%B3%BB%E5%88%976-Convolution-Neural-Network-CNN-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><h2 id="CNN的提出"><a href="#CNN的提出" class="headerlink" title="CNN的提出"></a>CNN的提出</h2><p><strong>其一，</strong>之前所提到的线性回归、比较简单逻辑回归都是全连接层<strong>(Full-Connected)</strong> ,那么在图像处理领域输入数据都是图像，现实中一张很小的图 <strong>100 * 100</strong> ，分辨率已经很低了，然是依然有<strong>30000 维数据</strong>，(这里默认图象是彩色图三通道的)，然后后面再堆几层网络，参数量实在是巨大，这是全连接网络的缺陷；</p><p><strong>其二，</strong>基于现实的观察有以下基点：</p><ul><li><p>假设CNN中每一个神经元都是用来识别某一个<strong>pattern</strong>[例如：鼻子，嘴，手臂] (实际上大概也是这样工作的)</p></li><li><p>人们在辨识一些小的部分比如鸟喙时，并不需要遍历一张图的所有信息，而是看到图片的一小部分就可以捕捉到需要的信息；</p></li><li>同一个部分(鸟喙)在图像中可能会出现在不同的位置，因此CNN的神经元以相同的参数就可以发现不同位置的鸟喙而不用重新学习参数</li><li>图像进行下采样，并不会影响我们对图片的观察(不包括比较极端的)；而图像较小的时候像素比较少此时也会减少参数</li></ul><p>基于以上，CNN卷积神经网络就正式提出了，并且在计算机视觉领域(影像处理)非常有效，几乎所有的任务，第一步都是要用卷积神经网络来提取特征。</p><h2 id="CNN一般架构"><a href="#CNN一般架构" class="headerlink" title="CNN一般架构"></a>CNN一般架构</h2><p>卷积神经网络一般是输入图像，然后经过 （卷积层、池化层）这两个一直重复，然后输出的像素拉平(flatten操作将当前值转变为一维向量)，连接上全连结网络输出，如下图：</p><p><a href="https://user-images.githubusercontent.com/60562661/74443982-1e21db00-4eaf-11ea-973c-7b46e241d959.png" data-fancybox="group" data-caption="1581600351984" class="fancybox"><img alt="1581600351984" style="zoom: 67%;" title="1581600351984" data-src="https://user-images.githubusercontent.com/60562661/74443982-1e21db00-4eaf-11ea-973c-7b46e241d959.png" class="lazyload"></a></p><h2 id="Convolution计算流程"><a href="#Convolution计算流程" class="headerlink" title="Convolution计算流程"></a>Convolution计算流程</h2><p><strong>首先，CNN中要训练的参数就是卷积核的每个像素的数值</strong></p><h3 id="单通道卷积计算"><a href="#单通道卷积计算" class="headerlink" title="单通道卷积计算"></a>单通道卷积计算</h3><p><a href="https://user-images.githubusercontent.com/60562661/74443985-1f530800-4eaf-11ea-8059-661371e1f691.png" data-fancybox="group" data-caption="undefined" class="fancybox"><img style="zoom: 67%;" data-src="https://user-images.githubusercontent.com/60562661/74443985-1f530800-4eaf-11ea-8059-661371e1f691.png" class="lazyload"></a></p><p>如上图，用filter1在图像6<em>6图像上滑动，从左上角开始，步长为1，在每个窗格对应位置相乘然后加起来输出一个新的值，此时就会形成一个新的4 <strong> 4的 img ，称为特征图</strong>Feature Map *</em>。</p><p>此时有一个卷积核，就输出一张特征图，两个卷积核就输出两张特征图，以此类推。</p><h3 id="多通道卷积计算"><a href="#多通道卷积计算" class="headerlink" title="多通道卷积计算"></a>多通道卷积计算</h3><p><a href="https://user-images.githubusercontent.com/60562661/74443978-1c581780-4eaf-11ea-923b-a7975171f4d7.png" data-fancybox="group" data-caption="1581598043317" class="fancybox"><img alt="1581598043317" style="zoom: 67%;" title="1581598043317" data-src="https://user-images.githubusercontent.com/60562661/74443978-1c581780-4eaf-11ea-923b-a7975171f4d7.png" class="lazyload"></a></p><p>如果输入的图像是三通道的，那么每个卷积核对应的也是三通道的，注意此时计算可能是：</p><p>卷积核的第一个通道与图像红色通道进行卷积运算，卷积核的第二个通道与图像绿色通道进行卷积运算，卷积核的第三个通道与图像蓝色通道进行卷积运算，然后 卷积核三个通道输出的img对应位置相加，形成一个新的1个通道的img，就是这个卷积核所输出的 <strong>Feature Map</strong>  。这里注意的是： 对于多通道图像，<code>一个卷积核进行卷积运算后所输出的依然是一个 feature map，而不是9个(3*3).</code></p><h2 id="Convolution-amp-Neural-Network"><a href="#Convolution-amp-Neural-Network" class="headerlink" title="Convolution & Neural Network"></a>Convolution & Neural Network</h2><p>以上讲了卷积的运算方式，那么卷积与神经网络，与全连接网络有什么关系呢？</p><p><strong>卷积实际上就是全连接网络(去掉一些weight) !</strong></p><p><a href="https://user-images.githubusercontent.com/60562661/74443980-1d894480-4eaf-11ea-81f5-dde23c1db352.png" data-fancybox="group" data-caption="1581598946132" class="fancybox"><img alt="1581598946132" style="zoom: 67%;" title="1581598946132" data-src="https://user-images.githubusercontent.com/60562661/74443980-1d894480-4eaf-11ea-81f5-dde23c1db352.png" class="lazyload"></a></p><p>分析一下这张图，</p><ul><li><p>首先右边蓝色的 1 2 3 4 ···一直到16，表示的是将左边6*6的图像拉平（这里没有画完），蓝色的框里的数字是每个像素的值；</p></li><li><p>然后上面是个3*3的卷积核，每个像素用不同颜色的⚪圈了起来；</p></li><li><p>然后上图右边部分橙色的 3，-1 就是 卷积核与图像滑动过的区域做的卷积计算得到的数值，将卷积核卷积后的4*4的img也拉平，就得到了右边的 3 ，-1  （这里用3和-1举例子所以没有画完）</p></li></ul><h3 id="大量参数的减少"><a href="#大量参数的减少" class="headerlink" title="大量参数的减少"></a>大量参数的减少</h3><p>卷积之后得到的图像的每个像素也就是右边的3，-1 等，可以看作是一个神经元，其中 卷积核做图像左上角的时候，计算刚好是与原来的6<em>6图像的 编号为 1 2 3 7 8 9 13 14 15 的像素进行的，因此“<strong>3</strong>”这个神经元就连接到了编号为 1 2 3 7 8 9 13 14 15 的像素，-1是同样的道理。这时候，如果计算参数量，就是 16 </em> 9 = 144 个参数，而此时如果用全连接层的话，就是 36 * 16 = 576 个参数，已经少了很多了</p><h3 id="参数共享"><a href="#参数共享" class="headerlink" title="参数共享"></a>参数共享</h3><p>上图中右边部分的神经元，并不是说所有的参数都要计算。一个卷积核中同一个像素滑动过的值他们之间的权重都是强迫相等的。举个例子，卷积核中的第一个像素(深红色圆圈)，与6<em>6的图像在左上角计算卷积时对应的编号为1的像素，卷积核向右滑动一次后，该像素(深红色圆圈)对应的是编号为2的像素，因此 上图右边部分 1 号像素和 右边的神经元3 ， 2号像素与右边的神经元-1之间连接都用的是深红色，这两条线的参数就是相等的。所以同理，上图右边部分连线中颜色相同的权值都是共享的。(<em>*Share Weights</em></em>) 此来再来计算一下参数量，就只有9个了。</p><p>这其实也不难理解，一开始文章就提到，卷积神经网络的参数就是卷积核的像素值，这里是3*3的卷积核9个像素，所以也就只有9个参数了。到这里已经是全连接网络的 1/64 了，也就是减少了64倍的参数，这在 上百万参数是减少的就更明显了！</p><p><strong>到这里，已经理解了卷积神经网络的计算方式以及如何减少参数</strong></p><h2 id="池化-Max-pooling"><a href="#池化-Max-pooling" class="headerlink" title="池化 Max pooling"></a>池化 Max pooling</h2><p><a href="https://user-images.githubusercontent.com/60562661/74443974-1a8e5400-4eaf-11ea-91d0-250625a1d4ad.jpg" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/74443974-1a8e5400-4eaf-11ea-91d0-250625a1d4ad.jpg" class="lazyload"></a></p><p>在卷积输出的特征图基础上，以2*2为单位，每个红色框里选出最的值组成一个新的img，这就是最大池化；</p><p>平均池化就是一个红色框里所有的像素值取平均。 </p><p>经过池化，图像尺寸变为 2*2 </p><p><strong>池化层采用最大池化方式，那么怎么求微分呢？不可导就不能梯度下降，这个下一篇文章会说。</strong></p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>以上就是CNN，卷积神经网络，工作方式可以理解为某一层的神经元识别一个 pattern ，然后全连接层组合这些个 pattern 最后提取出高质量的特征。 这个可以自己求证一下。大概可以这么解释。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>反向传播BP算法</title>
      <link href="/2020/02/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%B3%BB%E5%88%974-%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%ADBP%E7%AE%97%E6%B3%95/"/>
      <url>/2020/02/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%B3%BB%E5%88%974-%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%ADBP%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><p>之前讲过机器学习的三个步骤，<strong>深度学习</strong><code>Deep Learning</code>非常的类似，可以概括为以下几步：</p><ul><li>(设置函数) -> 搭建<strong>神经网络</strong></li><li>(函数的好坏定义) -> 设置<strong>损失函数</strong></li><li>(找出最优函数) -> <strong>反向传播</strong>更新参数</li></ul><p>第一步之前的设置函数，在这里用神经网络来替代了；</p><p>在线性回归逻辑回归中可以直接计算梯度，但是深度学习神经网络比较深，不能一下子求出梯度，因此本文主要来探讨一下反向传播 <code>Back Propagation</code>算法。</p><p><strong>同时，本文会附上手动搭建神经网络、计算梯度、实现反向传播的代码，纯手写只用到了numpy库！</strong></p><h2 id="前置知识"><a href="#前置知识" class="headerlink" title="前置知识"></a>前置知识</h2><p>神经网络的反向传播并不需要很高深的数学知识，需要掌握<strong>链式求导法则 (Chain Rule)</strong>。下面会一步步从数学上求出微分 ，并且理解这种算法的精妙之处。</p><h2 id="案例背景"><a href="#案例背景" class="headerlink" title="案例背景"></a>案例背景</h2><p><a href="https://user-images.githubusercontent.com/60562661/74358378-50263500-4dfc-11ea-8f03-2fac002d131d.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/74358378-50263500-4dfc-11ea-8f03-2fac002d131d.png" class="lazyload"></a></p><p>一个有代表性的例子，输入层经过神经网络得到输出值，与真实值之间存在误差，这里用交叉熵作为损失函数，因此在这里，要求梯度也就是求损失函数对于w的偏微分。</p><h2 id="层层深入"><a href="#层层深入" class="headerlink" title="层层深入"></a>层层深入</h2><p><a href="https://user-images.githubusercontent.com/60562661/74358360-4b618100-4dfc-11ea-8411-9478cb1f4a0f.png" data-fancybox="group" data-caption="1581522297605" class="fancybox"><img alt="1581522297605" title="1581522297605" data-src="https://user-images.githubusercontent.com/60562661/74358360-4b618100-4dfc-11ea-8411-9478cb1f4a0f.png" class="lazyload"></a></p><p>把上面具体的神经网络展开，假设只有两个神经元，这里只对w求微分，b的方式是一样的，所以以w为例。</p><p>首先，根据上图的函数以及chain rules，损失函数C对w的偏微分可以拆解为两部分</p><ul><li>C 对于 z 的偏导数 </li><li>z 对于 w 的偏导数</li></ul><h3 id="Forward-Pass"><a href="#Forward-Pass" class="headerlink" title="Forward Pass"></a>Forward Pass</h3><p>（先讲第二部分）其中，z 对于 w 的偏导数比较容易，可以很容易的看出来 z 对于 w1 的偏导数就是w之前的输入值，也就是 x1，同理 z 对于 w2 的偏导数就是 x2，下面的图强化一下 z 对于 w 的偏导数</p><p><a href="https://user-images.githubusercontent.com/60562661/74358383-51eff880-4dfc-11ea-9f7b-87aea43f3483.png" data-fancybox="group" data-caption="undefined" class="fancybox"><img style="zoom:50%;" data-src="https://user-images.githubusercontent.com/60562661/74358383-51eff880-4dfc-11ea-9f7b-87aea43f3483.png" class="lazyload"></a></p><p>可以观察到z对于每个w的偏导数就是 当前权重所之前的输入值，这样比较拗口，英语会比较好理解：</p><p><strong>The value of the input connected by the weight</strong> .通俗的说就是这条线从哪里出来，出来的那个节点值就是z对于这条线也就是这个w的偏微分。</p><p>这里也可以看出，前向传播可以算出每个中间值，也就是计算出了每个梯度的上述第二部分。</p><h3 id="Backward-Pass"><a href="#Backward-Pass" class="headerlink" title="Backward Pass"></a>Backward Pass</h3><p>下面看第一部分比较复杂的，也就是 C 对于 z 的偏导数。</p><p><a href="https://user-images.githubusercontent.com/60562661/74358367-4dc3db00-4dfc-11ea-81b3-7bf35d6c3b66.png" data-fancybox="group" data-caption="1581523046931" class="fancybox"><img alt="1581523046931" title="1581523046931" data-src="https://user-images.githubusercontent.com/60562661/74358367-4dc3db00-4dfc-11ea-81b3-7bf35d6c3b66.png" class="lazyload"></a></p><p>上图中 z 经过 sigmoid 函数 得到 a，a 继续传播到下一层，此时 C 对于 z 的偏导数可以转化为上图中的下面公式所写的。在求和的两部分中，同样的各自又都分为两部分，与上述的两部分类似。z’ 对于 a 的偏导数很容易，就直接是 w3 ，相应的 z’‘ 就是 w4.</p><p>所以此时问题就转化为 C对于z’ C对于z‘’ 的偏微分，如果这两部分知道那么就可以求出来 C对a的偏微分，同样的C对z的偏微分也就求出来了，也就解决了这部分问题。以下内容是<strong>关键：</strong></p><h3 id="反求"><a href="#反求" class="headerlink" title="反求"></a>反求</h3><p><a href="https://user-images.githubusercontent.com/60562661/74358708-e195a700-4dfc-11ea-978f-34ace433b4ce.png" data-fancybox="group" data-caption="1581523822435" class="fancybox"><img alt="1581523822435" style="zoom:50%;" title="1581523822435" data-src="https://user-images.githubusercontent.com/60562661/74358708-e195a700-4dfc-11ea-978f-34ace433b4ce.png" class="lazyload"></a></p><p>上图的下面的公式只是把值带入了前一步中的公式，但是可以想象一下，这里面的 乘法、加法 操作 很像是神经网络的前向传播，所以这里就可以想象成一个新的神经网络，只不过是反过来计算的，这时候就会计算出来 C 对于 z 的偏微分。值得注意的是 上图中 <code>sigmoid’(z)</code> 是个常数，因为z前向传播时已经计算出来了，所以这里就是计算一个数而已。因此现在到这一步，<strong>说明知道后面两项的偏微分可以求出前面的。</strong> 此时问题依然是 C对于z’ C对于z‘’ 的偏微分。</p><h3 id="大胆假设、细心求证"><a href="#大胆假设、细心求证" class="headerlink" title="大胆假设、细心求证"></a>大胆假设、细心求证</h3><h4 id="假设一-easy"><a href="#假设一-easy" class="headerlink" title="假设一 (easy)"></a>假设一 (easy)</h4><p>假设 <strong>z‘ z’‘</strong> 之后经过激活函数直接是最终的输出，此时求微分就很简单了，如下图：</p><p><a href="https://user-images.githubusercontent.com/60562661/74358371-4ef50800-4dfc-11ea-851d-3f8bb542090d.png" data-fancybox="group" data-caption="1581524647050" class="fancybox"><img alt="1581524647050" title="1581524647050" data-src="https://user-images.githubusercontent.com/60562661/74358371-4ef50800-4dfc-11ea-851d-3f8bb542090d.png" class="lazyload"></a></p><p>其中，C 对于 y1 的偏微分就是损失函数的偏微分，y1 对于 z’ 的偏微分就是根据<strong>激活函数</strong>（上图最后的橙色圆圈）求出微分很容易，z‘’ 同理。</p><p>在此种假设下，此时已经得出了 C 对于 z‘、 C 对于 z’‘ 的偏微分，回溯到前一个步骤，就求出了 C对于z的偏导，在往前回到最初步，发现此时已经求出了两个 需要的条件，此时就可以算出 C 对于 w1 ，C  对于 w2 的偏微分。</p><p><strong>也就是说，忙活到现在，也就只是算出来了第一个神经元的两条线(2个w)的梯度！</strong></p><h4 id="假设二-Normal"><a href="#假设二-Normal" class="headerlink" title="假设二 (Normal)"></a>假设二 (Normal)</h4><p>假设 <strong>z‘ z’‘</strong> 之后 依然有很多层，如下图：</p><p> <a href="https://user-images.githubusercontent.com/60562661/74358374-4f8d9e80-4dfc-11ea-9285-7f803a3a4c5f.png" data-fancybox="group" data-caption="1581525161904" class="fancybox"><img alt="1581525161904" title="1581525161904" data-src="https://user-images.githubusercontent.com/60562661/74358374-4f8d9e80-4dfc-11ea-9285-7f803a3a4c5f.png" class="lazyload"></a></p><p>由<code>反求</code>部分我们已经知道想要求 C对于 z’（or z‘’） 的偏导数，需要知道后面 C 对于 Za 及 Zb 的偏导数，所以需求会一直往后寻找，递归这个过程，知道到达输出层，然后一层层往前就会求出来最初始的梯度，如下图：</p><p><a href="https://user-images.githubusercontent.com/60562661/74358380-51576200-4dfc-11ea-9ec1-958f51f62321.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/74358380-51576200-4dfc-11ea-9ec1-958f51f62321.png" class="lazyload"></a></p><p>至此，如果理解了这些，就已经理解了反向传播的原理了。</p><h2 id="Conclusion-amp-Question"><a href="#Conclusion-amp-Question" class="headerlink" title="Conclusion & Question"></a>Conclusion & Question</h2><h3 id="BP算法总结"><a href="#BP算法总结" class="headerlink" title="BP算法总结"></a>BP算法总结</h3><p><code>Back Propagation</code>  算法分为两部分</p><ul><li>前向传播 求出 z 对于 w 的偏导数</li><li>反向传播 求出 C 对于 z 的偏导数 </li><li>两个值相乘就是梯度</li></ul><h3 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h3><p>从前到后的传播直接计算每个参数的梯度为什么比BP算法差?</p><h4 id="前向传播计算梯度"><a href="#前向传播计算梯度" class="headerlink" title="前向传播计算梯度"></a>前向传播计算梯度</h4><p>从前到后直接传播计算梯度，第一层的w需要知道后面所有的层的梯度，此时会进行一趟计算；2-end；</p><p>继续求第二层w 的梯度，需要知道后面所有层的梯度，也就是 3 - end； 最后加起来就是：</p><p>end - 2 + end - 3 + end - 4 + ….. + end-0,z明显计算量不小！</p><h4 id="反向传播计算梯度"><a href="#反向传播计算梯度" class="headerlink" title="反向传播计算梯度"></a>反向传播计算梯度</h4><p>从最后一层开始计算，先计算出最后一层梯度，可以直接计算出来，这样每次往前计算不用再一直累加，因此计算量小很多。所以说BP算法刚好就是利用了原来的网络和参数而且可以用和前向传播相同的计算量计算出所有w的梯度。这就是BP算法的精妙之处！</p><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>在这里手动搭建了一个神经网络，暂时没有考虑b，因为只是用来加深理解，又一个输入层，两个隐藏层，一个输出层，每层四个神经元。所有参数都是手动计算梯度。</p><p>根据以上分析的反向传播算法可以总结出以下几步：</p><ul><li>前向传播一遍计算出所有节点的值</li><li>反向传播一遍计算出所有结点的偏微分</li><li>做乘法求出所有的梯度进行更新</li></ul><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment">#Generate data</span></span><br><span class="line"><span class="comment"># Forward Node</span></span><br><span class="line">x_F = np.random.rand(<span class="number">4</span>)</span><br><span class="line">y_F = np.random.rand(<span class="number">4</span>)</span><br><span class="line">z_F = np.random.rand(<span class="number">4</span>)</span><br><span class="line">p_F = np.random.rand(<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#weight</span></span><br><span class="line">x_y_w = np.random.rand(<span class="number">4</span>,<span class="number">4</span>)</span><br><span class="line">y_z_w = np.random.rand(<span class="number">4</span>,<span class="number">4</span>)</span><br><span class="line">z_p_w = np.random.rand(<span class="number">4</span>,<span class="number">4</span>)</span><br><span class="line"><span class="comment">#backward node</span></span><br><span class="line">x_B = np.random.rand(<span class="number">4</span>)</span><br><span class="line">y_B = np.random.rand(<span class="number">4</span>)</span><br><span class="line">z_B = np.random.rand(<span class="number">4</span>)</span><br><span class="line">p_B = np.random.rand(<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#TARGET</span></span><br><span class="line">target = np.array([<span class="number">0.5</span>,<span class="number">0.7</span>,<span class="number">0.3</span>,<span class="number">0.1</span>])</span><br><span class="line"><span class="comment">#loss</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">SquareErrorLoss</span><span class="params">(output, target)</span>:</span></span><br><span class="line">    loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(output)):</span><br><span class="line">        loss = loss + (output[i] - target[i])**<span class="number">2</span></span><br><span class="line">    loss = loss</span><br><span class="line">    <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"><span class="comment"># Graident</span></span><br><span class="line">lr = <span class="number">0.0000001</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">500000</span>):</span><br><span class="line">    <span class="comment"># forward0</span></span><br><span class="line">    y_F = np.matmul(x_F, x_y_w)</span><br><span class="line">    z_F = np.matmul(y_F, y_z_w)</span><br><span class="line">    p_F = np.matmul(z_F, z_p_w)  <span class="comment"># 得到输出</span></span><br><span class="line">    loss_end = SquareErrorLoss(p_F, target)</span><br><span class="line">    <span class="comment"># backward</span></span><br><span class="line">    p_B = <span class="number">2</span>*p_F  <span class="comment"># end grad</span></span><br><span class="line">    z_B = np.matmul(p_B, z_p_w.T)</span><br><span class="line">    y_B = np.matmul(z_B, y_z_w.T)</span><br><span class="line">    <span class="comment"># print(z_F[0])</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># grad</span></span><br><span class="line">    z_p_w_grad = [np.dot(z_F[<span class="number">0</span>], p_B),</span><br><span class="line">                  np.dot(z_F[<span class="number">1</span>], p_B),</span><br><span class="line">                  np.dot(z_F[<span class="number">2</span>], p_B),</span><br><span class="line">                  np.dot(z_F[<span class="number">3</span>], p_B)]  <span class="comment"># 4*4</span></span><br><span class="line">    y_z_w_grad = [np.dot(y_F[<span class="number">0</span>], z_B),</span><br><span class="line">                  np.dot(y_F[<span class="number">1</span>], z_B),</span><br><span class="line">                  np.dot(y_F[<span class="number">2</span>], z_B),</span><br><span class="line">                  np.dot(y_F[<span class="number">3</span>], z_B)]  <span class="comment"># 4*4</span></span><br><span class="line">    x_y_w_grad = [np.dot(x_F[<span class="number">0</span>], y_B),</span><br><span class="line">                  np.dot(x_F[<span class="number">1</span>], y_B),</span><br><span class="line">                  np.dot(x_F[<span class="number">2</span>], y_B),</span><br><span class="line">                  np.dot(x_F[<span class="number">3</span>], y_B)]  <span class="comment"># 4*4</span></span><br><span class="line">    <span class="comment"># update</span></span><br><span class="line">    x_y_w = x_y_w - lr * np.array(x_y_w_grad)</span><br><span class="line">    y_z_w = y_z_w - lr * np.array(y_z_w_grad)</span><br><span class="line">    z_p_w = z_p_w - lr * np.array(z_p_w_grad)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> epoch % <span class="number">5000</span> == <span class="number">0</span>:</span><br><span class="line">        print(<span class="string">"当前loss值为"</span>)</span><br><span class="line">        print(loss_end)</span><br><span class="line">        print(p_F)</span><br><span class="line"></span><br><span class="line"><span class="comment">#截取输出片段打印</span></span><br><span class="line">当前loss值为</span><br><span class="line"><span class="number">165.06777280622663</span></span><br><span class="line">[<span class="number">8.38287281</span> <span class="number">5.70538503</span> <span class="number">7.00228248</span> <span class="number">5.84052431</span>]</span><br><span class="line">当前loss值为</span><br><span class="line"><span class="number">133.11940656598998</span></span><br><span class="line">[<span class="number">7.56299701</span> <span class="number">5.15781875</span> <span class="number">6.33931068</span> <span class="number">5.28536964</span>]</span><br><span class="line">当前loss值为</span><br><span class="line"><span class="number">109.77775387801975</span></span><br><span class="line">[<span class="number">6.89894847</span> <span class="number">4.7147705</span>  <span class="number">5.8028157</span>  <span class="number">4.83622736</span>]</span><br><span class="line">当前loss值为</span><br><span class="line"><span class="number">92.14372363473903</span></span><br><span class="line">[<span class="number">6.34836332</span> <span class="number">4.34779557</span> <span class="number">5.35839007</span> <span class="number">4.4642465</span> ]</span><br><span class="line">当前loss值为</span><br><span class="line"><span class="number">78.45934876430728</span></span><br><span class="line">[<span class="number">5.88318774</span> <span class="number">4.03806177</span> <span class="number">4.98325151</span> <span class="number">4.1503256</span> ]</span><br><span class="line">当前loss值为</span><br><span class="line"><span class="number">67.60388807433274</span></span><br><span class="line">[<span class="number">5.48405883</span> <span class="number">3.77257388</span> <span class="number">4.66167746</span> <span class="number">3.88128352</span>]</span><br><span class="line">当前loss值为</span><br><span class="line"><span class="number">58.833090378271265</span></span><br><span class="line">[<span class="number">5.13715314</span> <span class="number">3.54205652</span> <span class="number">4.38244476</span> <span class="number">3.64771203</span>]</span><br><span class="line">当前loss值为</span><br><span class="line"><span class="number">51.6356735906825</span></span><br><span class="line">[<span class="number">4.83232077</span> <span class="number">3.3397007</span>  <span class="number">4.13731374</span> <span class="number">3.44270456</span>]</span><br><span class="line"><span class="meta">... </span>... ... ... ... ... ... ... ... ... ... ...</span><br><span class="line">当前loss值为</span><br><span class="line"><span class="number">0.34148441938663887</span></span><br><span class="line">[<span class="number">0.38019982</span> <span class="number">0.42063884</span> <span class="number">0.60690939</span> <span class="number">0.49356868</span>]</span><br><span class="line">当前loss值为</span><br><span class="line"><span class="number">0.33762403308295663</span></span><br><span class="line">[<span class="number">0.37029135</span> <span class="number">0.41401346</span> <span class="number">0.59891746</span> <span class="number">0.48685882</span>]</span><br><span class="line">当前loss值为</span><br><span class="line"><span class="number">0.3343170568629769</span></span><br><span class="line">[<span class="number">0.36058041</span> <span class="number">0.40751086</span> <span class="number">0.5910724</span>  <span class="number">0.48027121</span>]</span><br><span class="line">当前loss值为</span><br><span class="line"><span class="number">0.3315343883568477</span></span><br><span class="line">[<span class="number">0.3510625</span>  <span class="number">0.40112821</span> <span class="number">0.58337076</span> <span class="number">0.47380298</span>]</span><br><span class="line">当前loss值为</span><br><span class="line"><span class="number">0.3292483287899748</span></span><br><span class="line">[<span class="number">0.3417333</span>  <span class="number">0.39486274</span> <span class="number">0.57580922</span> <span class="number">0.46745137</span>]</span><br></pre></td></tr></tbody></table></figure></div><p>以上代码可以看出，loss值不断不断的下降，并且最终趋于稳定，可以说明由之前的推导总结出的方法思路并无问题！</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Back Propagation </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Logistic Regression</title>
      <link href="/2020/02/11/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%B3%BB%E5%88%97-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"/>
      <url>/2020/02/11/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%B3%BB%E5%88%97-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><p>逻辑回归，是用于处理因变量为分类变量的回归问题，比如二分类问题，其实是一种分类算法。本文主要对比逻辑回归回归与线性回归的处理过程民兵探讨其中一些公式、细节。</p><h2 id="逻辑回归-amp-线性回归"><a href="#逻辑回归-amp-线性回归" class="headerlink" title="逻辑回归&线性回归"></a>逻辑回归&线性回归</h2><p><a href="https://user-images.githubusercontent.com/60562661/74258370-2bb15680-4d31-11ea-9d41-08b967ee8643.png" data-fancybox="group" data-caption="undefined" class="fancybox"><img style="zoom: 45%;" data-src="https://user-images.githubusercontent.com/60562661/74258370-2bb15680-4d31-11ea-9d41-08b967ee8643.png" class="lazyload"></a></p><p>如上图所示，</p><ul><li>step1确定函数时，逻辑回归函数输出的是个概率值，线性回归输出的可以是任何一个数</li><li>step2确定损失函数，逻辑回归用的<strong>交叉熵</strong>，线性回归则是均方误差</li><li><strong>step3比较神奇，两个损失函数长得差别很大，但是算到最后更新参数公式竟然是一样的！(后面有推导)</strong></li></ul><h2 id="Cross-Entropy"><a href="#Cross-Entropy" class="headerlink" title="Cross Entropy"></a>Cross Entropy</h2><p>背景，一系列函数设置：</p><p> <a href="https://user-images.githubusercontent.com/60562661/74258366-2b18c000-4d31-11ea-83e1-e5ba4074b47e.png" data-fancybox="group" data-caption="undefined" class="fancybox"><img style="zoom:40%;" data-src="https://user-images.githubusercontent.com/60562661/74258366-2b18c000-4d31-11ea-83e1-e5ba4074b47e.png" class="lazyload"></a></p><p>设计损失函数：这里有一个假设， x1 x2 …xN 属于 C1 类，真值为1，其余为0</p><p><a href="https://user-images.githubusercontent.com/60562661/74258376-2d7b1a00-4d31-11ea-96ba-0cc3210328f7.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/74258376-2d7b1a00-4d31-11ea-96ba-0cc3210328f7.png" class="lazyload"></a></p><p><strong>这里的之所以要取对数，是因为拆开之后求微分比较容易。</strong>蓝色线画的，即是交叉熵，也就是表格中step2的C函数。</p><p><a href="https://user-images.githubusercontent.com/60562661/74258361-26540c00-4d31-11ea-8693-ba5cdf8dbc64.png" data-fancybox="group" data-caption="undefined" class="fancybox"><img style="zoom:45%;" data-src="https://user-images.githubusercontent.com/60562661/74258361-26540c00-4d31-11ea-8693-ba5cdf8dbc64.png" class="lazyload"></a></p><p>上述函数对w求偏微分之后，也就是求出了梯度，（过程可以自己算一下，挺简单的），就得到了下面的公式，此时更新参数就和线性回归想同也推出来了。</p><h2 id="交叉熵和均方误差"><a href="#交叉熵和均方误差" class="headerlink" title="交叉熵和均方误差"></a>交叉熵和均方误差</h2><p><a href="https://user-images.githubusercontent.com/60562661/74258385-2f44dd80-4d31-11ea-907b-5b5c2bc25f78.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/74258385-2f44dd80-4d31-11ea-907b-5b5c2bc25f78.png" class="lazyload"></a></p><p>图中黑色曲面的代表<strong>交叉熵</strong>，红色的曲面代表<strong>均方误差</strong>，这幅图表达了参数的变化对于整个loss值的影响大小</p><ul><li>对于<strong>Cross Entropy</strong>，越边缘的点梯度越大，此时更新参数会比较快</li><li>对于 <strong>Square Error</strong>，边缘的点梯度并不大，而接近最小值的点梯度也比较小</li></ul><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>由上面的对比可知：逻辑回归如果用均方误差，会导致更新参数非常慢，而直接提高学习率也并不是一个好的选择，因为真正靠近真值时，梯度本来就比较小，较大的学习率此时也并不合理，因此一般来说，逻辑回归(也就是分类问题)可以采用交叉熵作为损失函数。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 逻辑回归 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>二维数组中的查找</title>
      <link href="/2020/02/11/%E7%89%9B%E5%AE%A2%E7%BD%91%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0-%E5%89%91%E6%8C%87offer%E7%B3%BB/"/>
      <url>/2020/02/11/%E7%89%9B%E5%AE%A2%E7%BD%91%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0-%E5%89%91%E6%8C%87offer%E7%B3%BB/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><p>自己最近正好有空，因此开始了刷题系列，牛客网上的剑指offer题目。今天记录一个比较有思想的题目。因为这些都是算法题目，如果去用穷举蒙混过关就没意思了，因此尽量找比较优化的算法。我这里用python来解答。</p><p>最近正好也是有空，因此开始了刷题系列，牛客网上的剑指offer题目。今天记录一个比较有思想的题目。因为这些都是算法题目，如果去用穷举蒙混过关就没意思了，因此尽量找比较优化的算法。我这里用python来解答。</p><h2 id="题目："><a href="#题目：" class="headerlink" title="题目："></a>题目：</h2><p><code>在一个二维数组中（每个一维数组的长度相同），每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。</code></p><h2 id="思路："><a href="#思路：" class="headerlink" title="思路："></a>思路：</h2><h4 id="思路一："><a href="#思路一：" class="headerlink" title="思路一："></a>思路一：</h4><p>因为数组的有序性，从左到右从上到下递增，利用这一个规律，选取左下角的数为基点，如果目标数大于该数，那么目标肯定在基点的右边，所以 <strong>column + 1 </strong>; 如果目标小于基点数，那么 <strong>row - 1 </strong>。</p><p>逻辑是这样，每移动一次，都会以目前所在的点为基点，因此会排除一行或者一列，这种复杂度就会比较低了。‘</p><h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="comment"># array 二维列表</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">Find</span><span class="params">(self, target, array)</span>:</span></span><br><span class="line">        hang = len(array)</span><br><span class="line">        lie = len(array[<span class="number">0</span>])</span><br><span class="line">        i = hang - <span class="number">1</span></span><br><span class="line">        j = <span class="number">0</span></span><br><span class="line">        result = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">while</span>(i>=<span class="number">0</span> <span class="keyword">and</span> j<lie):< span><br><span class="line">            <span class="keyword">if</span> target < array[i][j]:</span><br><span class="line">                i = i - <span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> target > array[i][j]:</span><br><span class="line">                j = j + <span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> target == array[i][j]:</span><br><span class="line">                result = <span class="literal">True</span></span><br><span class="line">                <span class="keyword">return</span> result</span><br><span class="line">        <span class="keyword">return</span> result</span><br></lie):<></span></pre></td></tr></tbody></table></figure></div><h4 id="思路二："><a href="#思路二：" class="headerlink" title="思路二："></a>思路二：</h4><p>遍历每一行用二分查找法，这个代码还没写，所以明天补上，这种方法比较通俗易懂。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数组查找 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>模型的误差来源及其改进</title>
      <link href="/2020/02/11/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%B3%BB%E5%88%97-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%AF%AF%E5%B7%AE%E6%9D%A5%E8%87%AA%E5%93%AA%E9%87%8C/"/>
      <url>/2020/02/11/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%B3%BB%E5%88%97-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%AF%AF%E5%B7%AE%E6%9D%A5%E8%87%AA%E5%93%AA%E9%87%8C/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><p>之前文章讲到过用梯度下降法来更新参数。深度学习反向传播，根据误差调整参数，那么深度学习的<code>error</code>到底来自哪里？这个是比较必要的，可以给我们提高自己的模型提供方案。</p><p>这个李宏毅老师讲的很清楚，有需要可以学习一下，附上链接:<a href="https://www.bilibili.com/video/av48285039?p=8" target="_blank" rel="noopener">https://www.bilibili.com/video/av48285039?p=8</a></p><h2 id="Error来源概述"><a href="#Error来源概述" class="headerlink" title="Error来源概述"></a>Error来源概述</h2><p>深度学习种<code>Error</code> 来源于两方面：</p><ul><li><strong>bias</strong> 偏置</li><li><strong>variance</strong> 方差</li></ul><p><a href="https://user-images.githubusercontent.com/60562661/74254221-1cc7a580-4d2b-11ea-9b91-35b7d92a3efc.png" data-fancybox="group" data-caption="undefined" class="fancybox"><img style="zoom:50%;" data-src="https://user-images.githubusercontent.com/60562661/74254221-1cc7a580-4d2b-11ea-9b91-35b7d92a3efc.png" class="lazyload"></a></p><h2 id="Variance"><a href="#Variance" class="headerlink" title="Variance"></a>Variance</h2><p>直观上，方差可以了解为散布的分散程度。上图可以明显的看出比较高的方差，点的散布很分散，比较低的方差则比较紧凑。方差可以用来形容模型的稳定性。一般来说，</p><p>比较<strong>简单</strong>的模型，方差较<strong>小</strong>，分布比较<strong>紧密</strong>；比较<strong>复杂</strong>的模型，方差比较<strong>大</strong>，分布比较<strong>分散</strong></p><p>可以如下解释：</p><ul><li>比较简单的模型，比如 f(x) = c，受数据的影响为0，因此所有值相同，方差为0，分布都在一起</li><li>比价复杂的模型，比如五次方方程，受到数据的影响会比较大，取到的值很多，因此每次的预测值可能相差很远，此时方差就比较大了</li></ul><h2 id="Bias"><a href="#Bias" class="headerlink" title="Bias"></a>Bias</h2><p>将所有预测出来的函数求出期望值得到的函数距离真实函数依然会有一段距离，这就是<strong>bias</strong>，如下图所示，</p><p><code>红线表示100个预测出来的函数，蓝线表示这100个函数的平均，黑线表示真实函数</code></p><p><a href="https://user-images.githubusercontent.com/60562661/74254439-6912e580-4d2b-11ea-881f-9cfd6cbbafc9.png" data-fancybox="group" data-caption="undefined" class="fancybox"><img style="zoom: 50%;" data-src="https://user-images.githubusercontent.com/60562661/74254439-6912e580-4d2b-11ea-881f-9cfd6cbbafc9.png" class="lazyload"></a></p><p>可以看出，<strong>简单</strong>的模型bias比较<strong>大</strong>，而<strong>复杂</strong>的模型bias比较<strong>小</strong></p><p>可以解释为，上图的底部，<strong>我们所设计模型的复杂程度其实也就决定了函数所能表达的范围</strong>，过于简单的函数所包含的范围可能根本没有包含到真值，因此bias比较大；而比较复杂的函数范围比较大，包含到了真值，因此bias会比较小。</p><h2 id="比较"><a href="#比较" class="headerlink" title="比较"></a>比较</h2><div class="table-container"><table><thead><tr><th>模型复杂程度</th><th>方差 Variance(精确性)</th><th>偏置Bias(准确性)</th></tr></thead><tbody><tr><td>Simple Model</td><td>较小</td><td>较大</td></tr><tr><td>Complex Model</td><td>较大</td><td>较小</td></tr></tbody></table></div><h2 id="总结与改进"><a href="#总结与改进" class="headerlink" title="总结与改进"></a>总结与改进</h2><p>了解了误差的来源，那么如何判断自己的模型是什么问题呢？</p><ul><li><p>如果模型无法适应训练数据，也就是说在<strong>训练集上误差比较大</strong>，此时就是 <strong>bias</strong> 比较大，此时处于<strong>欠拟合状态，（underfitting）</strong>也就是模型过于简单，此时改进：</p><ul><li>载入更多的特征</li><li>创建更复杂的模型</li><li><strong>注意，此时收集数据集增加数据集并起不到作用</strong></li></ul></li><li><p>如果模型在训练集表现得很好，但是在测试集表现得很差，此时就是<strong>Variance比较大</strong>，也就是<strong>过拟合（overfitting）</strong>了，此时改进：</p><ul><li>增加数据集，对于过拟合是一个很好的解决办法，如果采集不到更多的数据，则可以利用现有的数据去生成更多新的数据</li><li><strong>Regularization</strong> 正则化 ，正则化的效果是使得到的曲线更加的平滑，如下图</li></ul></li></ul><p><a href="https://user-images.githubusercontent.com/60562661/74254459-6dd79980-4d2b-11ea-950a-df5101cc68af.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/74254459-6dd79980-4d2b-11ea-950a-df5101cc68af.png" class="lazyload"></a></p><h2 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h2><p>以线性回归为例，在损失函数的最后加上一项 参数 <strong>wi的平方和</strong>，这就会要求w越小越好，起到限制作用</p><p><a href="https://user-images.githubusercontent.com/60562661/74254484-77f99800-4d2b-11ea-8a9b-d9a6e32b63cf.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/74254484-77f99800-4d2b-11ea-8a9b-d9a6e32b63cf.png" class="lazyload"></a></p><ul><li>此时函数会比较平滑，平滑即对输入不会非常敏感，至于为什么会比较平滑，可以看上图下面部分，当xi 变化时，输出结果就加了一项 wi * 变化量， 若wi 很小接近0，对结果影响并不大，因此会比较平滑。</li><li><p>“莱姆大” 正则化项的系数控制了函数的平滑程度，函数不是月平滑越好，有个度，因此有一个系数控制</p></li><li><p>对于偏置b，不用加正则化项是因为 ： 正则化使得函数更加平滑，能过滤掉杂色信息，而偏置 b 只能使得函数上下移动，对本来的目的并没有帮助。因此正则化项没有偏置 b 。</p></li></ul></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ERROR </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>梯度下降法 ②_学习率</title>
      <link href="/2020/02/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%B3%BB%E5%88%97%E4%B8%80-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95-%E2%91%A1/"/>
      <url>/2020/02/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%B3%BB%E5%88%97%E4%B8%80-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95-%E2%91%A1/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><h1 id="梯度下降法及其优化"><a href="#梯度下降法及其优化" class="headerlink" title="梯度下降法及其优化"></a>梯度下降法及其优化</h1><p>在上一篇文章中已经讲述了梯度下降法的基本流程，也讲了梯度下降法存在的问题，这篇文章就来继续讲解梯度下降法的后续。</p><p>前一篇文章提到学习率的问题，如果学习率过大会导致震荡而难以收敛，过小的话又会收敛太慢，耗费时间，因此出现了Adagrad.</p><h2 id="Tip1：Adaptive-Learning-Rate"><a href="#Tip1：Adaptive-Learning-Rate" class="headerlink" title="Tip1：Adaptive Learning Rate"></a>Tip1：Adaptive Learning Rate</h2><p>学习率对于参数调整影响很大，因此需要仔细地调整，手动调节参数肯定是不太现实，而自适应的调整参数有以下两个原则：</p><ul><li>开始阶段学习率比较大</li><li>随着迭代次数的增加越来越小</li></ul><h2 id="Adagrad-Gradient-Descent"><a href="#Adagrad-Gradient-Descent" class="headerlink" title="Adagrad Gradient Descent"></a>Adagrad Gradient Descent</h2><h3 id="与Gradient-Descent的比较"><a href="#与Gradient-Descent的比较" class="headerlink" title="与Gradient Descent的比较"></a>与Gradient Descent的比较</h3><p><a href="https://user-images.githubusercontent.com/60562661/74164696-17048e00-4c5f-11ea-8f27-b56011c83c1a.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/74164696-17048e00-4c5f-11ea-8f27-b56011c83c1a.png" class="lazyload"></a></p><h3 id="数学公式推导"><a href="#数学公式推导" class="headerlink" title="数学公式推导"></a>数学公式推导</h3><p>原始学习率变成了 <code>常数/梯度的平方和开根号</code>，这个公式也是又推导过程的，如下(笔记字比较丑)：</p><p><a href="https://user-images.githubusercontent.com/60562661/74164719-1cfa6f00-4c5f-11ea-985b-cca1a74e4a77.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/74164719-1cfa6f00-4c5f-11ea-985b-cca1a74e4a77.png" class="lazyload"></a></p><h3 id="其中的矛盾"><a href="#其中的矛盾" class="headerlink" title="其中的矛盾"></a>其中的矛盾</h3><p>观察最后一步，可以看出后面的  <strong>梯度 </strong> 和  <strong>分母的梯度的平方和开根号 </strong> （最后一行红笔画出来的）是矛盾的，梯度越大，分母也会越大，约束整个函数，但是效果会比较好。这个可以解释为，不只是考虑了一阶偏导数g(t),同时也考虑了二阶偏导数，所以结果会更加准确。(具体的可以参考李宏毅深度学习视频，前一篇文章有提到。)</p><h3 id="Adagrad总结"><a href="#Adagrad总结" class="headerlink" title="Adagrad总结"></a>Adagrad总结</h3><p>Adagrad梯度下降法其实是实现了自适应的去调节学习率，不在需要手动的仔细去调节。</p><h2 id="Tip2：Stochastic-Gradient-Descent"><a href="#Tip2：Stochastic-Gradient-Descent" class="headerlink" title="Tip2：Stochastic Gradient Descent"></a>Tip2：Stochastic Gradient Descent</h2><p>随机梯度下降法也是比较常见的，是梯度下降法的一种变体，改变也不多，它与梯度下降法的不同之处在于：</p><p>​        假设有十组训练数据，也就是十个函数，梯度下降法会把每一组参数带进去计算损失求和，每组参数的梯度也相应会进行求和嘛，然后才更新一次参数；随机梯度下降法不再需要求和这一过程，即随便一组数据带入损失函数求出梯度直接更新参数。</p><p>这种方法听起来也比较一般，它的主要优点在于<strong>更新参数快，</strong>  天下武功，唯快不破嘛。</p><h2 id="Tip3：Feature-scaling"><a href="#Tip3：Feature-scaling" class="headerlink" title="Tip3：Feature scaling"></a>Tip3：Feature scaling</h2><p>特征归一化。在做梯度下降法时，只要梯度分不一样，可以归一化之后在做，主要是因为如果某一个特征值非常大，那么它所占的比重就会非常大，这对学习非常不利。</p><p>常用的一个归一化方法：</p><p>对于特征 x1,x2,x3······xn,每种特征的某一个维度求一下这列数的均值和标准差，然后原始数据减去均值除以标准差即可归一化，如下图：</p><p><a href="https://user-images.githubusercontent.com/60562661/74164700-18ce5180-4c5f-11ea-880f-770b8016f100.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/74164700-18ce5180-4c5f-11ea-880f-770b8016f100.png" class="lazyload"></a></p><p><strong>这样做之后这一维数据就会服从均值为0，方差为1的高斯分布。</strong></p><h2 id="Code-梯度下降法python实现"><a href="#Code-梯度下降法python实现" class="headerlink" title="Code:梯度下降法python实现"></a>Code:梯度下降法python实现</h2><h3 id="背景："><a href="#背景：" class="headerlink" title="背景："></a>背景：</h3><p><strong>函数（model）</strong>：y = w1<em> x^2 + w2</em>x + b ,计算出参数 w1 w2 b，给顶的真值是w1_truth = 1.8，w2_truth=2.4，b_truth = 5.6</p><p><strong>loss function</strong>   ：均方误差，公式写出太麻烦，就是y的真实值减去y的预测值的平方和</p><h3 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#写一个深度学习的回归案例</span></span><br><span class="line"><span class="comment">#y = w1*x^2 + w2*x + b ,计算出参数 w1 w2 b</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment">#生成数据 </span></span><br><span class="line">x_data = np.random.rand(<span class="number">10</span>)</span><br><span class="line">w1_truth = <span class="number">1.8</span></span><br><span class="line">w2_truth = <span class="number">2.4</span></span><br><span class="line">b_truth = <span class="number">5.6</span></span><br><span class="line">y_data = np.random.rand(<span class="number">10</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    y_data[i] = w1_truth*x_data[i]*x_data[i] + w2_truth*x_data[i] + b_truth</span><br><span class="line">print(y_data.shape)</span><br><span class="line">print(x_data.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置参数</span></span><br><span class="line">w1 = <span class="number">6</span></span><br><span class="line">w2 = <span class="number">4</span></span><br><span class="line">b = <span class="number">8</span></span><br><span class="line">lr = <span class="number">1</span></span><br><span class="line">steps = <span class="number">100000</span></span><br><span class="line">lr_w1 = <span class="number">0</span></span><br><span class="line">lr_w2 = <span class="number">0</span></span><br><span class="line">lr_b = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(steps):</span><br><span class="line">    w1_grad = <span class="number">0</span></span><br><span class="line">    w2_grad = <span class="number">0</span></span><br><span class="line">    b_grad = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        w1_grad = w1_grad - <span class="number">2</span>*(y_data[i] - b-w1*x_data[i]*x_data[i]-w2*x_data[i])* (x_data[i]**<span class="number">2</span>)</span><br><span class="line">        w2_grad = w2_grad - <span class="number">2</span>*(y_data[i] - b-w1*x_data[i]*x_data[i]-w2*x_data[i])* x_data[i]</span><br><span class="line">        b_grad = b_grad - <span class="number">2</span>*(y_data[i] - b-w1*x_data[i]*x_data[i]-w2*x_data[i])* <span class="number">1.0</span></span><br><span class="line">    lr_w1 = lr_w1 + w1_grad**<span class="number">2</span></span><br><span class="line">    lr_w2 = lr_w2 + w2_grad**<span class="number">2</span></span><br><span class="line">    lr_b = lr_b + b_grad**<span class="number">2</span></span><br><span class="line">    <span class="comment"># update</span></span><br><span class="line">    w1 = w1 - lr/np.sqrt(lr_w1) * w1_grad</span><br><span class="line">    w2 = w2 - lr/np.sqrt(lr_w2) * w2_grad</span><br><span class="line">    b  = b  - lr/np.sqrt(lr_b) * b_grad</span><br><span class="line">print(<span class="string">"w1= %f,w2 = %f, b= %f"</span> % (w1,w2,b))</span><br><span class="line"><span class="comment">#以下是代码的输出结果，可以自己测试一下，完美找到了真实值</span></span><br><span class="line"><span class="comment"># w1= 1.800000,w2 = 2.400000, b= 5.600000</span></span><br></pre></td></tr></tbody></table></figure></div><h3 id="代码中的一些细节"><a href="#代码中的一些细节" class="headerlink" title="代码中的一些细节"></a><strong>代码中的一些细节</strong></h3><ul><li><p>以上代码如果只用一个学习率，收敛会很慢，而且10万个迭代也不会迭代导最终结果，差距还是比较大的，因此代码用的是Adagrad梯度下降法，纯粹手工实现的，可以完美的预测出结果</p></li><li><p>至于代码中的计算 w1 w2 b 的梯度公式，可以手工推导出来，如下图：</p></li></ul><p><a href="https://user-images.githubusercontent.com/60562661/74164747-24217d00-4c5f-11ea-8506-fdaf73f9c02d.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/74164747-24217d00-4c5f-11ea-8506-fdaf73f9c02d.png" class="lazyload"></a></p></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 梯度下降法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>梯度下降法 ①_概述</title>
      <link href="/2020/02/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%B3%BB%E5%88%97%E4%B8%80-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/"/>
      <url>/2020/02/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8%E7%B3%BB%E5%88%97%E4%B8%80-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><p>我是研究CV方向的，但是深度学习我只是在学习Tensorflow书的时候学过里面的东西，很多东西讲的过于简单，理解并不直观，所以最近就在学习深度学习的视频，是李宏毅老师讲的，内容很生动，解决了我很多疑惑，附上视频地址->，看视频就要跟着老师推导一遍公式，也是理解了很多内在的东西。</p><p><strong>bilibili</strong> : <a href="https://www.bilibili.com/video/av48285039?p=43" target="_blank" rel="noopener">https://www.bilibili.com/video/av48285039?p=43</a></p><p><strong>Youtube</strong>: <a href="https://www.youtube.com/watch?v=D_S6y0Jm6dQ" target="_blank" rel="noopener">https://www.youtube.com/watch?v=D_S6y0Jm6dQ</a></p><h2 id="概述：深度学习流程"><a href="#概述：深度学习流程" class="headerlink" title="概述：深度学习流程"></a>概述：深度学习流程</h2><p>深度学习过程于机器学习类似，这里就先讲一下机器学习的，深度学习后面会讲到。对于一个特定的<strong>机器学习</strong> <code>Machine Learning</code>任务，简单来说有以下固定的三个步骤：</p><ul><li><p><strong>定义</strong>一系列的函数 ；</p></li><li><p>评价函数的好坏，也就是定义损失函数；</p></li><li><p>找出最好的函数(model)</p></li></ul><p><a href="https://user-images.githubusercontent.com/60562661/74164678-14099d80-4c5f-11ea-961c-fd913422405a.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/74164678-14099d80-4c5f-11ea-961c-fd913422405a.png" class="lazyload"></a></p><p>在定义好函数和确定损失函数之后，就要开始调整参数。这时候就需要用到<strong>梯度下降法</strong>了。</p><h2 id="梯度下降法概述"><a href="#梯度下降法概述" class="headerlink" title="梯度下降法概述"></a>梯度下降法概述</h2><p>调整参数就是为了师让损失函数最小，也就是选择出最好的函数 （Model）。先讲一下梯度下降法更新参数的真个流程。</p><h3 id="梯度"><a href="#梯度" class="headerlink" title="梯度"></a>梯度</h3><p>首先，梯度Gradient，就是在这一点的微分（偏导数），也就是曲线在该点切线的斜率，高等数学就有讲过；不理解微分就可以当作是等高线图的法线方向。梯度代表了函数上升最快的方向，所以一个函数在一点求出梯度，然后按照梯度的反方向偏移就是减小最快的。</p><p><strong>所以这里也可以得知，首先需要一个可微的函数。</strong></p><h3 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h3><p><a href="https://user-images.githubusercontent.com/60562661/74164735-208df600-4c5f-11ea-842d-dd446164c461.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/74164735-208df600-4c5f-11ea-842d-dd446164c461.png" class="lazyload"></a></p><ol><li><p>假设对于参数w，要更新w，首先要初始化w的值，可以随机初始化一个值，当然也有其他方法这里并不关心</p></li><li><p>计算损失函数 Loss function，L(·)对于参数w在该点处的偏导数，这就是函数在这一点的梯度。为什么是偏导数，因为参数不只是w一个，也有bias偏置b。</p></li><li><p>计算出梯度就知道在那个方向上损失函数降幅最大，就开始更新参数，直到一个局部最小值。</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">w_new = w_original - lr*w_original_graident</span><br></pre></td></tr></tbody></table></figure></div></li><li><p>重复 <strong>2、3</strong> 步骤，就可以不断调整参数</p></li></ol><p><strong>Note :</strong> </p><ul><li>上述伪代码中有一个 lr参数，这是学习率Learning Rate，学习率决定了每次下降的步长，学习率影响还是比较大的，过小需要的时间太久，过大的话又会震荡不能收敛，这也是梯度下降法的一个存在的问题，后续会继续讲。</li><li>上述第三步提到会函数会降低到局部最小值，这里整个是以线性函数为例，故不用考虑是否会降到局部最小值。</li></ul><hr><h3 id="关于梯度下降法，第二篇文章会继续讲解一些细节及其优化。"><a href="#关于梯度下降法，第二篇文章会继续讲解一些细节及其优化。" class="headerlink" title="关于梯度下降法，第二篇文章会继续讲解一些细节及其优化。"></a>关于梯度下降法，第二篇文章会继续讲解一些细节及其优化。</h3></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 梯度下降法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo_blog搭建2-主题相关</title>
      <link href="/2020/02/09/hexo-blog%E6%90%AD%E5%BB%BA2-%E4%B8%BB%E9%A2%98%E7%9B%B8%E5%85%B3/"/>
      <url>/2020/02/09/hexo-blog%E6%90%AD%E5%BB%BA2-%E4%B8%BB%E9%A2%98%E7%9B%B8%E5%85%B3/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><p>我的这个版本博客是基于Hexo搭建的，主题采用的是 <a href="https://jerryc.me/posts/21cfbf15/#" target="_blank" rel="noopener">Butterfly</a>，在这个网址有详细的安装配置教程。 这个主题我非非常喜欢，看了很多的主题就相中了这款。然而配置也是花了我整整一天，可能还算是比较顺利把！配置过程中有的地方安装文档讲的不是很详细，我自己也踩坑了，来记录一下！</p><p> <a href="https://user-images.githubusercontent.com/60562661/74105856-93826880-4b9c-11ea-8629-4b1b724d54f4.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/74105856-93826880-4b9c-11ea-8629-4b1b724d54f4.png" class="lazyload"></a></p><h2 id="添加-Gallery（相册）"><a href="#添加-Gallery（相册）" class="headerlink" title="添加 Gallery（相册）"></a>添加 Gallery（相册）</h2><h3 id="新建页面"><a href="#新建页面" class="headerlink" title="新建页面"></a>新建页面</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bash</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo new page gallery <span class="comment">#此时会在source目录下产生gallery/index.md</span></span><br></pre></td></tr></tbody></table></figure></div><p>打开来编辑这个md文件，有两点要注意的：</p><ul><li>开头的 <strong>type: “gallery”</strong>   不能出错</li><li>内容格式 按照  <strong><div class="justified-gallery"><p>img1  img2  img3 </p>          </div></strong>    来写</li></ul><p><a href="https://user-images.githubusercontent.com/60562661/74105571-12c26d00-4b9a-11ea-8e58-9cb4520896fd.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/74105571-12c26d00-4b9a-11ea-8e58-9cb4520896fd.png" class="lazyload"></a></p><h3 id="添加导航栏"><a href="#添加导航栏" class="headerlink" title="添加导航栏"></a>添加导航栏</h3><p>在 butterfly.yml 文件的menu下照着之前的添加相册，如下图</p><p><a href="https://user-images.githubusercontent.com/60562661/74105539-d5f67600-4b99-11ea-83f1-f856a034b9b3.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/74105539-d5f67600-4b99-11ea-83f1-f856a034b9b3.png" class="lazyload"></a></p><p>至此，相册添加结束</p><h2 id="添加本地搜索"><a href="#添加本地搜索" class="headerlink" title="添加本地搜索"></a>添加本地搜索</h2><h3 id="安装hexo本地搜索的插件"><a href="#安装hexo本地搜索的插件" class="headerlink" title="安装hexo本地搜索的插件"></a>安装hexo本地搜索的插件</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bash</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-generator-searchdb --save</span><br></pre></td></tr></tbody></table></figure></div><h3 id="配置全局的config文件"><a href="#配置全局的config文件" class="headerlink" title="配置全局的config文件"></a>配置全局的config文件</h3><p><a href="https://user-images.githubusercontent.com/60562661/74105544-da229380-4b99-11ea-8ba8-7715f23704b9.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/74105544-da229380-4b99-11ea-8ba8-7715f23704b9.png" class="lazyload"></a></p><h3 id="配置butterfly文件"><a href="#配置butterfly文件" class="headerlink" title="配置butterfly文件"></a>配置butterfly文件</h3><p>这里的配置和官方教程一样，不再赘述</p><h3 id="踩坑"><a href="#踩坑" class="headerlink" title="踩坑"></a>踩坑</h3><p>我自己在这里一直配置不好，刚开始发现是找不到 search.xml 文件，后来我在博客插件目录找到了，然后改上图的path，这样在本地启动blog是可以搜索的，但是推送到远程就不行了，后面我重装了插件，path改成默认路径,然后 <code>hexo clean</code>  <code>hexo g</code> <code>hexo d</code>  就很神奇的在github仓库生成了search.xml文件，也就随之可以用了，具体原理我还没搞明白，以后明白了再更新。</p><h2 id="添加评论"><a href="#添加评论" class="headerlink" title="添加评论"></a>添加评论</h2><p>我用的是 Valine 评论系统，这个很容易搭建起来，大致描述一下流程：</p><h3 id="配置-valine"><a href="#配置-valine" class="headerlink" title="配置 valine"></a>配置 valine</h3><ol><li><p>注册 <a href="https://www.leancloud.cn/" target="_blank" rel="noopener">https://www.leancloud.cn/</a> 在这个网站注册账号，然后进行实名认证</p></li><li><p>创建一个应用</p></li><li><p>进入设置页面，在应用keys中可以看到自己的 <strong>AppID</strong> <strong>AppKey</strong>   等会儿会用到</p></li><li><p><strong>在安全中心页面 web安全域名写入自己的博客域名</strong>（这一步很重要，我就是一开始在这里栽了）</p><p><strong>至此，valine配置结束</strong></p></li></ol><h3 id="配置主题文件"><a href="#配置主题文件" class="headerlink" title="配置主题文件"></a>配置主题文件</h3><p>这里的流程和官方教程一样，很容易，自己直接会明白</p><p><strong>我在这里卡住是因为写 APPID APPKey出了问题，卡了很久才发现</strong></p><p>然后重新更新生成就有了评论功能！</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 博客 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> blog </tag>
            
            <tag> 博客主题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>拥有自己优雅的图床</title>
      <link href="/2020/02/09/%E6%8B%A5%E6%9C%89%E8%87%AA%E5%B7%B1%E4%BC%98%E9%9B%85%E7%9A%84%E5%9B%BE%E5%BA%8A/"/>
      <url>/2020/02/09/%E6%8B%A5%E6%9C%89%E8%87%AA%E5%B7%B1%E4%BC%98%E9%9B%85%E7%9A%84%E5%9B%BE%E5%BA%8A/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><p> 图床，就是专门用来存放图片的空间，不过与本地不同，图床是存储在网络上的。这样图片会有个地址，可以访问到图片，也可以引用。如果写个人博客等等肯定用得上。github这个天然的图床不用就太可惜了！ 所以选择github来作为自己图床。</p><p><a href="https://user-images.githubusercontent.com/60562661/74098587-0831b480-4b55-11ea-992f-e7dd9181abe7.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/74098587-0831b480-4b55-11ea-992f-e7dd9181abe7.png" class="lazyload"></a></p><h2 id="仓库准备"><a href="#仓库准备" class="headerlink" title="仓库准备"></a>仓库准备</h2><p>可以新建一个仓库，也可以在现有的仓库下。具体怎么建仓库请自己寻找。</p><p><strong>下面以我自己的仓库为例</strong></p><p><a href="https://user-images.githubusercontent.com/60562661/74098589-09fb7800-4b55-11ea-9ac8-6995b63f32e4.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/74098589-09fb7800-4b55-11ea-9ac8-6995b63f32e4.png" class="lazyload"></a></p><h2 id="进入issues新建问题"><a href="#进入issues新建问题" class="headerlink" title="进入issues新建问题"></a>进入issues新建问题</h2><p>点击issues，然后点击右上角NewIssues，进入如下界面</p><p><a href="https://user-images.githubusercontent.com/60562661/74098590-0a940e80-4b55-11ea-9157-59279231e403.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/74098590-0a940e80-4b55-11ea-9157-59279231e403.png" class="lazyload"></a></p><p>关键部分红色框已经框出来，可以在这里上传自己的图片，然后点击提交即可，图下图</p><p><a href="https://user-images.githubusercontent.com/60562661/74098591-0b2ca500-4b55-11ea-8540-b66aafb27fa7.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/74098591-0b2ca500-4b55-11ea-8540-b66aafb27fa7.png" class="lazyload"></a></p><p>此时点击图片，即可打开一个新的链接，此时图片的网址就可以被引用了。</p><p><strong>Enjoy！</strong></p></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 图床 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 图床 </tag>
            
            <tag> github </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>自己的域名与github绑定</title>
      <link href="/2020/02/06/%E8%87%AA%E5%B7%B1%E7%9A%84%E5%9F%9F%E5%90%8D%E4%B8%8Egithub%E7%BB%91%E5%AE%9A/"/>
      <url>/2020/02/06/%E8%87%AA%E5%B7%B1%E7%9A%84%E5%9F%9F%E5%90%8D%E4%B8%8Egithub%E7%BB%91%E5%AE%9A/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><p>一般情况下用github托管的博客很方便，但是域名访问只能用 <a href="https://xxxx.github.io来访问，这时候就有与自己的域名绑定的问题，即自己的域名指向github地址。（以腾讯云为例）" target="_blank" rel="noopener">https://xxxx.github.io来访问，这时候就有与自己的域名绑定的问题，即自己的域名指向github地址。（以腾讯云为例）</a></p><p><a href="https://user-images.githubusercontent.com/60562661/73957566-7ef66400-4941-11ea-87ee-e9c53fdbc305.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/73957566-7ef66400-4941-11ea-87ee-e9c53fdbc305.png" class="lazyload"></a></p><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><p>开始操作前，确保自己已经有：</p><ul><li><strong>可用</strong>的域名：注意不需要备案（我的是这样），但是大多数需要实名认证</li><li>有自己的<strong>github</strong>项目地址，确保可以访问</li></ul><h2 id="域名解析"><a href="#域名解析" class="headerlink" title="域名解析"></a>域名解析</h2><p>进入腾讯云控制台，在自己的域名解析处设置如下：</p><p><a href="https://user-images.githubusercontent.com/60562661/73957562-7dc53700-4941-11ea-81f5-472730958808.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/73957562-7dc53700-4941-11ea-81f5-472730958808.png" class="lazyload"></a></p><p>这里要注意两点：</p><ul><li>记录类型选择 <strong>CNAME</strong></li><li>记录值为自己的github项目地址（<strong>github域名</strong>）</li></ul><p>此时如果解析成功，<strong>ping</strong>一下测试：</p><p><a href="https://user-images.githubusercontent.com/60562661/73957564-7e5dcd80-4941-11ea-93c1-501060db97b2.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/73957564-7e5dcd80-4941-11ea-93c1-501060db97b2.png" class="lazyload"></a></p><h2 id="github仓库设置"><a href="#github仓库设置" class="headerlink" title="github仓库设置"></a>github仓库设置</h2><p>进入github项目仓库设置，往下翻在 Github Page 中自定义地址写自己的域名 然后保存，此时主页会自动生成 CNAME 文件，如下图：</p><p><a href="https://user-images.githubusercontent.com/60562661/73957559-7c940a00-4941-11ea-8f4c-b56ac851d659.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/73957559-7c940a00-4941-11ea-8f4c-b56ac851d659.png" class="lazyload"></a></p><h2 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h2><h3 id="等待时间"><a href="#等待时间" class="headerlink" title="等待时间"></a>等待时间</h3><p>等待10-15min，就可以通过自己的域名来访问了。注意能ping通说明已经成功，此时就不要频繁修改设置了，影响同步 时间</p><h3 id="普适性"><a href="#普适性" class="headerlink" title="普适性"></a>普适性</h3><p>以上流程在hugo博客上毫无问题，原因是hugo博客推送到服务器是推送public中的内容，而CNAME在根目录并不会影响；</p><p>但是在hexo博客上就有问题了，我查了一下发现如果直接在gtihub直接指定，会在github仓库上直接生成CNAME文件，而这时候有个问题就是在写文章同步的话，本地并没有CNAME文件，会直接覆盖掉已经生成的CNAME 文件，此时指定的域名就不生效了。因此有了以下的章节。</p><h2 id="Hexo博客绑定域名"><a href="#Hexo博客绑定域名" class="headerlink" title="Hexo博客绑定域名"></a>Hexo博客绑定域名</h2><p>首先在本地 博客根目录中source文件夹下新建一个CNAME文件，内容就是自己的域名，然后再按照上面去github指定。</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 部署 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 域名 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>从0开始搭建私人云盘</title>
      <link href="/2020/02/06/%E4%BB%8E0%E5%BC%80%E5%A7%8B%E6%90%AD%E5%BB%BA%E7%A7%81%E4%BA%BA%E4%BA%91%E7%9B%98/"/>
      <url>/2020/02/06/%E4%BB%8E0%E5%BC%80%E5%A7%8B%E6%90%AD%E5%BB%BA%E7%A7%81%E4%BA%BA%E4%BA%91%E7%9B%98/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><p>现在的云盘有很多，百度云、蓝奏云、腾讯微云等等，看起来似乎是没有搭建云盘的必要，但是百度云限速让我觉得恶心，不开超级会员就非常非常非常慢，开了又觉得亏，所以就想到了能不能自己搭建一个云盘。自己搭建的私有云还有一个特点就是比较安全，其实只是自己比较喜欢乱鼓捣新东西。现在的下载速度并不快，我还没研究，但是上传速度经过修改可以达到2M/s以上，其实我的云服务器比较垃圾，毕竟是1块钱白嫖了一个月—。</p><p><strong>先上链接：</strong></p><p><a href="http://111.229.74.50/kodexplorer/index.php?explorer" target="_blank" rel="noopener">http://111.229.74.50/kodexplorer/index.php?explorer</a></p><p><a href="https://user-images.githubusercontent.com/60562661/73954603-02618680-493d-11ea-9ebd-b33ee3002b8e.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/73954603-02618680-493d-11ea-9ebd-b33ee3002b8e.png" class="lazyload"></a></p><h2 id="购买一个云服务器"><a href="#购买一个云服务器" class="headerlink" title="购买一个云服务器"></a>购买一个云服务器</h2><p>云服务器性能越好，与上传下载速度都有很大关系，结合自己个人需求、经济状况适当购买。当然也可以先白嫖一个用用体验一下。购买云服务器国内比较火的也就几个：<strong>阿里云，腾讯云，京东云，华为云。</strong>我用的腾讯云的服务器。<strong>↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓ ↓</strong></p><p><a href="https://user-images.githubusercontent.com/60562661/73954616-068da400-493d-11ea-9634-e7cad5cde6eb.png" data-fancybox="group" data-caption="photo" class="fancybox"><img alt="photo" title="photo" data-src="https://user-images.githubusercontent.com/60562661/73954616-068da400-493d-11ea-9634-e7cad5cde6eb.png" class="lazyload"></a></p><h2 id="开始配置服务器"><a href="#开始配置服务器" class="headerlink" title="开始配置服务器"></a>开始配置服务器</h2><p><strong>Note：服务器以windows操作系统为例；本私有云基于可道云kodexplorer</strong></p><h3 id="远程登陆到服务器"><a href="#远程登陆到服务器" class="headerlink" title="远程登陆到服务器"></a>远程登陆到服务器</h3><p>以腾讯云为例，上图中主机后面就有登录，可以直接登录，登录之后界面是这样的：(每个人的服务器界面会有点不一样，win比较方便，但是 linux更适合作为服务器系统)</p><p><a href="https://user-images.githubusercontent.com/60562661/73954608-04c3e080-493d-11ea-8fcb-52f59f4acc8d.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/73954608-04c3e080-493d-11ea-8fcb-52f59f4acc8d.png" class="lazyload"></a></p><h3 id="配置PHP环境"><a href="#配置PHP环境" class="headerlink" title="配置PHP环境"></a>配置PHP环境</h3><p>下载安装Xampp (XAMPP 是一个把 Apache 网页服务器与 PHP、Perl 及 MariaDB 集合在一起的安装包，允许用户可以在自己的电脑上轻易的建立网页服务器环境。)</p><p>中文官网下载地址 ： <a href="https://www.apachefriends.org/zh_cn/download.html。" target="_blank" rel="noopener">https://www.apachefriends.org/zh_cn/download.html。</a> </p><p>安装下一步下一步就可以，安装完之后开启<strong>Apache、 MySQL</strong>两项，如下图</p><p><a href="https://user-images.githubusercontent.com/60562661/73954610-055c7700-493d-11ea-879d-3a9c99c2e006.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/73954610-055c7700-493d-11ea-879d-3a9c99c2e006.png" class="lazyload"></a></p><p>点击Admin进入相应页面（如下图）即说明已经配置好。就是这么容易 。</p><p><a href="https://user-images.githubusercontent.com/60562661/73954613-05f50d80-493d-11ea-86f3-da2ae7e8a8b0.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/73954613-05f50d80-493d-11ea-86f3-da2ae7e8a8b0.png" class="lazyload"></a></p><h3 id="下载和安装可道云kodexplorer"><a href="#下载和安装可道云kodexplorer" class="headerlink" title="下载和安装可道云kodexplorer"></a>下载和安装可道云kodexplorer</h3><p>下载地址：<a href="http://kodcloud.com/download.html" target="_blank" rel="noopener">http://kodcloud.com/download.html</a></p><p>下载完成后解压，将可道云文件夹复制到xmapp安装文件夹下的htdocs文件夹，此时已经完成</p><p><strong>Note: 可道云文件夹命名应为</strong><code>kodexplorer</code>(有点常识都会理解)</p><h3 id="访问自己的私有云"><a href="#访问自己的私有云" class="headerlink" title="访问自己的私有云"></a>访问自己的私有云</h3><p><a href="http://112.xxx.xx.xx/kodexplorer/index.php?user/login" target="_blank" rel="noopener">http://112.xxx.xx.xx/kodexplorer/index.php?user/login</a></p><h2 id="可道云配置优化"><a href="#可道云配置优化" class="headerlink" title="可道云配置优化"></a>可道云配置优化</h2><p>操作完2已经可以访问上传下载添加用户了。但是此时上传速度很慢，此时就需要配置一下了，以下操作我亲自测试有用，但是下载还是比较慢，我再研究一下。</p><h3 id="修改php-ini上传限制"><a href="#修改php-ini上传限制" class="headerlink" title="修改php.ini上传限制"></a>修改php.ini上传限制</h3><p>在xmapp安装目录直接搜索该文件即可</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">php</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight php"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">max_execution_time = <span class="number">3600</span></span><br><span class="line">max_input_time = <span class="number">3600</span></span><br><span class="line">post_max_size = <span class="number">150</span>M</span><br><span class="line">upload_max_filesize = <span class="number">150</span>M</span><br></pre></td></tr></tbody></table></figure></div><h3 id="修改可道云配置"><a href="#修改可道云配置" class="headerlink" title="修改可道云配置"></a>修改可道云配置</h3><p>在config/下新建 setting_user.php文件;粘贴如下内容；(已存在则略过)</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">php</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight php"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"><!--?php</span--></span><br><span class="line"></span><br><span class="line"><span class="comment">//分片上传: 每个切片5M,需要php.ini 中upload_max_filesize大于此值</span></span><br><span class="line">$GLOBALS[<span class="string">'config'</span>][<span class="string">'settings'</span>][<span class="string">'updloadChunkSize'</span>] = <span class="number">1024</span>*<span class="number">1024</span>*<span class="number">5</span>;   </span><br><span class="line"></span><br><span class="line"><span class="comment">//上传并发数量; 推荐15个并发;</span></span><br><span class="line">$GLOBALS[<span class="string">'config'</span>][<span class="string">'settings'</span>][<span class="string">'updloadThreads'</span>] = <span class="number">15</span>;</span><br></span></pre></td></tr></tbody></table></figure></div><hr><p>完结，撒花，下载速度慢研究出来原因再更新</p><p><a href="https://user-images.githubusercontent.com/60562661/73954934-7d2aa180-493d-11ea-989f-f16d19aca743.jpg" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/73954934-7d2aa180-493d-11ea-989f-f16d19aca743.jpg" class="lazyload"></a></p></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 黑科技 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Cloud </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo_blog搭建部署笔记</title>
      <link href="/2020/02/05/MyBlog-Hexo%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA/"/>
      <url>/2020/02/05/MyBlog-Hexo%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><h2 id="安装环境"><a href="#安装环境" class="headerlink" title="安装环境"></a>安装环境</h2><p><strong>NodeJS</strong> + <strong>hexo</strong> + <strong>git</strong>, 这三个安装教程可以自行百度到，很多博客里也有，这里便不再赘述</p><h2 id="搭建博客"><a href="#搭建博客" class="headerlink" title="搭建博客"></a>搭建博客</h2><h3 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bash</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo init</span><br></pre></td></tr></tbody></table></figure></div><h3 id="写一篇新博客"><a href="#写一篇新博客" class="headerlink" title="写一篇新博客"></a>写一篇新博客</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bash</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo new <span class="string">"helloworld"</span> <span class="comment">#此时在source/_posts下会生成文章</span></span><br></pre></td></tr></tbody></table></figure></div><h3 id="运行测试"><a href="#运行测试" class="headerlink" title="运行测试"></a>运行测试</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bash</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo s</span><br></pre></td></tr></tbody></table></figure></div><p><strong>此时基本搭建完成</strong></p><h2 id="部署到github"><a href="#部署到github" class="headerlink" title="部署到github"></a>部署到github</h2><h3 id="安装deploy插件"><a href="#安装deploy插件" class="headerlink" title="安装deploy插件"></a>安装deploy插件</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bash</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install --save hexo-deployer-git</span><br></pre></td></tr></tbody></table></figure></div><h3 id="新建github仓库"><a href="#新建github仓库" class="headerlink" title="新建github仓库"></a>新建github仓库</h3><p>这步比较简单，可以自己查查如何新建</p><h3 id="修改全局配置文件-config-yml："><a href="#修改全局配置文件-config-yml：" class="headerlink" title="修改全局配置文件  _config.yml："></a>修改全局配置文件  _config.yml：</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">yml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight yml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">deploy:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">git</span></span><br><span class="line">  <span class="attr">repo:</span> <span class="string">https://github.com/fryddup/fryddup.github.io.git</span> <span class="comment">#自己的仓库地址</span></span><br><span class="line">  <span class="attr">branch:</span> <span class="string">master</span></span><br></pre></td></tr></tbody></table></figure></div><h3 id="推到远程服务器"><a href="#推到远程服务器" class="headerlink" title="推到远程服务器"></a>推到远程服务器</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bash</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo -d</span><br></pre></td></tr></tbody></table></figure></div><p>此时可以通过 <a href="https://huaqi.blue">https://huaqi.blue</a> 来访问我的博客</p><hr><h2 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h2><p>每次写完博客 hexo clean  hexo g 两步必不可少，然后在 hexo d</p><p><a href="C:\Users\33196\Desktop\0.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="C:\Users\33196\Desktop\0.png" class="lazyload"></a></p></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 博客 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> blog </tag>
            
            <tag> hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Windwos下几款实用又美观的软件</title>
      <link href="/2020/02/02/windwos%E4%B8%8B%E5%87%A0%E6%AC%BE%E5%AE%9E%E7%94%A8%E5%8F%88%E7%BE%8E%E8%A7%82%E7%9A%84%E8%BD%AF%E4%BB%B6%E6%8E%A8%E8%8D%90/"/>
      <url>/2020/02/02/windwos%E4%B8%8B%E5%87%A0%E6%AC%BE%E5%AE%9E%E7%94%A8%E5%8F%88%E7%BE%8E%E8%A7%82%E7%9A%84%E8%BD%AF%E4%BB%B6%E6%8E%A8%E8%8D%90/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><p>本人是windows重症患者，经常在搜集乱七八糟（好看）的软件，因此来记录几款实用的软件。</p><h2 id="1-Typora"><a href="#1-Typora" class="headerlink" title="1. Typora"></a>1. Typora</h2><p>markdown笔记软件，大家应该都知道这个，美观又实用！</p><p>官网：<a href="https://typora.io/" target="_blank" rel="noopener">https://typora.io/</a></p><p><a href="https://user-images.githubusercontent.com/60562661/73609608-62d58880-460a-11ea-8b27-655765e84224.gif" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/73609608-62d58880-460a-11ea-8b27-655765e84224.gif" class="lazyload"></a></p><h2 id="2-Choaolatey"><a href="#2-Choaolatey" class="headerlink" title="2. Choaolatey"></a>2. Choaolatey</h2><p>这是一款windows下的包管理器，可以像 linux 一样安装各种包，很是方便！</p><p>官网：<a href="https://chocolatey.org/" target="_blank" rel="noopener">https://chocolatey.org/</a></p><p><a href="https://user-images.githubusercontent.com/60562661/73609604-61a45b80-460a-11ea-923c-16414aa000a9.gif" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/73609604-61a45b80-460a-11ea-923c-16414aa000a9.gif" class="lazyload"></a></p><h2 id="3-hyper"><a href="#3-hyper" class="headerlink" title="3. hyper"></a>3. hyper</h2><p>hyper是 windows下面很炫酷的一个终端嘛，有各种皮肤、插件！</p><p>官网：<a href="https://hyper.is/" target="_blank" rel="noopener">https://hyper.is/</a></p><p><a href="https://user-images.githubusercontent.com/60562661/73609605-623cf200-460a-11ea-9ac7-f9c937f919fd.gif" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/73609605-623cf200-460a-11ea-9ac7-f9c937f919fd.gif" class="lazyload"></a></p><h2 id="4-Listary"><a href="#4-Listary" class="headerlink" title="4. Listary"></a>4. Listary</h2><p>这是一款很方便搜索打开本地文件的软件，有很多功能值得探索</p><p>官网：<a href="https://www.listary.com/" target="_blank" rel="noopener">https://www.listary.com/</a></p><p><a href="https://user-images.githubusercontent.com/60562661/73609607-623cf200-460a-11ea-915a-f9e90a77cfd6.gif" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/73609607-623cf200-460a-11ea-915a-f9e90a77cfd6.gif" class="lazyload"></a></p><h2 id="5-IobitUninstaller"><a href="#5-IobitUninstaller" class="headerlink" title="5. IobitUninstaller"></a>5. IobitUninstaller</h2><p>windows上卸载软件用的一款软件，超好用</p><p><a href="https://user-images.githubusercontent.com/60562661/73609606-623cf200-460a-11ea-9942-0fc4b33b02ba.png" data-fancybox="group" data-caption class="fancybox"><img alt title data-src="https://user-images.githubusercontent.com/60562661/73609606-623cf200-460a-11ea-9942-0fc4b33b02ba.png" class="lazyload"></a></p><p>后续再有好的继续补充…..</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 软件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> windows </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hugo_blog搭建部署笔记</title>
      <link href="/2020/02/02/hugo_blog%E6%90%AD%E5%BB%BA%E9%83%A8%E7%BD%B2%E7%AC%94%E8%AE%B0/"/>
      <url>/2020/02/02/hugo_blog%E6%90%AD%E5%BB%BA%E9%83%A8%E7%BD%B2%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><p>之前一直用的  Hexo Blog ,奈何写出来太丑了，不习惯，部署起来也比较麻烦，就找到了新的好看的，还真的是好看是第一生产力！hugo部署过程如下。</p><p><a href="https://user-images.githubusercontent.com/60562661/73609078-10459d80-4605-11ea-93b4-d26fa0f93625.png" data-fancybox="group" data-caption="hugo" class="fancybox"><img alt="hugo" title="hugo" data-src="https://user-images.githubusercontent.com/60562661/73609078-10459d80-4605-11ea-93b4-d26fa0f93625.png" class="lazyload"></a></p><h2 id="描述版："><a href="#描述版：" class="headerlink" title="描述版："></a>描述版：</h2><h4 id="1-安装-hugo-（有很多方法，可以到官方网站看一下，我是采用chocolate来安装的）"><a href="#1-安装-hugo-（有很多方法，可以到官方网站看一下，我是采用chocolate来安装的）" class="headerlink" title="1.安装 hugo （有很多方法，可以到官方网站看一下，我是采用chocolate来安装的）"></a>1.安装 hugo （有很多方法，可以到官方网站看一下，我是采用chocolate来安装的）</h4><p><code>choco install hugo</code></p><h4 id="2-检测go语言是否安装成功"><a href="#2-检测go语言是否安装成功" class="headerlink" title="2.检测go语言是否安装成功"></a>2.检测go语言是否安装成功</h4><p><code>hugo version</code></p><h4 id="3-开始建站-建立一个-myblog-站点（博客的根目录）"><a href="#3-开始建站-建立一个-myblog-站点（博客的根目录）" class="headerlink" title="3.开始建站,建立一个 myblog 站点（博客的根目录）"></a>3.开始建站,建立一个 myblog 站点（博客的根目录）</h4><p><code>hugo new site myblog</code></p><h4 id="4-安装hugo博客主题-官网-https-themes-gohugo-io-每个主题有对应的方式，我以我自己的为例-此时目录在博客的根目录"><a href="#4-安装hugo博客主题-官网-https-themes-gohugo-io-每个主题有对应的方式，我以我自己的为例-此时目录在博客的根目录" class="headerlink" title="4.安装hugo博客主题 官网 https://themes.gohugo.io/,每个主题有对应的方式，我以我自己的为例,此时目录在博客的根目录"></a>4.安装hugo博客主题 官网 <a href="https://themes.gohugo.io/,每个主题有对应的方式，我以我自己的为例,此时目录在博客的根目录" target="_blank" rel="noopener">https://themes.gohugo.io/,每个主题有对应的方式，我以我自己的为例,此时目录在博客的根目录</a></h4><p><code>git clone https://github.com/flysnow-org/maupassant-hugo themes/maupassant</code></p><h4 id="5-写一篇新博客，位于content-post"><a href="#5-写一篇新博客，位于content-post" class="headerlink" title="5.写一篇新博客，位于content/post/"></a>5.写一篇新博客，位于content/post/</h4><p><code>hugo new post/Hello,world.md</code></p><h4 id="6-启动本地调试，此时位于根目录"><a href="#6-启动本地调试，此时位于根目录" class="headerlink" title="6.启动本地调试，此时位于根目录"></a>6.启动本地调试，此时位于根目录</h4><p><code>hugo server --buildDrafts</code></p><h4 id="7-新建github仓库，这个比较容易，自己解决"><a href="#7-新建github仓库，这个比较容易，自己解决" class="headerlink" title="7.新建github仓库，这个比较容易，自己解决"></a>7.新建github仓库，这个比较容易，自己解决</h4><h4 id="8-关联到GitHub-此步骤会生成public文件夹"><a href="#8-关联到GitHub-此步骤会生成public文件夹" class="headerlink" title="8.关联到GitHub,此步骤会生成public文件夹"></a>8.关联到GitHub,此步骤会生成public文件夹</h4><p><code>hugo --themes=maupassant --baseURL="https://huaqi19.github.io/"</code></p><h4 id="9-将-public-文件夹内容推送到空的github仓库中"><a href="#9-将-public-文件夹内容推送到空的github仓库中" class="headerlink" title="9.将 public 文件夹内容推送到空的github仓库中"></a>9.将 public 文件夹内容推送到空的github仓库中</h4><p>此处步骤省略，如何推送可以参考我的上一篇博客  git推送文件</p><h4 id="10-更新博客"><a href="#10-更新博客" class="headerlink" title="10.更新博客"></a>10.更新博客</h4><p><code>hugo -D</code></p><h4 id="至此博客搭建完成，主题配置请自行研究"><a href="#至此博客搭建完成，主题配置请自行研究" class="headerlink" title="至此博客搭建完成，主题配置请自行研究"></a>至此博客搭建完成，主题配置请自行研究</h4><h2 id="代码版："><a href="#代码版：" class="headerlink" title="代码版："></a>代码版：</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bash</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.安装 hugo （有很多方法，可以到官方网站看一下，我是采用chocolate来安装的）</span></span><br><span class="line">choco install hugo</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.检测go语言是否安装成功</span></span><br><span class="line">hugo version</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.开始建站,建立一个 myblog 站点（博客的根目录）</span></span><br><span class="line">hugo new site myblog</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.安装hugo博客主题 官网 https://themes.gohugo.io/</span></span><br><span class="line"><span class="comment"># 每个主题有对应的方式，我以我自己的为例</span></span><br><span class="line"><span class="comment"># 此时目录在博客的根目录</span></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/flysnow-org/maupassant-hugo themes/maupassant</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5.写一篇新博客，位于content/post/</span></span><br><span class="line">hugo new post/Hello,world.md</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6.启动本地调试，此时位于根目录</span></span><br><span class="line">hugo server --buildDrafts</span><br><span class="line"></span><br><span class="line"><span class="comment"># 7.新建github仓库，这个比较容易，自己解决</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 8.关联到GitHub,此步骤会生成public文件夹</span></span><br><span class="line">hugo --themes=maupassant --baseURL=<span class="string">"https://huaqi19.github.io/"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 9.将 public 文件夹内容推送到空的github仓库中</span></span><br><span class="line"><span class="comment"># 此处步骤省略，如何推送可以参考我的上一篇博客  git推送文件</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 10.更新博客</span></span><br><span class="line">hugo -D</span><br><span class="line"></span><br><span class="line"><span class="comment"># 至此博客搭建完成，主题配置请自行研究</span></span><br></pre></td></tr></tbody></table></figure></div></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> 博客 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> blog </tag>
            
            <tag> hugo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Git常用操作整合</title>
      <link href="/2020/02/02/git%E6%8E%A8%E9%80%81%E6%96%87%E4%BB%B6/"/>
      <url>/2020/02/02/git%E6%8E%A8%E9%80%81%E6%96%87%E4%BB%B6/</url>
      
        <content type="html"><![CDATA[<html><head><link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script></head><body><p>github远程托管文件 非常的方便。git操作种比较多的就是本地文件推送到远程，仓库等。而我一直也是没有搞明白，github本地文件远程推送是如何操作的，以至于今天卡了很久，来记录一下。</p><p><a href="https://user-images.githubusercontent.com/60562661/73609075-07ed6280-4605-11ea-9971-35fe0663a9e0.jpg" data-fancybox="group" data-caption="git" class="fancybox"><img alt="git" title="git" data-src="https://user-images.githubusercontent.com/60562661/73609075-07ed6280-4605-11ea-9971-35fe0663a9e0.jpg" class="lazyload"></a></p><h2 id="git推送本地文件"><a href="#git推送本地文件" class="headerlink" title="git推送本地文件"></a>git推送本地文件</h2><h3 id="一般流程"><a href="#一般流程" class="headerlink" title="一般流程"></a>一般流程</h3><p><strong>Note </strong>:  默认远程仓库是空的</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bash</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.新建远程仓库 ，这个可以自己去查阅，很容易</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.把本地需要推送的文件夹设置为git仓库</span></span><br><span class="line">git init</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.添加文件</span></span><br><span class="line">git add .</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.提交文件</span></span><br><span class="line">git commit -m <span class="string">'first_commit'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 5.添加镜像源</span></span><br><span class="line">git remote add origin https://github.com/fryddup/fryddup.github.io.git</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6.推送文件</span></span><br><span class="line">git push -u origin master</span><br></pre></td></tr></tbody></table></figure></div><h3 id="同步问题"><a href="#同步问题" class="headerlink" title="同步问题"></a>同步问题</h3><p>以上代码即可实现本地文件推送到远程，但是注意当仓库不是空的，仓库有改动，应当如下操作：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bash</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">git add .</span><br><span class="line"></span><br><span class="line">git commit -m <span class="string">'first_commit'</span></span><br><span class="line"></span><br><span class="line">git pull  <span class="comment">#注意，此命令即是远程文件同步到本地。</span></span><br><span class="line"></span><br><span class="line">git push -u origin master</span><br></pre></td></tr></tbody></table></figure></div><h2 id="git-代理相关"><a href="#git-代理相关" class="headerlink" title="git 代理相关"></a>git 代理相关</h2><h3 id="设置代理"><a href="#设置代理" class="headerlink" title="设置代理"></a>设置代理</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bash</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git config --global http.proxy <span class="string">'socks5://127.0.0.1:1080'</span> </span><br><span class="line">git config --global https.proxy <span class="string">'socks5://127.0.0.1:1080'</span></span><br></pre></td></tr></tbody></table></figure></div><h3 id="查看代理"><a href="#查看代理" class="headerlink" title="查看代理"></a>查看代理</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bash</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git config --global --get http.proxy</span><br><span class="line">git config --global --get https.proxy</span><br></pre></td></tr></tbody></table></figure></div><h3 id="取消代理"><a href="#取消代理" class="headerlink" title="取消代理"></a>取消代理</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bash</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git config --global --<span class="built_in">unset</span> http.proxy</span><br><span class="line">git config --global --<span class="built_in">unset</span> https.proxy</span><br></pre></td></tr></tbody></table></figure></div><h2 id="踩坑"><a href="#踩坑" class="headerlink" title="踩坑"></a>踩坑</h2><p>新建仓库，新建<code>README.md</code>，本地 add，commit 之后，push遇到了如下错误：</p><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">bash</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> ! [rejected]        master -> master (non-fast-forward)</span><br><span class="line">error: failed to push some refs to <span class="string">'https://github.com/tzwx/DeepLearning.git'</span></span><br></pre></td></tr></tbody></table></figure></div><ol><li><code>git pull origin master --allow-unrelated-histories //把远程仓库和本地同步，消除差异</code></li><li><code>git push -u origin master</code></li></ol><p>git其他操作、问题以后遇到了再补充**</p></body></html>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
          <category> Git </category>
          
      </categories>
      
      
        <tags>
            
            <tag> git </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
